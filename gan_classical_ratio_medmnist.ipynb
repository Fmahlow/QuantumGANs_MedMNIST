{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANs ClÃ¡ssicas â€“ Experimentos por Ratio (MedMNIST)\n",
    "\n",
    "Este notebook reÃºne apenas os blocos responsÃ¡veis por variar os ratios de dados sintÃ©ticos nos experimentos de classificaÃ§Ã£o, tanto no cenÃ¡rio nÃ£o balanceado quanto no balanceado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision medmnist matplotlib torchmetrics seaborn scikit-learn scipy --quiet\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import medmnist\n",
    "from medmnist import INFO\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/mahlow/.medmnist/breastmnist.npz\n",
      "Using downloaded and verified file: /home/mahlow/.medmnist/breastmnist.npz\n"
     ]
    }
   ],
   "source": [
    "from medmnist_data import load_medmnist_data\n",
    "\n",
    "DATA_FLAG = 'breastmnist'\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "medmnist_data = load_medmnist_data(\n",
    "    data_flag=DATA_FLAG,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    download=True,\n",
    ")\n",
    "info = medmnist_data.info\n",
    "train_dataset = medmnist_data.train_dataset\n",
    "test_dataset = medmnist_data.test_dataset\n",
    "train_loader = medmnist_data.train_loader\n",
    "test_loader = medmnist_data.test_loader\n",
    "num_classes = medmnist_data.num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classical_gans import (\n",
    "    DCGenerator,\n",
    "    DCDiscriminator,\n",
    "    CGANGenerator,\n",
    "    CGANDiscriminator,\n",
    "    WGANGPGenerator,\n",
    "    WGANGPCritic,\n",
    "    train_gan_for_class,\n",
    "    train_gan_for_class_with_loss,\n",
    "    train_cgan,\n",
    "    train_wgangp,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "latent_dim = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ClassificaÃ§Ã£o com ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset, random_split\n",
    "from torchvision.models import resnet18\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "\n",
    "# --- collate_fn e SyntheticDataset inalterados ---\n",
    "def custom_collate_fn(batch):\n",
    "    xs, ys = zip(*batch)\n",
    "    xs = torch.stack(xs, dim=0)\n",
    "    ys_list = []\n",
    "    for y in ys:\n",
    "        if isinstance(y, torch.Tensor):\n",
    "            val = y.item() if y.numel() == 1 else int(y.argmax().item())\n",
    "        else:\n",
    "            val = int(y)\n",
    "        ys_list.append(val)\n",
    "    ys = torch.tensor(ys_list, dtype=torch.long)\n",
    "    return xs, ys\n",
    "\n",
    "class SyntheticDataset(Dataset):\n",
    "    def __init__(self, generator_dict, num_per_class, latent_dim, device=None):\n",
    "        self.samples = []\n",
    "        device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        for label_name, gen in generator_dict.items():\n",
    "            label = 0 if label_name == 'malignant' else 1\n",
    "            noise = torch.randn(num_per_class, latent_dim, 1, 1, device=device)\n",
    "            with torch.no_grad():\n",
    "                imgs = gen(noise).cpu()\n",
    "            for img in imgs:\n",
    "                self.samples.append((img, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "# --- FunÃ§Ãµes de treino e avaliaÃ§Ã£o inalteradas ---\n",
    "def train_model(model, loader, epochs=5, device=None):\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    for epoch in range(epochs):\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def evaluate(model, loader, device=None):\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            out = model(x)\n",
    "            preds = out.argmax(dim=1).cpu()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(y)\n",
    "\n",
    "    y_true = torch.cat(all_labels).numpy()\n",
    "    y_pred = torch.cat(all_preds).numpy()\n",
    "\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return acc, prec, rec, f1, auc, tn, fp, fn, tp\n",
    "\n",
    "# --- FunÃ§Ã£o principal modificada ---\n",
    "def run_experiments(train_dataset, test_dataset, G_dc_dict, latent_dim,\n",
    "                    batch_size=32, epochs=5, device=None):\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    ratios = [0.0, 0.25, 0.5, 0.75, 1.0, 1.5]\n",
    "    results = []\n",
    "\n",
    "    print(\"\\n=== Experimentos com mistura real + sintÃ©tico ===\\n\")\n",
    "    for r in ratios:\n",
    "        if r == 0.0:\n",
    "            ds = train_dataset\n",
    "            print(f\"Ratio {r:.2f}: sem dados sintÃ©ticos (apenas reais)\")\n",
    "        else:\n",
    "            num_syn = int(len(train_dataset) * r)\n",
    "            num_per_class = num_syn // 2\n",
    "            syn_ds = SyntheticDataset(G_dc_dict, num_per_class, latent_dim, device)\n",
    "            ds = ConcatDataset([train_dataset, syn_ds])\n",
    "\n",
    "            print(f\"Ratio {r:.2f}: {num_syn} sintÃ©ticas no total \"\n",
    "                  f\"({num_per_class} por classe)\")\n",
    "\n",
    "        loader = DataLoader(ds, batch_size=batch_size, shuffle=True,\n",
    "                            collate_fn=custom_collate_fn)\n",
    "\n",
    "        model = resnet18(num_classes=2)\n",
    "        model.conv1 = nn.Conv2d(1, 64, 7, 2, 3, bias=False)\n",
    "\n",
    "        train_model(model, loader, epochs=epochs, device=device)\n",
    "\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                 shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "        acc, prec, rec, f1, auc, tn, fp, fn, tp = evaluate(\n",
    "            model, test_loader, device=device\n",
    "        )\n",
    "\n",
    "        results.append({\n",
    "            'ratio': r,\n",
    "            'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1,\n",
    "            'auc': auc, 'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp\n",
    "        })\n",
    "\n",
    "    print(\"\\n=== Treino 100% sintÃ©tico â†’ Teste real ===\")\n",
    "    syn_only_ds = SyntheticDataset(G_dc_dict, len(train_dataset)//2, latent_dim, device)\n",
    "    print(f\"Total de sintÃ©ticas geradas: {len(syn_only_ds)} \"\n",
    "          f\"({len(syn_only_ds)//2} por classe)\\n\")\n",
    "\n",
    "    syn_loader  = DataLoader(syn_only_ds, batch_size=batch_size, shuffle=True,\n",
    "                             collate_fn=custom_collate_fn)\n",
    "    model = resnet18(num_classes=2)\n",
    "    model.conv1 = nn.Conv2d(1, 64, 7, 2, 3, bias=False)\n",
    "    train_model(model, syn_loader, epochs=epochs, device=device)\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                             collate_fn=custom_collate_fn)\n",
    "    acc, prec, rec, f1, auc, tn, fp, fn, tp = evaluate(model, test_loader, device=device)\n",
    "    results.append({\n",
    "        'ratio': '100%_sintÃ©ticoâ†’real', 'acc': acc, 'prec': prec, 'rec': rec,\n",
    "        'f1': f1, 'auc': auc, 'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp\n",
    "    })\n",
    "\n",
    "    print(\"\\n=== Treino/Teste 100% sintÃ©tico (70/30) ===\")\n",
    "    total_syn = len(syn_only_ds)\n",
    "    n_train   = int(total_syn * 0.7)\n",
    "    n_test    = total_syn - n_train\n",
    "    print(f\"Total: {total_syn} (treino: {n_train}, teste: {n_test})\\n\")\n",
    "\n",
    "    syn_train_ds, syn_test_ds = random_split(syn_only_ds, [n_train, n_test])\n",
    "    train_loader = DataLoader(syn_train_ds, batch_size=batch_size, shuffle=True,\n",
    "                              collate_fn=custom_collate_fn)\n",
    "    test_loader  = DataLoader(syn_test_ds,  batch_size=batch_size, shuffle=False,\n",
    "                              collate_fn=custom_collate_fn)\n",
    "    model = resnet18(num_classes=2)\n",
    "    model.conv1 = nn.Conv2d(1, 64, 7, 2, 3, bias=False)\n",
    "    train_model(model, train_loader, epochs=epochs, device=device)\n",
    "    acc, prec, rec, f1, auc, tn, fp, fn, tp = evaluate(model, test_loader, device=device)\n",
    "    results.append({\n",
    "        'ratio': '100%_sintÃ©tico_70/30_selftest', 'acc': acc, 'prec': prec,\n",
    "        'rec': rec, 'f1': f1, 'auc': auc, 'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp\n",
    "    })\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanceamento de Classes com Dados SintÃ©ticos da Classe 0\n",
    "\n",
    "Treina um classificador acrescentando gradualmente amostras geradas pela GAN apenas da classe 0 atÃ© que o conjunto de treino fique balanceado.\n",
    "O conjunto de teste permanece inalterado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import ConcatDataset, TensorDataset, DataLoader\n",
    "from torchvision.models import resnet18\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def _to_scalar(y):\n",
    "    if isinstance(y, torch.Tensor):\n",
    "        return int(y.detach().view(-1)[0].item())\n",
    "    y_np = np.asarray(y)\n",
    "    return int(y_np.reshape(-1)[0].item())\n",
    "\n",
    "def balance_class0_experiment(\n",
    "    train_dataset, test_dataset, G_class0, latent_dim,\n",
    "    step_ratio=0.25, epochs=5, batch_size=64, device=None\n",
    "):\n",
    "    device = torch.device(device or ('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "    # Generator na GPU/CPU correta e em modo eval\n",
    "    G_class0 = G_class0.to(device).eval()\n",
    "\n",
    "    # Contagem segura das classes\n",
    "    count0 = sum(1 for _, y in train_dataset if _to_scalar(y) == 0)\n",
    "    count1 = sum(1 for _, y in train_dataset if _to_scalar(y) == 1)\n",
    "\n",
    "    # deficit de 0 para igualar 1 (assumindo classe 0 como minoritÃ¡ria)\n",
    "    deficit = max(0, count1 - count0)\n",
    "\n",
    "    steps = int(1 / step_ratio)\n",
    "    ratios, metrics = [], []\n",
    "\n",
    "    print(f\"[INFO] Reais: class0={count0}, class1={count1} | dÃ©ficit(class0)={deficit}\")\n",
    "    print(\"[INFO] ratio=0: balancear primeiro (adicionar exatamente o dÃ©ficit na classe 0).\")\n",
    "    print(\"[INFO] ratios seguintes: adicionar extra = int(dÃ©ficit * r) por cima do conjunto jÃ¡ balanceado.\\n\")\n",
    "\n",
    "    # PrÃ©-cria o dataset balanceado (ratio = 0)\n",
    "    if deficit > 0:\n",
    "        z0 = torch.randn(deficit, latent_dim, 1, 1, device=device, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            synth_imgs0 = G_class0(z0)\n",
    "        if synth_imgs0.dim() == 3:\n",
    "            synth_imgs0 = synth_imgs0.unsqueeze(1)\n",
    "        synth_imgs0 = synth_imgs0.detach().cpu()\n",
    "        synth_labels0 = torch.zeros(deficit, dtype=torch.long)\n",
    "        base_synth_ds = TensorDataset(synth_imgs0, synth_labels0)\n",
    "        balanced_ds = ConcatDataset([train_dataset, base_synth_ds])\n",
    "    else:\n",
    "        # jÃ¡ estÃ¡ balanceado\n",
    "        balanced_ds = train_dataset\n",
    "\n",
    "    # Loop de ratios: ratio 0 usa o balanced_ds; ratios > 0 adicionam \"extra\"\n",
    "    for i in range(steps + 1):\n",
    "        r = i * step_ratio\n",
    "\n",
    "        if i == 0:\n",
    "            # apenas o balanceamento\n",
    "            current_ds = balanced_ds\n",
    "            added_this_round = deficit\n",
    "            total_syn_class0 = deficit\n",
    "            print(f\"ratio={r:.2f}: +{added_this_round} (classe 0) â†’ total sintÃ©tico classe0={total_syn_class0}\")\n",
    "        else:\n",
    "            extra = int(deficit * r)\n",
    "            if extra > 0:\n",
    "                z_extra = torch.randn(extra, latent_dim, 1, 1, device=device, dtype=torch.float32)\n",
    "                with torch.no_grad():\n",
    "                    extra_imgs0 = G_class0(z_extra)\n",
    "                if extra_imgs0.dim() == 3:\n",
    "                    extra_imgs0 = extra_imgs0.unsqueeze(1)\n",
    "                extra_imgs0 = extra_imgs0.detach().cpu()\n",
    "                extra_labels0 = torch.zeros(extra, dtype=torch.long)\n",
    "                extra_ds0 = TensorDataset(extra_imgs0, extra_labels0)\n",
    "                current_ds = ConcatDataset([balanced_ds, extra_ds0])\n",
    "            else:\n",
    "                current_ds = balanced_ds\n",
    "\n",
    "            added_this_round = deficit + extra   # total adicionada nesta iteraÃ§Ã£o (em relaÃ§Ã£o ao dataset original)\n",
    "            total_syn_class0 = added_this_round  # todo o sintÃ©tico atÃ© aqui Ã© da classe 0\n",
    "            print(f\"ratio={r:.2f}: +{added_this_round} (classe 0; sendo {deficit} p/ balancear + {extra} extra) \"\n",
    "                  f\"â†’ total sintÃ©tico classe0={total_syn_class0}\")\n",
    "\n",
    "        loader = DataLoader(\n",
    "            current_ds, batch_size=batch_size, shuffle=True,\n",
    "            pin_memory=(device.type == 'cuda'),\n",
    "            collate_fn=custom_collate_fn\n",
    "        )\n",
    "\n",
    "        # novo classificador a cada rodada\n",
    "        model = resnet18(num_classes=2)\n",
    "        model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        model = model.to(device)\n",
    "\n",
    "        train_model(model, loader, epochs=epochs, device=device)\n",
    "\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, batch_size=batch_size, shuffle=False,\n",
    "            pin_memory=(device.type == 'cuda'),\n",
    "            collate_fn=custom_collate_fn\n",
    "        )\n",
    "        acc, prec, rec, f1, auc, tn, fp, fn, tp = evaluate(model, test_loader, device=device)\n",
    "\n",
    "        ratios.append(r)\n",
    "        metrics.append({\n",
    "            'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1, 'auc': auc,\n",
    "            'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp,\n",
    "            'added_class0_synth_total': total_syn_class0,\n",
    "            'added_this_round': added_this_round\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(metrics)\n",
    "    df.insert(0, 'ratio', ratios)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rodando vÃ¡rias vezes (nÃ£o balanceado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "\n",
    "def run_k_times(\n",
    "    k: int,\n",
    "    train_dataset,\n",
    "    test_dataset,\n",
    "    make_generators_fn,   # callable: make_generators_fn(run_id) -> G_dc_dict\n",
    "    latent_dim: int,\n",
    "    batch_size: int = 32,\n",
    "    epochs: int = 5,\n",
    "    device: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Executa k rodadas independentes:\n",
    "      1) cria/treina geradores via make_generators_fn(run_id)\n",
    "      2) roda run_experiments(...) com esses geradores\n",
    "      3) agrega mÃ©dia e desvio por ratio\n",
    "\n",
    "    Adiciona prints com tempo estimado e total.\n",
    "    \"\"\"\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    all_runs = []\n",
    "\n",
    "    print(f\"\\n=== Iniciando {k} rodadas de experimento ===\")\n",
    "    start_global = time.time()\n",
    "\n",
    "    for run_id in range(1, k + 1):\n",
    "        run_start = time.time()\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(f\"== Rodada {run_id}/{k}\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        # 1) treinar/carregar GANs desta rodada\n",
    "        G_dc_dict = make_generators_fn(run_id)\n",
    "\n",
    "        # 2) executar seus experimentos com estes geradores\n",
    "        df_k = run_experiments(\n",
    "            train_dataset=train_dataset,\n",
    "            test_dataset=test_dataset,\n",
    "            G_dc_dict=G_dc_dict,\n",
    "            latent_dim=latent_dim,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            device=device\n",
    "        )\n",
    "        df_k[\"run_id\"] = run_id\n",
    "        all_runs.append(df_k)\n",
    "\n",
    "        # liberar memoria da GPU (se aplicÃ¡vel)\n",
    "        del G_dc_dict\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # === tempo e estimativas ===\n",
    "        run_end = time.time()\n",
    "        elapsed = run_end - run_start\n",
    "        avg_time = np.mean([df_k.attrs.get('elapsed', elapsed) if 'elapsed' in df_k.attrs else elapsed for df_k in all_runs])\n",
    "        remaining = avg_time * (k - run_id)\n",
    "        print(f\"â±ï¸  Tempo da rodada {run_id}: {elapsed/60:.2f} min\")\n",
    "        print(f\"ðŸ•  Estimativa restante: {remaining/60:.2f} min ({(remaining/60)/60:.2f} h)\")\n",
    "\n",
    "    end_global = time.time()\n",
    "    total_time = end_global - start_global\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"âœ… Todas as {k} rodadas concluÃ­das.\")\n",
    "    print(f\"â±ï¸  Tempo total: {total_time/60:.2f} min ({(total_time/60)/60:.2f} h)\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    # concatena todas as rodadas\n",
    "    df_all = pd.concat(all_runs, ignore_index=True)\n",
    "\n",
    "    # agrega mÃ©dia e desvio por ratio\n",
    "    agg = df_all.groupby(\"ratio\").agg({\n",
    "        \"acc\": [\"mean\", \"std\"],\n",
    "        \"prec\": [\"mean\", \"std\"],\n",
    "        \"rec\": [\"mean\", \"std\"],\n",
    "        \"f1\": [\"mean\", \"std\"],\n",
    "        \"auc\": [\"mean\", \"std\"],\n",
    "        \"tn\": [\"mean\", \"std\"],\n",
    "        \"fp\": [\"mean\", \"std\"],\n",
    "        \"fn\": [\"mean\", \"std\"],\n",
    "        \"tp\": [\"mean\", \"std\"]\n",
    "    }).reset_index()\n",
    "\n",
    "    # opcional: deixar colunas planas\n",
    "    agg.columns = ['_'.join(col).strip('_') for col in agg.columns.values]\n",
    "\n",
    "    return df_all, agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Iniciando 5 rodadas de experimento ===\n",
      "\n",
      "======================================================================\n",
      "== Rodada 1/5\n",
      "======================================================================\n",
      "[GAN] Rodada 1: treinando G_malignant e G_benign do zero | seed=1001\n",
      "Epoch 1/50 - Loss D: 1.041 | Loss G: 1.078\n",
      "Epoch 2/50 - Loss D: 0.497 | Loss G: 1.726\n",
      "Epoch 3/50 - Loss D: 0.388 | Loss G: 2.113\n",
      "Epoch 4/50 - Loss D: 0.279 | Loss G: 2.390\n",
      "Epoch 5/50 - Loss D: 0.195 | Loss G: 2.667\n",
      "Epoch 6/50 - Loss D: 0.247 | Loss G: 2.621\n",
      "Epoch 7/50 - Loss D: 0.178 | Loss G: 2.939\n",
      "Epoch 8/50 - Loss D: 0.156 | Loss G: 3.045\n",
      "Epoch 9/50 - Loss D: 0.172 | Loss G: 3.075\n",
      "Epoch 10/50 - Loss D: 0.143 | Loss G: 3.160\n",
      "Epoch 11/50 - Loss D: 0.147 | Loss G: 3.185\n",
      "Epoch 12/50 - Loss D: 0.175 | Loss G: 3.157\n",
      "Epoch 13/50 - Loss D: 0.206 | Loss G: 3.066\n",
      "Epoch 14/50 - Loss D: 0.192 | Loss G: 2.874\n",
      "Epoch 15/50 - Loss D: 0.246 | Loss G: 3.545\n",
      "Epoch 16/50 - Loss D: 0.398 | Loss G: 2.599\n",
      "Epoch 17/50 - Loss D: 0.433 | Loss G: 2.848\n",
      "Epoch 18/50 - Loss D: 0.327 | Loss G: 2.461\n",
      "Epoch 19/50 - Loss D: 0.795 | Loss G: 2.645\n",
      "Epoch 20/50 - Loss D: 0.395 | Loss G: 2.171\n",
      "Epoch 21/50 - Loss D: 0.552 | Loss G: 2.366\n",
      "Epoch 22/50 - Loss D: 0.430 | Loss G: 2.330\n",
      "Epoch 23/50 - Loss D: 0.758 | Loss G: 2.231\n",
      "Epoch 24/50 - Loss D: 0.524 | Loss G: 2.077\n",
      "Epoch 25/50 - Loss D: 0.496 | Loss G: 2.326\n",
      "Epoch 26/50 - Loss D: 1.049 | Loss G: 1.597\n",
      "Epoch 27/50 - Loss D: 0.703 | Loss G: 1.662\n",
      "Epoch 28/50 - Loss D: 0.986 | Loss G: 1.442\n",
      "Epoch 29/50 - Loss D: 0.762 | Loss G: 1.414\n",
      "Epoch 30/50 - Loss D: 0.867 | Loss G: 1.331\n",
      "Epoch 31/50 - Loss D: 1.093 | Loss G: 1.344\n",
      "Epoch 32/50 - Loss D: 0.895 | Loss G: 1.323\n",
      "Epoch 33/50 - Loss D: 0.786 | Loss G: 1.404\n",
      "Epoch 34/50 - Loss D: 0.991 | Loss G: 1.443\n",
      "Epoch 35/50 - Loss D: 0.929 | Loss G: 1.314\n",
      "Epoch 36/50 - Loss D: 0.893 | Loss G: 1.273\n",
      "Epoch 37/50 - Loss D: 0.838 | Loss G: 1.275\n",
      "Epoch 38/50 - Loss D: 1.105 | Loss G: 1.411\n",
      "Epoch 39/50 - Loss D: 0.903 | Loss G: 1.274\n",
      "Epoch 40/50 - Loss D: 0.828 | Loss G: 1.242\n",
      "Epoch 41/50 - Loss D: 0.905 | Loss G: 1.349\n",
      "Epoch 42/50 - Loss D: 0.841 | Loss G: 1.238\n",
      "Epoch 43/50 - Loss D: 0.999 | Loss G: 1.421\n",
      "Epoch 44/50 - Loss D: 0.892 | Loss G: 1.342\n",
      "Epoch 45/50 - Loss D: 0.909 | Loss G: 1.212\n",
      "Epoch 46/50 - Loss D: 1.069 | Loss G: 1.310\n",
      "Epoch 47/50 - Loss D: 0.926 | Loss G: 1.236\n",
      "Epoch 48/50 - Loss D: 0.950 | Loss G: 1.282\n",
      "Epoch 49/50 - Loss D: 0.882 | Loss G: 1.238\n",
      "Epoch 50/50 - Loss D: 0.854 | Loss G: 1.481\n",
      "Epoch 1/50 - Loss D: 1.036 | Loss G: 1.051\n",
      "Epoch 2/50 - Loss D: 0.614 | Loss G: 1.530\n",
      "Epoch 3/50 - Loss D: 0.430 | Loss G: 2.018\n",
      "Epoch 4/50 - Loss D: 0.314 | Loss G: 2.206\n",
      "Epoch 5/50 - Loss D: 0.264 | Loss G: 2.463\n",
      "Epoch 6/50 - Loss D: 0.255 | Loss G: 2.546\n",
      "Epoch 7/50 - Loss D: 0.245 | Loss G: 2.651\n",
      "Epoch 8/50 - Loss D: 0.263 | Loss G: 2.613\n",
      "Epoch 9/50 - Loss D: 0.268 | Loss G: 2.646\n",
      "Epoch 10/50 - Loss D: 0.322 | Loss G: 2.631\n",
      "Epoch 11/50 - Loss D: 0.403 | Loss G: 2.813\n",
      "Epoch 12/50 - Loss D: 0.227 | Loss G: 2.967\n",
      "Epoch 13/50 - Loss D: 0.240 | Loss G: 3.308\n",
      "Epoch 14/50 - Loss D: 0.650 | Loss G: 2.543\n",
      "Epoch 15/50 - Loss D: 0.395 | Loss G: 2.415\n",
      "Epoch 16/50 - Loss D: 0.391 | Loss G: 2.408\n",
      "Epoch 17/50 - Loss D: 1.023 | Loss G: 1.993\n",
      "Epoch 18/50 - Loss D: 0.632 | Loss G: 2.100\n",
      "Epoch 19/50 - Loss D: 0.933 | Loss G: 1.617\n",
      "Epoch 20/50 - Loss D: 0.699 | Loss G: 1.740\n",
      "Epoch 21/50 - Loss D: 0.851 | Loss G: 1.903\n",
      "Epoch 22/50 - Loss D: 1.028 | Loss G: 1.305\n",
      "Epoch 23/50 - Loss D: 0.961 | Loss G: 1.222\n",
      "Epoch 24/50 - Loss D: 1.099 | Loss G: 1.299\n",
      "Epoch 25/50 - Loss D: 0.973 | Loss G: 1.221\n",
      "Epoch 26/50 - Loss D: 1.027 | Loss G: 1.323\n",
      "Epoch 27/50 - Loss D: 0.902 | Loss G: 1.317\n",
      "Epoch 28/50 - Loss D: 1.040 | Loss G: 1.222\n",
      "Epoch 29/50 - Loss D: 0.973 | Loss G: 1.216\n",
      "Epoch 30/50 - Loss D: 1.031 | Loss G: 1.139\n",
      "Epoch 31/50 - Loss D: 0.985 | Loss G: 1.177\n",
      "Epoch 32/50 - Loss D: 1.014 | Loss G: 1.199\n",
      "Epoch 33/50 - Loss D: 1.008 | Loss G: 1.178\n",
      "Epoch 34/50 - Loss D: 1.072 | Loss G: 1.254\n",
      "Epoch 35/50 - Loss D: 1.099 | Loss G: 1.109\n",
      "Epoch 36/50 - Loss D: 1.135 | Loss G: 1.120\n",
      "Epoch 37/50 - Loss D: 1.106 | Loss G: 1.090\n",
      "Epoch 38/50 - Loss D: 1.032 | Loss G: 1.230\n",
      "Epoch 39/50 - Loss D: 1.037 | Loss G: 1.170\n",
      "Epoch 40/50 - Loss D: 1.055 | Loss G: 1.162\n",
      "Epoch 41/50 - Loss D: 1.002 | Loss G: 1.108\n",
      "Epoch 42/50 - Loss D: 1.018 | Loss G: 1.177\n",
      "Epoch 43/50 - Loss D: 1.059 | Loss G: 1.214\n",
      "Epoch 44/50 - Loss D: 1.081 | Loss G: 1.297\n",
      "Epoch 45/50 - Loss D: 1.017 | Loss G: 1.106\n",
      "Epoch 46/50 - Loss D: 1.013 | Loss G: 1.216\n",
      "Epoch 47/50 - Loss D: 1.026 | Loss G: 1.100\n",
      "Epoch 48/50 - Loss D: 1.040 | Loss G: 1.338\n",
      "Epoch 49/50 - Loss D: 1.008 | Loss G: 1.088\n",
      "Epoch 50/50 - Loss D: 1.131 | Loss G: 1.341\n",
      "\n",
      "=== Experimentos com mistura real + sintÃ©tico ===\n",
      "\n",
      "Ratio 0.00: sem dados sintÃ©ticos (apenas reais)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 0.25: 136 sintÃ©ticas no total (68 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 0.50: 273 sintÃ©ticas no total (136 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 0.75: 409 sintÃ©ticas no total (204 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 1.00: 546 sintÃ©ticas no total (273 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 1.50: 819 sintÃ©ticas no total (409 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Treino 100% sintÃ©tico â†’ Teste real ===\n",
      "Total de sintÃ©ticas geradas: 546 (273 por classe)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Treino/Teste 100% sintÃ©tico (70/30) ===\n",
      "Total: 546 (treino: 382, teste: 164)\n",
      "\n",
      "â±ï¸  Tempo da rodada 1: 1.79 min\n",
      "ðŸ•  Estimativa restante: 7.16 min (0.12 h)\n",
      "\n",
      "======================================================================\n",
      "== Rodada 2/5\n",
      "======================================================================\n",
      "[GAN] Rodada 2: treinando G_malignant e G_benign do zero | seed=1002\n",
      "Epoch 1/50 - Loss D: 0.846 | Loss G: 1.290\n",
      "Epoch 2/50 - Loss D: 0.419 | Loss G: 1.925\n",
      "Epoch 3/50 - Loss D: 0.255 | Loss G: 2.426\n",
      "Epoch 4/50 - Loss D: 0.263 | Loss G: 2.459\n",
      "Epoch 5/50 - Loss D: 0.199 | Loss G: 2.680\n",
      "Epoch 6/50 - Loss D: 0.140 | Loss G: 3.092\n",
      "Epoch 7/50 - Loss D: 0.126 | Loss G: 3.100\n",
      "Epoch 8/50 - Loss D: 0.144 | Loss G: 2.987\n",
      "Epoch 9/50 - Loss D: 0.130 | Loss G: 3.168\n",
      "Epoch 10/50 - Loss D: 0.128 | Loss G: 3.248\n",
      "Epoch 11/50 - Loss D: 0.215 | Loss G: 2.939\n",
      "Epoch 12/50 - Loss D: 0.302 | Loss G: 2.985\n",
      "Epoch 13/50 - Loss D: 0.287 | Loss G: 2.776\n",
      "Epoch 14/50 - Loss D: 0.265 | Loss G: 2.839\n",
      "Epoch 15/50 - Loss D: 0.309 | Loss G: 2.959\n",
      "Epoch 16/50 - Loss D: 0.190 | Loss G: 3.252\n",
      "Epoch 17/50 - Loss D: 0.356 | Loss G: 2.704\n",
      "Epoch 18/50 - Loss D: 0.349 | Loss G: 2.335\n",
      "Epoch 19/50 - Loss D: 0.994 | Loss G: 2.528\n",
      "Epoch 20/50 - Loss D: 0.487 | Loss G: 2.167\n",
      "Epoch 21/50 - Loss D: 0.452 | Loss G: 2.128\n",
      "Epoch 22/50 - Loss D: 0.551 | Loss G: 2.225\n",
      "Epoch 23/50 - Loss D: 0.490 | Loss G: 1.893\n",
      "Epoch 24/50 - Loss D: 1.041 | Loss G: 1.841\n",
      "Epoch 25/50 - Loss D: 0.673 | Loss G: 1.669\n",
      "Epoch 26/50 - Loss D: 0.844 | Loss G: 1.458\n",
      "Epoch 27/50 - Loss D: 0.961 | Loss G: 1.632\n",
      "Epoch 28/50 - Loss D: 0.834 | Loss G: 1.457\n",
      "Epoch 29/50 - Loss D: 0.834 | Loss G: 1.235\n",
      "Epoch 30/50 - Loss D: 0.988 | Loss G: 1.463\n",
      "Epoch 31/50 - Loss D: 0.805 | Loss G: 1.331\n",
      "Epoch 32/50 - Loss D: 0.869 | Loss G: 1.368\n",
      "Epoch 33/50 - Loss D: 0.772 | Loss G: 1.368\n",
      "Epoch 34/50 - Loss D: 1.197 | Loss G: 1.386\n",
      "Epoch 35/50 - Loss D: 1.014 | Loss G: 1.270\n",
      "Epoch 36/50 - Loss D: 0.898 | Loss G: 1.239\n",
      "Epoch 37/50 - Loss D: 0.885 | Loss G: 1.360\n",
      "Epoch 38/50 - Loss D: 0.953 | Loss G: 1.175\n",
      "Epoch 39/50 - Loss D: 0.870 | Loss G: 1.271\n",
      "Epoch 40/50 - Loss D: 0.860 | Loss G: 1.283\n",
      "Epoch 41/50 - Loss D: 0.846 | Loss G: 1.268\n",
      "Epoch 42/50 - Loss D: 0.827 | Loss G: 1.402\n",
      "Epoch 43/50 - Loss D: 0.878 | Loss G: 1.558\n",
      "Epoch 44/50 - Loss D: 1.038 | Loss G: 1.367\n",
      "Epoch 45/50 - Loss D: 0.941 | Loss G: 1.263\n",
      "Epoch 46/50 - Loss D: 0.986 | Loss G: 1.466\n",
      "Epoch 47/50 - Loss D: 0.900 | Loss G: 1.306\n",
      "Epoch 48/50 - Loss D: 0.989 | Loss G: 1.325\n",
      "Epoch 49/50 - Loss D: 0.977 | Loss G: 1.377\n",
      "Epoch 50/50 - Loss D: 0.909 | Loss G: 1.320\n",
      "Epoch 1/50 - Loss D: 1.020 | Loss G: 1.113\n",
      "Epoch 2/50 - Loss D: 0.479 | Loss G: 1.797\n",
      "Epoch 3/50 - Loss D: 0.376 | Loss G: 2.137\n",
      "Epoch 4/50 - Loss D: 0.242 | Loss G: 2.495\n",
      "Epoch 5/50 - Loss D: 0.214 | Loss G: 2.703\n",
      "Epoch 6/50 - Loss D: 0.185 | Loss G: 2.908\n",
      "Epoch 7/50 - Loss D: 0.149 | Loss G: 3.019\n",
      "Epoch 8/50 - Loss D: 0.185 | Loss G: 2.930\n",
      "Epoch 9/50 - Loss D: 0.238 | Loss G: 2.791\n",
      "Epoch 10/50 - Loss D: 0.319 | Loss G: 2.713\n",
      "Epoch 11/50 - Loss D: 0.501 | Loss G: 2.858\n",
      "Epoch 12/50 - Loss D: 0.725 | Loss G: 2.189\n",
      "Epoch 13/50 - Loss D: 0.416 | Loss G: 2.508\n",
      "Epoch 14/50 - Loss D: 0.299 | Loss G: 2.668\n",
      "Epoch 15/50 - Loss D: 0.305 | Loss G: 2.725\n",
      "Epoch 16/50 - Loss D: 0.354 | Loss G: 2.737\n",
      "Epoch 17/50 - Loss D: 0.421 | Loss G: 2.363\n",
      "Epoch 18/50 - Loss D: 0.924 | Loss G: 2.019\n",
      "Epoch 19/50 - Loss D: 0.708 | Loss G: 1.760\n",
      "Epoch 20/50 - Loss D: 0.681 | Loss G: 1.658\n",
      "Epoch 21/50 - Loss D: 0.764 | Loss G: 1.856\n",
      "Epoch 22/50 - Loss D: 0.745 | Loss G: 1.699\n",
      "Epoch 23/50 - Loss D: 0.916 | Loss G: 1.604\n",
      "Epoch 24/50 - Loss D: 0.770 | Loss G: 1.519\n",
      "Epoch 25/50 - Loss D: 0.904 | Loss G: 1.440\n",
      "Epoch 26/50 - Loss D: 0.775 | Loss G: 1.407\n",
      "Epoch 27/50 - Loss D: 0.827 | Loss G: 1.452\n",
      "Epoch 28/50 - Loss D: 0.857 | Loss G: 1.412\n",
      "Epoch 29/50 - Loss D: 0.795 | Loss G: 1.419\n",
      "Epoch 30/50 - Loss D: 0.738 | Loss G: 1.462\n",
      "Epoch 31/50 - Loss D: 0.890 | Loss G: 1.573\n",
      "Epoch 32/50 - Loss D: 0.786 | Loss G: 1.436\n",
      "Epoch 33/50 - Loss D: 0.717 | Loss G: 1.551\n",
      "Epoch 34/50 - Loss D: 0.718 | Loss G: 1.458\n",
      "Epoch 35/50 - Loss D: 0.794 | Loss G: 1.702\n",
      "Epoch 36/50 - Loss D: 1.007 | Loss G: 1.351\n",
      "Epoch 37/50 - Loss D: 0.823 | Loss G: 1.316\n",
      "Epoch 38/50 - Loss D: 0.803 | Loss G: 1.362\n",
      "Epoch 39/50 - Loss D: 0.800 | Loss G: 1.383\n",
      "Epoch 40/50 - Loss D: 0.829 | Loss G: 1.390\n",
      "Epoch 41/50 - Loss D: 1.050 | Loss G: 1.552\n",
      "Epoch 42/50 - Loss D: 0.846 | Loss G: 1.332\n",
      "Epoch 43/50 - Loss D: 0.792 | Loss G: 1.510\n",
      "Epoch 44/50 - Loss D: 0.812 | Loss G: 1.397\n",
      "Epoch 45/50 - Loss D: 0.832 | Loss G: 1.446\n",
      "Epoch 46/50 - Loss D: 0.813 | Loss G: 1.524\n",
      "Epoch 47/50 - Loss D: 0.813 | Loss G: 1.362\n",
      "Epoch 48/50 - Loss D: 0.727 | Loss G: 1.481\n",
      "Epoch 49/50 - Loss D: 0.741 | Loss G: 1.577\n",
      "Epoch 50/50 - Loss D: 0.814 | Loss G: 1.268\n",
      "\n",
      "=== Experimentos com mistura real + sintÃ©tico ===\n",
      "\n",
      "Ratio 0.00: sem dados sintÃ©ticos (apenas reais)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 0.25: 136 sintÃ©ticas no total (68 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 0.50: 273 sintÃ©ticas no total (136 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 0.75: 409 sintÃ©ticas no total (204 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 1.00: 546 sintÃ©ticas no total (273 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 1.50: 819 sintÃ©ticas no total (409 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Treino 100% sintÃ©tico â†’ Teste real ===\n",
      "Total de sintÃ©ticas geradas: 546 (273 por classe)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Treino/Teste 100% sintÃ©tico (70/30) ===\n",
      "Total: 546 (treino: 382, teste: 164)\n",
      "\n",
      "â±ï¸  Tempo da rodada 2: 1.75 min\n",
      "ðŸ•  Estimativa restante: 5.26 min (0.09 h)\n",
      "\n",
      "======================================================================\n",
      "== Rodada 3/5\n",
      "======================================================================\n",
      "[GAN] Rodada 3: treinando G_malignant e G_benign do zero | seed=1003\n",
      "Epoch 1/50 - Loss D: 0.918 | Loss G: 1.113\n",
      "Epoch 2/50 - Loss D: 0.492 | Loss G: 1.731\n",
      "Epoch 3/50 - Loss D: 0.320 | Loss G: 2.171\n",
      "Epoch 4/50 - Loss D: 0.282 | Loss G: 2.414\n",
      "Epoch 5/50 - Loss D: 0.239 | Loss G: 2.459\n",
      "Epoch 6/50 - Loss D: 0.197 | Loss G: 2.676\n",
      "Epoch 7/50 - Loss D: 0.154 | Loss G: 2.920\n",
      "Epoch 8/50 - Loss D: 0.143 | Loss G: 3.022\n",
      "Epoch 9/50 - Loss D: 0.163 | Loss G: 2.923\n",
      "Epoch 10/50 - Loss D: 0.188 | Loss G: 2.883\n",
      "Epoch 11/50 - Loss D: 0.208 | Loss G: 2.890\n",
      "Epoch 12/50 - Loss D: 0.318 | Loss G: 3.029\n",
      "Epoch 13/50 - Loss D: 0.253 | Loss G: 2.912\n",
      "Epoch 14/50 - Loss D: 0.209 | Loss G: 2.987\n",
      "Epoch 15/50 - Loss D: 0.516 | Loss G: 2.684\n",
      "Epoch 16/50 - Loss D: 1.134 | Loss G: 2.249\n",
      "Epoch 17/50 - Loss D: 0.458 | Loss G: 2.210\n",
      "Epoch 18/50 - Loss D: 0.462 | Loss G: 2.187\n",
      "Epoch 19/50 - Loss D: 0.460 | Loss G: 2.144\n",
      "Epoch 20/50 - Loss D: 0.401 | Loss G: 2.180\n",
      "Epoch 21/50 - Loss D: 0.433 | Loss G: 2.532\n",
      "Epoch 22/50 - Loss D: 0.978 | Loss G: 1.783\n",
      "Epoch 23/50 - Loss D: 0.549 | Loss G: 1.941\n",
      "Epoch 24/50 - Loss D: 0.504 | Loss G: 2.087\n",
      "Epoch 25/50 - Loss D: 0.851 | Loss G: 1.981\n",
      "Epoch 26/50 - Loss D: 0.919 | Loss G: 1.564\n",
      "Epoch 27/50 - Loss D: 0.808 | Loss G: 1.420\n",
      "Epoch 28/50 - Loss D: 0.825 | Loss G: 1.450\n",
      "Epoch 29/50 - Loss D: 1.084 | Loss G: 1.436\n",
      "Epoch 30/50 - Loss D: 0.972 | Loss G: 1.196\n",
      "Epoch 31/50 - Loss D: 0.868 | Loss G: 1.335\n",
      "Epoch 32/50 - Loss D: 0.920 | Loss G: 1.399\n",
      "Epoch 33/50 - Loss D: 0.910 | Loss G: 1.324\n",
      "Epoch 34/50 - Loss D: 0.978 | Loss G: 1.391\n",
      "Epoch 35/50 - Loss D: 0.977 | Loss G: 1.159\n",
      "Epoch 36/50 - Loss D: 0.976 | Loss G: 1.272\n",
      "Epoch 37/50 - Loss D: 0.896 | Loss G: 1.192\n",
      "Epoch 38/50 - Loss D: 0.995 | Loss G: 1.426\n",
      "Epoch 39/50 - Loss D: 0.960 | Loss G: 1.096\n",
      "Epoch 40/50 - Loss D: 1.070 | Loss G: 1.306\n",
      "Epoch 41/50 - Loss D: 1.037 | Loss G: 1.234\n",
      "Epoch 42/50 - Loss D: 1.011 | Loss G: 1.203\n",
      "Epoch 43/50 - Loss D: 1.045 | Loss G: 1.209\n",
      "Epoch 44/50 - Loss D: 0.941 | Loss G: 1.224\n",
      "Epoch 45/50 - Loss D: 0.933 | Loss G: 1.223\n",
      "Epoch 46/50 - Loss D: 0.974 | Loss G: 1.284\n",
      "Epoch 47/50 - Loss D: 0.921 | Loss G: 1.222\n",
      "Epoch 48/50 - Loss D: 1.050 | Loss G: 1.264\n",
      "Epoch 49/50 - Loss D: 1.011 | Loss G: 1.298\n",
      "Epoch 50/50 - Loss D: 0.876 | Loss G: 1.305\n",
      "Epoch 1/50 - Loss D: 1.008 | Loss G: 1.166\n",
      "Epoch 2/50 - Loss D: 0.530 | Loss G: 1.826\n",
      "Epoch 3/50 - Loss D: 0.373 | Loss G: 2.259\n",
      "Epoch 4/50 - Loss D: 0.261 | Loss G: 2.542\n",
      "Epoch 5/50 - Loss D: 0.185 | Loss G: 2.820\n",
      "Epoch 6/50 - Loss D: 0.145 | Loss G: 3.018\n",
      "Epoch 7/50 - Loss D: 0.096 | Loss G: 3.338\n",
      "Epoch 8/50 - Loss D: 0.108 | Loss G: 3.429\n",
      "Epoch 9/50 - Loss D: 0.174 | Loss G: 3.382\n",
      "Epoch 10/50 - Loss D: 0.151 | Loss G: 3.499\n",
      "Epoch 11/50 - Loss D: 0.086 | Loss G: 3.989\n",
      "Epoch 12/50 - Loss D: 0.049 | Loss G: 4.154\n",
      "Epoch 13/50 - Loss D: 0.045 | Loss G: 4.363\n",
      "Epoch 14/50 - Loss D: 0.037 | Loss G: 4.433\n",
      "Epoch 15/50 - Loss D: 0.028 | Loss G: 4.704\n",
      "Epoch 16/50 - Loss D: 0.021 | Loss G: 4.982\n",
      "Epoch 17/50 - Loss D: 0.018 | Loss G: 5.119\n",
      "Epoch 18/50 - Loss D: 0.016 | Loss G: 5.185\n",
      "Epoch 19/50 - Loss D: 0.016 | Loss G: 5.221\n",
      "Epoch 20/50 - Loss D: 0.021 | Loss G: 4.929\n",
      "Epoch 21/50 - Loss D: 0.115 | Loss G: 4.369\n",
      "Epoch 22/50 - Loss D: 0.075 | Loss G: 4.289\n",
      "Epoch 23/50 - Loss D: 0.035 | Loss G: 4.710\n",
      "Epoch 24/50 - Loss D: 0.023 | Loss G: 5.076\n",
      "Epoch 25/50 - Loss D: 0.018 | Loss G: 5.389\n",
      "Epoch 26/50 - Loss D: 0.015 | Loss G: 5.606\n",
      "Epoch 27/50 - Loss D: 0.012 | Loss G: 5.774\n",
      "Epoch 28/50 - Loss D: 0.011 | Loss G: 5.856\n",
      "Epoch 29/50 - Loss D: 0.009 | Loss G: 5.923\n",
      "Epoch 30/50 - Loss D: 0.010 | Loss G: 5.892\n",
      "Epoch 31/50 - Loss D: 0.069 | Loss G: 4.622\n",
      "Epoch 32/50 - Loss D: 0.144 | Loss G: 3.793\n",
      "Epoch 33/50 - Loss D: 0.983 | Loss G: 3.231\n",
      "Epoch 34/50 - Loss D: 0.530 | Loss G: 2.885\n",
      "Epoch 35/50 - Loss D: 0.755 | Loss G: 2.321\n",
      "Epoch 36/50 - Loss D: 0.497 | Loss G: 2.600\n",
      "Epoch 37/50 - Loss D: 0.388 | Loss G: 2.362\n",
      "Epoch 38/50 - Loss D: 0.326 | Loss G: 2.547\n",
      "Epoch 39/50 - Loss D: 0.832 | Loss G: 2.410\n",
      "Epoch 40/50 - Loss D: 0.541 | Loss G: 1.968\n",
      "Epoch 41/50 - Loss D: 0.569 | Loss G: 1.879\n",
      "Epoch 42/50 - Loss D: 0.648 | Loss G: 1.699\n",
      "Epoch 43/50 - Loss D: 0.855 | Loss G: 1.643\n",
      "Epoch 44/50 - Loss D: 0.785 | Loss G: 1.549\n",
      "Epoch 45/50 - Loss D: 0.756 | Loss G: 1.579\n",
      "Epoch 46/50 - Loss D: 0.857 | Loss G: 1.453\n",
      "Epoch 47/50 - Loss D: 0.871 | Loss G: 1.357\n",
      "Epoch 48/50 - Loss D: 0.952 | Loss G: 1.455\n",
      "Epoch 49/50 - Loss D: 0.905 | Loss G: 1.421\n",
      "Epoch 50/50 - Loss D: 0.829 | Loss G: 1.286\n",
      "\n",
      "=== Experimentos com mistura real + sintÃ©tico ===\n",
      "\n",
      "Ratio 0.00: sem dados sintÃ©ticos (apenas reais)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 0.25: 136 sintÃ©ticas no total (68 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 0.50: 273 sintÃ©ticas no total (136 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 0.75: 409 sintÃ©ticas no total (204 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 1.00: 546 sintÃ©ticas no total (273 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 1.50: 819 sintÃ©ticas no total (409 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Treino 100% sintÃ©tico â†’ Teste real ===\n",
      "Total de sintÃ©ticas geradas: 546 (273 por classe)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Treino/Teste 100% sintÃ©tico (70/30) ===\n",
      "Total: 546 (treino: 382, teste: 164)\n",
      "\n",
      "â±ï¸  Tempo da rodada 3: 1.74 min\n",
      "ðŸ•  Estimativa restante: 3.48 min (0.06 h)\n",
      "\n",
      "======================================================================\n",
      "== Rodada 4/5\n",
      "======================================================================\n",
      "[GAN] Rodada 4: treinando G_malignant e G_benign do zero | seed=1004\n",
      "Epoch 1/50 - Loss D: 0.919 | Loss G: 1.215\n",
      "Epoch 2/50 - Loss D: 0.354 | Loss G: 2.053\n",
      "Epoch 3/50 - Loss D: 0.240 | Loss G: 2.470\n",
      "Epoch 4/50 - Loss D: 0.156 | Loss G: 3.115\n",
      "Epoch 5/50 - Loss D: 0.124 | Loss G: 3.064\n",
      "Epoch 6/50 - Loss D: 0.073 | Loss G: 3.716\n",
      "Epoch 7/50 - Loss D: 0.051 | Loss G: 4.025\n",
      "Epoch 8/50 - Loss D: 0.050 | Loss G: 3.949\n",
      "Epoch 9/50 - Loss D: 0.062 | Loss G: 3.977\n",
      "Epoch 10/50 - Loss D: 0.046 | Loss G: 3.945\n",
      "Epoch 11/50 - Loss D: 0.037 | Loss G: 4.198\n",
      "Epoch 12/50 - Loss D: 0.028 | Loss G: 4.568\n",
      "Epoch 13/50 - Loss D: 0.025 | Loss G: 4.662\n",
      "Epoch 14/50 - Loss D: 0.019 | Loss G: 4.870\n",
      "Epoch 15/50 - Loss D: 0.016 | Loss G: 5.072\n",
      "Epoch 16/50 - Loss D: 0.014 | Loss G: 5.175\n",
      "Epoch 17/50 - Loss D: 0.012 | Loss G: 5.255\n",
      "Epoch 18/50 - Loss D: 0.012 | Loss G: 5.338\n",
      "Epoch 19/50 - Loss D: 0.011 | Loss G: 5.340\n",
      "Epoch 20/50 - Loss D: 0.010 | Loss G: 5.447\n",
      "Epoch 21/50 - Loss D: 0.128 | Loss G: 5.028\n",
      "Epoch 22/50 - Loss D: 0.065 | Loss G: 4.251\n",
      "Epoch 23/50 - Loss D: 0.108 | Loss G: 4.016\n",
      "Epoch 24/50 - Loss D: 0.169 | Loss G: 3.485\n",
      "Epoch 25/50 - Loss D: 0.210 | Loss G: 3.875\n",
      "Epoch 26/50 - Loss D: 0.455 | Loss G: 4.296\n",
      "Epoch 27/50 - Loss D: 0.296 | Loss G: 3.245\n",
      "Epoch 28/50 - Loss D: 0.240 | Loss G: 3.805\n",
      "Epoch 29/50 - Loss D: 0.135 | Loss G: 3.506\n",
      "Epoch 30/50 - Loss D: 0.094 | Loss G: 3.815\n",
      "Epoch 31/50 - Loss D: 0.098 | Loss G: 3.820\n",
      "Epoch 32/50 - Loss D: 0.246 | Loss G: 3.143\n",
      "Epoch 33/50 - Loss D: 0.416 | Loss G: 3.367\n",
      "Epoch 34/50 - Loss D: 0.521 | Loss G: 2.872\n",
      "Epoch 35/50 - Loss D: 0.363 | Loss G: 2.962\n",
      "Epoch 36/50 - Loss D: 0.466 | Loss G: 2.860\n",
      "Epoch 37/50 - Loss D: 0.624 | Loss G: 2.068\n",
      "Epoch 38/50 - Loss D: 0.384 | Loss G: 2.409\n",
      "Epoch 39/50 - Loss D: 0.541 | Loss G: 2.342\n",
      "Epoch 40/50 - Loss D: 0.838 | Loss G: 2.234\n",
      "Epoch 41/50 - Loss D: 0.586 | Loss G: 1.806\n",
      "Epoch 42/50 - Loss D: 0.541 | Loss G: 1.850\n",
      "Epoch 43/50 - Loss D: 0.948 | Loss G: 1.946\n",
      "Epoch 44/50 - Loss D: 0.787 | Loss G: 1.460\n",
      "Epoch 45/50 - Loss D: 0.949 | Loss G: 1.566\n",
      "Epoch 46/50 - Loss D: 0.743 | Loss G: 1.688\n",
      "Epoch 47/50 - Loss D: 0.563 | Loss G: 1.800\n",
      "Epoch 48/50 - Loss D: 0.797 | Loss G: 1.638\n",
      "Epoch 49/50 - Loss D: 0.763 | Loss G: 1.720\n",
      "Epoch 50/50 - Loss D: 0.624 | Loss G: 1.686\n",
      "Epoch 1/50 - Loss D: 0.928 | Loss G: 1.210\n",
      "Epoch 2/50 - Loss D: 0.519 | Loss G: 1.785\n",
      "Epoch 3/50 - Loss D: 0.372 | Loss G: 2.177\n",
      "Epoch 4/50 - Loss D: 0.303 | Loss G: 2.365\n",
      "Epoch 5/50 - Loss D: 0.261 | Loss G: 2.493\n",
      "Epoch 6/50 - Loss D: 0.242 | Loss G: 2.559\n",
      "Epoch 7/50 - Loss D: 0.235 | Loss G: 2.635\n",
      "Epoch 8/50 - Loss D: 0.220 | Loss G: 2.800\n",
      "Epoch 9/50 - Loss D: 0.226 | Loss G: 2.769\n",
      "Epoch 10/50 - Loss D: 0.361 | Loss G: 2.588\n",
      "Epoch 11/50 - Loss D: 0.506 | Loss G: 2.754\n",
      "Epoch 12/50 - Loss D: 0.433 | Loss G: 2.568\n",
      "Epoch 13/50 - Loss D: 0.416 | Loss G: 2.486\n",
      "Epoch 14/50 - Loss D: 0.410 | Loss G: 2.336\n",
      "Epoch 15/50 - Loss D: 0.423 | Loss G: 2.534\n",
      "Epoch 16/50 - Loss D: 0.459 | Loss G: 2.626\n",
      "Epoch 17/50 - Loss D: 0.899 | Loss G: 1.938\n",
      "Epoch 18/50 - Loss D: 0.638 | Loss G: 1.723\n",
      "Epoch 19/50 - Loss D: 0.878 | Loss G: 1.798\n",
      "Epoch 20/50 - Loss D: 0.741 | Loss G: 1.549\n",
      "Epoch 21/50 - Loss D: 0.706 | Loss G: 1.792\n",
      "Epoch 22/50 - Loss D: 1.043 | Loss G: 1.591\n",
      "Epoch 23/50 - Loss D: 0.877 | Loss G: 1.383\n",
      "Epoch 24/50 - Loss D: 0.840 | Loss G: 1.358\n",
      "Epoch 25/50 - Loss D: 0.855 | Loss G: 1.324\n",
      "Epoch 26/50 - Loss D: 0.906 | Loss G: 1.419\n",
      "Epoch 27/50 - Loss D: 1.087 | Loss G: 1.194\n",
      "Epoch 28/50 - Loss D: 1.027 | Loss G: 1.148\n",
      "Epoch 29/50 - Loss D: 0.977 | Loss G: 1.201\n",
      "Epoch 30/50 - Loss D: 0.987 | Loss G: 1.142\n",
      "Epoch 31/50 - Loss D: 1.304 | Loss G: 1.348\n",
      "Epoch 32/50 - Loss D: 1.119 | Loss G: 1.130\n",
      "Epoch 33/50 - Loss D: 1.096 | Loss G: 1.063\n",
      "Epoch 34/50 - Loss D: 1.010 | Loss G: 1.153\n",
      "Epoch 35/50 - Loss D: 0.960 | Loss G: 1.214\n",
      "Epoch 36/50 - Loss D: 1.029 | Loss G: 1.222\n",
      "Epoch 37/50 - Loss D: 1.029 | Loss G: 1.235\n",
      "Epoch 38/50 - Loss D: 1.027 | Loss G: 1.160\n",
      "Epoch 39/50 - Loss D: 1.015 | Loss G: 1.218\n",
      "Epoch 40/50 - Loss D: 0.998 | Loss G: 1.204\n",
      "Epoch 41/50 - Loss D: 1.040 | Loss G: 1.291\n",
      "Epoch 42/50 - Loss D: 1.195 | Loss G: 1.085\n",
      "Epoch 43/50 - Loss D: 1.069 | Loss G: 1.039\n",
      "Epoch 44/50 - Loss D: 1.256 | Loss G: 1.126\n",
      "Epoch 45/50 - Loss D: 1.133 | Loss G: 1.032\n",
      "Epoch 46/50 - Loss D: 1.103 | Loss G: 1.246\n",
      "Epoch 47/50 - Loss D: 1.196 | Loss G: 1.105\n",
      "Epoch 48/50 - Loss D: 1.129 | Loss G: 1.020\n",
      "Epoch 49/50 - Loss D: 1.078 | Loss G: 1.027\n",
      "Epoch 50/50 - Loss D: 1.061 | Loss G: 1.092\n",
      "\n",
      "=== Experimentos com mistura real + sintÃ©tico ===\n",
      "\n",
      "Ratio 0.00: sem dados sintÃ©ticos (apenas reais)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 0.25: 136 sintÃ©ticas no total (68 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 0.50: 273 sintÃ©ticas no total (136 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 0.75: 409 sintÃ©ticas no total (204 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 1.00: 546 sintÃ©ticas no total (273 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 1.50: 819 sintÃ©ticas no total (409 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Treino 100% sintÃ©tico â†’ Teste real ===\n",
      "Total de sintÃ©ticas geradas: 546 (273 por classe)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Treino/Teste 100% sintÃ©tico (70/30) ===\n",
      "Total: 546 (treino: 382, teste: 164)\n",
      "\n",
      "â±ï¸  Tempo da rodada 4: 1.75 min\n",
      "ðŸ•  Estimativa restante: 1.75 min (0.03 h)\n",
      "\n",
      "======================================================================\n",
      "== Rodada 5/5\n",
      "======================================================================\n",
      "[GAN] Rodada 5: treinando G_malignant e G_benign do zero | seed=1005\n",
      "Epoch 1/50 - Loss D: 0.837 | Loss G: 1.242\n",
      "Epoch 2/50 - Loss D: 0.435 | Loss G: 1.863\n",
      "Epoch 3/50 - Loss D: 0.312 | Loss G: 2.222\n",
      "Epoch 4/50 - Loss D: 0.285 | Loss G: 2.549\n",
      "Epoch 5/50 - Loss D: 0.236 | Loss G: 2.521\n",
      "Epoch 6/50 - Loss D: 0.155 | Loss G: 2.933\n",
      "Epoch 7/50 - Loss D: 0.155 | Loss G: 2.901\n",
      "Epoch 8/50 - Loss D: 0.156 | Loss G: 3.008\n",
      "Epoch 9/50 - Loss D: 0.163 | Loss G: 3.047\n",
      "Epoch 10/50 - Loss D: 0.185 | Loss G: 2.917\n",
      "Epoch 11/50 - Loss D: 0.194 | Loss G: 3.148\n",
      "Epoch 12/50 - Loss D: 0.246 | Loss G: 3.230\n",
      "Epoch 13/50 - Loss D: 0.245 | Loss G: 2.710\n",
      "Epoch 14/50 - Loss D: 0.294 | Loss G: 2.960\n",
      "Epoch 15/50 - Loss D: 0.232 | Loss G: 2.810\n",
      "Epoch 16/50 - Loss D: 0.360 | Loss G: 3.109\n",
      "Epoch 17/50 - Loss D: 0.442 | Loss G: 2.761\n",
      "Epoch 18/50 - Loss D: 0.301 | Loss G: 2.822\n",
      "Epoch 19/50 - Loss D: 0.270 | Loss G: 2.548\n",
      "Epoch 20/50 - Loss D: 0.559 | Loss G: 2.661\n",
      "Epoch 21/50 - Loss D: 0.572 | Loss G: 2.500\n",
      "Epoch 22/50 - Loss D: 0.379 | Loss G: 2.255\n",
      "Epoch 23/50 - Loss D: 0.492 | Loss G: 2.141\n",
      "Epoch 24/50 - Loss D: 0.476 | Loss G: 2.584\n",
      "Epoch 25/50 - Loss D: 0.730 | Loss G: 2.115\n",
      "Epoch 26/50 - Loss D: 0.713 | Loss G: 1.612\n",
      "Epoch 27/50 - Loss D: 0.680 | Loss G: 1.779\n",
      "Epoch 28/50 - Loss D: 0.612 | Loss G: 1.761\n",
      "Epoch 29/50 - Loss D: 0.869 | Loss G: 1.426\n",
      "Epoch 30/50 - Loss D: 0.685 | Loss G: 1.627\n",
      "Epoch 31/50 - Loss D: 0.677 | Loss G: 1.496\n",
      "Epoch 32/50 - Loss D: 0.740 | Loss G: 1.534\n",
      "Epoch 33/50 - Loss D: 1.020 | Loss G: 1.540\n",
      "Epoch 34/50 - Loss D: 0.869 | Loss G: 1.529\n",
      "Epoch 35/50 - Loss D: 0.723 | Loss G: 1.442\n",
      "Epoch 36/50 - Loss D: 0.692 | Loss G: 1.642\n",
      "Epoch 37/50 - Loss D: 0.735 | Loss G: 1.888\n",
      "Epoch 38/50 - Loss D: 0.846 | Loss G: 1.861\n",
      "Epoch 39/50 - Loss D: 0.889 | Loss G: 1.396\n",
      "Epoch 40/50 - Loss D: 0.608 | Loss G: 1.811\n",
      "Epoch 41/50 - Loss D: 0.579 | Loss G: 1.847\n",
      "Epoch 42/50 - Loss D: 0.664 | Loss G: 1.808\n",
      "Epoch 43/50 - Loss D: 0.868 | Loss G: 1.734\n",
      "Epoch 44/50 - Loss D: 0.830 | Loss G: 1.526\n",
      "Epoch 45/50 - Loss D: 0.855 | Loss G: 1.645\n",
      "Epoch 46/50 - Loss D: 0.646 | Loss G: 1.737\n",
      "Epoch 47/50 - Loss D: 0.710 | Loss G: 1.764\n",
      "Epoch 48/50 - Loss D: 0.598 | Loss G: 1.867\n",
      "Epoch 49/50 - Loss D: 1.011 | Loss G: 1.684\n",
      "Epoch 50/50 - Loss D: 1.015 | Loss G: 1.349\n",
      "Epoch 1/50 - Loss D: 1.087 | Loss G: 1.138\n",
      "Epoch 2/50 - Loss D: 0.460 | Loss G: 1.919\n",
      "Epoch 3/50 - Loss D: 0.267 | Loss G: 2.514\n",
      "Epoch 4/50 - Loss D: 0.173 | Loss G: 2.861\n",
      "Epoch 5/50 - Loss D: 0.256 | Loss G: 2.622\n",
      "Epoch 6/50 - Loss D: 0.211 | Loss G: 3.122\n",
      "Epoch 7/50 - Loss D: 0.137 | Loss G: 3.500\n",
      "Epoch 8/50 - Loss D: 0.129 | Loss G: 3.364\n",
      "Epoch 9/50 - Loss D: 0.109 | Loss G: 3.610\n",
      "Epoch 10/50 - Loss D: 0.123 | Loss G: 3.411\n",
      "Epoch 11/50 - Loss D: 0.108 | Loss G: 3.665\n",
      "Epoch 12/50 - Loss D: 0.178 | Loss G: 3.625\n",
      "Epoch 13/50 - Loss D: 0.162 | Loss G: 3.655\n",
      "Epoch 14/50 - Loss D: 0.117 | Loss G: 3.882\n",
      "Epoch 15/50 - Loss D: 0.220 | Loss G: 3.525\n",
      "Epoch 16/50 - Loss D: 0.277 | Loss G: 3.383\n",
      "Epoch 17/50 - Loss D: 0.420 | Loss G: 3.221\n",
      "Epoch 18/50 - Loss D: 0.356 | Loss G: 3.150\n",
      "Epoch 19/50 - Loss D: 0.242 | Loss G: 2.990\n",
      "Epoch 20/50 - Loss D: 0.150 | Loss G: 3.395\n",
      "Epoch 21/50 - Loss D: 0.152 | Loss G: 3.320\n",
      "Epoch 22/50 - Loss D: 0.313 | Loss G: 3.352\n",
      "Epoch 23/50 - Loss D: 0.637 | Loss G: 2.452\n",
      "Epoch 24/50 - Loss D: 0.688 | Loss G: 2.527\n",
      "Epoch 25/50 - Loss D: 0.456 | Loss G: 2.419\n",
      "Epoch 26/50 - Loss D: 0.557 | Loss G: 2.125\n",
      "Epoch 27/50 - Loss D: 0.550 | Loss G: 2.032\n",
      "Epoch 28/50 - Loss D: 0.873 | Loss G: 1.859\n",
      "Epoch 29/50 - Loss D: 0.557 | Loss G: 1.999\n",
      "Epoch 30/50 - Loss D: 0.549 | Loss G: 1.775\n",
      "Epoch 31/50 - Loss D: 0.928 | Loss G: 1.967\n",
      "Epoch 32/50 - Loss D: 0.651 | Loss G: 1.687\n",
      "Epoch 33/50 - Loss D: 0.801 | Loss G: 1.505\n",
      "Epoch 34/50 - Loss D: 0.706 | Loss G: 1.474\n",
      "Epoch 35/50 - Loss D: 0.882 | Loss G: 1.578\n",
      "Epoch 36/50 - Loss D: 0.743 | Loss G: 1.516\n",
      "Epoch 37/50 - Loss D: 0.788 | Loss G: 1.556\n",
      "Epoch 38/50 - Loss D: 0.732 | Loss G: 1.545\n",
      "Epoch 39/50 - Loss D: 0.807 | Loss G: 1.534\n",
      "Epoch 40/50 - Loss D: 0.974 | Loss G: 1.335\n",
      "Epoch 41/50 - Loss D: 0.875 | Loss G: 1.279\n",
      "Epoch 42/50 - Loss D: 0.829 | Loss G: 1.288\n",
      "Epoch 43/50 - Loss D: 0.772 | Loss G: 1.327\n",
      "Epoch 44/50 - Loss D: 1.015 | Loss G: 1.636\n",
      "Epoch 45/50 - Loss D: 0.902 | Loss G: 1.194\n",
      "Epoch 46/50 - Loss D: 0.811 | Loss G: 1.296\n",
      "Epoch 47/50 - Loss D: 0.775 | Loss G: 1.459\n",
      "Epoch 48/50 - Loss D: 0.813 | Loss G: 1.581\n",
      "Epoch 49/50 - Loss D: 0.925 | Loss G: 1.358\n",
      "Epoch 50/50 - Loss D: 0.843 | Loss G: 1.267\n",
      "\n",
      "=== Experimentos com mistura real + sintÃ©tico ===\n",
      "\n",
      "Ratio 0.00: sem dados sintÃ©ticos (apenas reais)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 0.25: 136 sintÃ©ticas no total (68 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 0.50: 273 sintÃ©ticas no total (136 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 0.75: 409 sintÃ©ticas no total (204 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 1.00: 546 sintÃ©ticas no total (273 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 1.50: 819 sintÃ©ticas no total (409 por classe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Treino 100% sintÃ©tico â†’ Teste real ===\n",
      "Total de sintÃ©ticas geradas: 546 (273 por classe)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Treino/Teste 100% sintÃ©tico (70/30) ===\n",
      "Total: 546 (treino: 382, teste: 164)\n",
      "\n",
      "â±ï¸  Tempo da rodada 5: 1.76 min\n",
      "ðŸ•  Estimativa restante: 0.00 min (0.00 h)\n",
      "\n",
      "======================================================================\n",
      "âœ… Todas as 5 rodadas concluÃ­das.\n",
      "â±ï¸  Tempo total: 8.79 min (0.15 h)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "=== resumo (mÃ©dia e desvio por ratio) ===\n",
      "                           ratio  acc_mean   acc_std  prec_mean  prec_std  \\\n",
      "0                            0.0  0.753846  0.049984   0.788377  0.055047   \n",
      "1                           0.25  0.765385  0.082665   0.902748  0.031484   \n",
      "2                            0.5  0.812821  0.029861   0.857192  0.047165   \n",
      "3                           0.75  0.815385  0.029515   0.835554  0.033658   \n",
      "4                            1.0  0.797436  0.034698   0.822283  0.049157   \n",
      "5                            1.5  0.814103  0.039255   0.855787  0.055347   \n",
      "6  100%_sintÃ©tico_70/30_selftest  0.987805  0.012195   0.987540  0.022341   \n",
      "7            100%_sintÃ©ticoâ†’real  0.676923  0.076468   0.778035  0.046580   \n",
      "\n",
      "   rec_mean   rec_std   f1_mean    f1_std  auc_mean   auc_std  tn_mean  \\\n",
      "0  0.915789  0.078360  0.844403  0.033128  0.615038  0.100021     13.2   \n",
      "1  0.766667  0.151503  0.819707  0.087994  0.764286  0.027758     32.0   \n",
      "2  0.900000  0.084956  0.874276  0.027122  0.738095  0.056608     24.2   \n",
      "3  0.933333  0.041424  0.880806  0.018864  0.714286  0.058590     20.8   \n",
      "4  0.929825  0.050771  0.870653  0.016741  0.683960  0.093443     18.4   \n",
      "5  0.905263  0.084000  0.876106  0.030271  0.735965  0.080995     23.8   \n",
      "6  0.990877  0.014679  0.989002  0.010654  0.987105  0.013620     76.6   \n",
      "7  0.798246  0.193580  0.772988  0.091950  0.572932  0.055480     14.6   \n",
      "\n",
      "      tn_std  fp_mean     fp_std  fn_mean     fn_std  tp_mean     tp_std  \n",
      "0  10.281051     28.8  10.281051      9.6   8.933085    104.4   8.933085  \n",
      "1   4.636809     10.0   4.636809     26.6  17.271364     87.4  17.271364  \n",
      "2   7.596052     17.8   7.596052     11.4   9.685040    102.6   9.685040  \n",
      "3   5.848077     21.2   5.848077      7.6   4.722288    106.4   4.722288  \n",
      "4   9.633276     23.6   9.633276      8.0   5.787918    106.0   5.787918  \n",
      "5   9.230385     18.2   9.230385     10.8   9.576012    103.2   9.576012  \n",
      "6   8.905055      1.2   2.167948      0.8   1.303840     85.4   7.469940  \n",
      "7  11.436783     27.4  11.436783     23.0  22.068076     91.0  22.068076  \n"
     ]
    }
   ],
   "source": [
    "import os, random, numpy as np, torch\n",
    "\n",
    "def _seed_everything(seed: int):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def make_generators_fn_factory(train_loader, latent_dim: int, gan_epochs: int = 50, device: str | None = None):\n",
    "    \"\"\"\n",
    "    Retorna uma funÃ§Ã£o make_generators_fn(run_id) que:\n",
    "      - seta uma seed por rodada\n",
    "      - instancia G/D do zero para cada classe\n",
    "      - treina cada GAN com seu train_gan_for_class\n",
    "      - devolve {\"malignant\": G0, \"benign\": G1} em .eval()\n",
    "    \"\"\"\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def make_generators_fn(run_id: int):\n",
    "        seed = 1000 + run_id\n",
    "        print(f\"[GAN] Rodada {run_id}: treinando G_malignant e G_benign do zero | seed={seed}\")\n",
    "        _seed_everything(seed)\n",
    "\n",
    "        # classe 0 (malignant)\n",
    "        G_mal = DCGenerator(latent_dim=latent_dim).to(device)\n",
    "        D_mal = DCDiscriminator(img_channels=1).to(device)\n",
    "        G_mal = train_gan_for_class(\n",
    "            train_loader=train_loader,\n",
    "            label_target=0,\n",
    "            G=G_mal, D=D_mal,\n",
    "            latent_dim=latent_dim,\n",
    "            num_epochs=gan_epochs,\n",
    "            device=device\n",
    "        ).eval()\n",
    "\n",
    "        # classe 1 (benign)\n",
    "        G_ben = DCGenerator(latent_dim=latent_dim).to(device)\n",
    "        D_ben = DCDiscriminator(img_channels=1).to(device)\n",
    "        G_ben = train_gan_for_class(\n",
    "            train_loader=train_loader,\n",
    "            label_target=1,\n",
    "            G=G_ben, D=D_ben,\n",
    "            latent_dim=latent_dim,\n",
    "            num_epochs=gan_epochs,\n",
    "            device=device\n",
    "        ).eval()\n",
    "\n",
    "        # retornamos sÃ³ os GERADORES (em eval)\n",
    "        return {\"malignant\": G_mal, \"benign\": G_ben}\n",
    "\n",
    "    return make_generators_fn\n",
    "\n",
    "make_generators_fn = make_generators_fn_factory(\n",
    "    train_loader=train_loader,   # mesmo loader que vocÃª jÃ¡ usa para treinar as GANs\n",
    "    latent_dim=latent_dim,\n",
    "    gan_epochs=50,               # ajuste se quiser mais/menos Ã©pocas por rodada\n",
    "    device=None\n",
    ")\n",
    "\n",
    "# Agora cada rodada vai TREINAR uma nova dupla de geradores do zero\n",
    "df_all, df_summary = run_k_times(\n",
    "    k=5,\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    make_generators_fn=make_generators_fn,\n",
    "    latent_dim=latent_dim,\n",
    "    batch_size=32,\n",
    "    epochs=5,\n",
    "    device=None\n",
    ")\n",
    "\n",
    "print(\"\\n=== resumo (mÃ©dia e desvio por ratio) ===\")\n",
    "print(df_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratio</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>prec_mean</th>\n",
       "      <th>prec_std</th>\n",
       "      <th>rec_mean</th>\n",
       "      <th>rec_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>tn_mean</th>\n",
       "      <th>tn_std</th>\n",
       "      <th>fp_mean</th>\n",
       "      <th>fp_std</th>\n",
       "      <th>fn_mean</th>\n",
       "      <th>fn_std</th>\n",
       "      <th>tp_mean</th>\n",
       "      <th>tp_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.049984</td>\n",
       "      <td>0.788377</td>\n",
       "      <td>0.055047</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.078360</td>\n",
       "      <td>0.844403</td>\n",
       "      <td>0.033128</td>\n",
       "      <td>0.615038</td>\n",
       "      <td>0.100021</td>\n",
       "      <td>13.2</td>\n",
       "      <td>10.281051</td>\n",
       "      <td>28.8</td>\n",
       "      <td>10.281051</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.933085</td>\n",
       "      <td>104.4</td>\n",
       "      <td>8.933085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.765385</td>\n",
       "      <td>0.082665</td>\n",
       "      <td>0.902748</td>\n",
       "      <td>0.031484</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.151503</td>\n",
       "      <td>0.819707</td>\n",
       "      <td>0.087994</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>0.027758</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.636809</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.636809</td>\n",
       "      <td>26.6</td>\n",
       "      <td>17.271364</td>\n",
       "      <td>87.4</td>\n",
       "      <td>17.271364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.812821</td>\n",
       "      <td>0.029861</td>\n",
       "      <td>0.857192</td>\n",
       "      <td>0.047165</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.084956</td>\n",
       "      <td>0.874276</td>\n",
       "      <td>0.027122</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.056608</td>\n",
       "      <td>24.2</td>\n",
       "      <td>7.596052</td>\n",
       "      <td>17.8</td>\n",
       "      <td>7.596052</td>\n",
       "      <td>11.4</td>\n",
       "      <td>9.685040</td>\n",
       "      <td>102.6</td>\n",
       "      <td>9.685040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.029515</td>\n",
       "      <td>0.835554</td>\n",
       "      <td>0.033658</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.041424</td>\n",
       "      <td>0.880806</td>\n",
       "      <td>0.018864</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.058590</td>\n",
       "      <td>20.8</td>\n",
       "      <td>5.848077</td>\n",
       "      <td>21.2</td>\n",
       "      <td>5.848077</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.722288</td>\n",
       "      <td>106.4</td>\n",
       "      <td>4.722288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.797436</td>\n",
       "      <td>0.034698</td>\n",
       "      <td>0.822283</td>\n",
       "      <td>0.049157</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.050771</td>\n",
       "      <td>0.870653</td>\n",
       "      <td>0.016741</td>\n",
       "      <td>0.683960</td>\n",
       "      <td>0.093443</td>\n",
       "      <td>18.4</td>\n",
       "      <td>9.633276</td>\n",
       "      <td>23.6</td>\n",
       "      <td>9.633276</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.787918</td>\n",
       "      <td>106.0</td>\n",
       "      <td>5.787918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.814103</td>\n",
       "      <td>0.039255</td>\n",
       "      <td>0.855787</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.030271</td>\n",
       "      <td>0.735965</td>\n",
       "      <td>0.080995</td>\n",
       "      <td>23.8</td>\n",
       "      <td>9.230385</td>\n",
       "      <td>18.2</td>\n",
       "      <td>9.230385</td>\n",
       "      <td>10.8</td>\n",
       "      <td>9.576012</td>\n",
       "      <td>103.2</td>\n",
       "      <td>9.576012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100%_sintÃ©tico_70/30_selftest</td>\n",
       "      <td>0.987805</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.987540</td>\n",
       "      <td>0.022341</td>\n",
       "      <td>0.990877</td>\n",
       "      <td>0.014679</td>\n",
       "      <td>0.989002</td>\n",
       "      <td>0.010654</td>\n",
       "      <td>0.987105</td>\n",
       "      <td>0.013620</td>\n",
       "      <td>76.6</td>\n",
       "      <td>8.905055</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.167948</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.303840</td>\n",
       "      <td>85.4</td>\n",
       "      <td>7.469940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100%_sintÃ©ticoâ†’real</td>\n",
       "      <td>0.676923</td>\n",
       "      <td>0.076468</td>\n",
       "      <td>0.778035</td>\n",
       "      <td>0.046580</td>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.193580</td>\n",
       "      <td>0.772988</td>\n",
       "      <td>0.091950</td>\n",
       "      <td>0.572932</td>\n",
       "      <td>0.055480</td>\n",
       "      <td>14.6</td>\n",
       "      <td>11.436783</td>\n",
       "      <td>27.4</td>\n",
       "      <td>11.436783</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.068076</td>\n",
       "      <td>91.0</td>\n",
       "      <td>22.068076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ratio  acc_mean   acc_std  prec_mean  prec_std  \\\n",
       "0                            0.0  0.753846  0.049984   0.788377  0.055047   \n",
       "1                           0.25  0.765385  0.082665   0.902748  0.031484   \n",
       "2                            0.5  0.812821  0.029861   0.857192  0.047165   \n",
       "3                           0.75  0.815385  0.029515   0.835554  0.033658   \n",
       "4                            1.0  0.797436  0.034698   0.822283  0.049157   \n",
       "5                            1.5  0.814103  0.039255   0.855787  0.055347   \n",
       "6  100%_sintÃ©tico_70/30_selftest  0.987805  0.012195   0.987540  0.022341   \n",
       "7            100%_sintÃ©ticoâ†’real  0.676923  0.076468   0.778035  0.046580   \n",
       "\n",
       "   rec_mean   rec_std   f1_mean    f1_std  auc_mean   auc_std  tn_mean  \\\n",
       "0  0.915789  0.078360  0.844403  0.033128  0.615038  0.100021     13.2   \n",
       "1  0.766667  0.151503  0.819707  0.087994  0.764286  0.027758     32.0   \n",
       "2  0.900000  0.084956  0.874276  0.027122  0.738095  0.056608     24.2   \n",
       "3  0.933333  0.041424  0.880806  0.018864  0.714286  0.058590     20.8   \n",
       "4  0.929825  0.050771  0.870653  0.016741  0.683960  0.093443     18.4   \n",
       "5  0.905263  0.084000  0.876106  0.030271  0.735965  0.080995     23.8   \n",
       "6  0.990877  0.014679  0.989002  0.010654  0.987105  0.013620     76.6   \n",
       "7  0.798246  0.193580  0.772988  0.091950  0.572932  0.055480     14.6   \n",
       "\n",
       "      tn_std  fp_mean     fp_std  fn_mean     fn_std  tp_mean     tp_std  \n",
       "0  10.281051     28.8  10.281051      9.6   8.933085    104.4   8.933085  \n",
       "1   4.636809     10.0   4.636809     26.6  17.271364     87.4  17.271364  \n",
       "2   7.596052     17.8   7.596052     11.4   9.685040    102.6   9.685040  \n",
       "3   5.848077     21.2   5.848077      7.6   4.722288    106.4   4.722288  \n",
       "4   9.633276     23.6   9.633276      8.0   5.787918    106.0   5.787918  \n",
       "5   9.230385     18.2   9.230385     10.8   9.576012    103.2   9.576012  \n",
       "6   8.905055      1.2   2.167948      0.8   1.303840     85.4   7.469940  \n",
       "7  11.436783     27.4  11.436783     23.0  22.068076     91.0  22.068076  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1260x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: auc_by_ratio_lollipop.png | error=std\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _bootstrap_ci_mean(a, iters=2000, alpha=0.05, rng=None):\n",
    "    rng = rng or np.random.default_rng(123)\n",
    "    a = np.asarray(a, dtype=float)\n",
    "    a = a[~np.isnan(a)]\n",
    "    if len(a) == 0:\n",
    "        return np.nan, np.nan\n",
    "    means = [rng.choice(a, size=len(a), replace=True).mean() for _ in range(iters)]\n",
    "    lo = np.percentile(means, 100*alpha/2)\n",
    "    hi = np.percentile(means, 100*(1 - alpha/2))\n",
    "    return float(lo), float(hi)\n",
    "\n",
    "def plot_auc_lollipop_by_ratio(df_all, col_ratio=\"ratio\", col_auc=\"auc\",\n",
    "                               error=None, title=\"AUC by Ratio\",\n",
    "                               xlabel=\"AUC\", fname=\"auc_by_ratio_lollipop.png\"):\n",
    "    # 1) filtrar ratios numÃ©ricos e ordenar\n",
    "    tmp = df_all.copy()\n",
    "    tmp[\"_ratio_num\"] = pd.to_numeric(tmp[col_ratio], errors=\"coerce\")\n",
    "    tmp = tmp.dropna(subset=[\"_ratio_num\"])\n",
    "    ratios_sorted = sorted(tmp[\"_ratio_num\"].unique())\n",
    "    y = np.arange(len(ratios_sorted))\n",
    "\n",
    "    # 2) agregar por ratio\n",
    "    means, errs = [], []\n",
    "    for r in ratios_sorted:\n",
    "        vals = tmp.loc[tmp[\"_ratio_num\"] == r, col_auc].astype(float).dropna().values\n",
    "        m = float(np.mean(vals)) if len(vals) else np.nan\n",
    "        means.append(m)\n",
    "        if error == \"std\":\n",
    "            e = float(np.std(vals, ddof=1)) if len(vals) > 1 else 0.0\n",
    "        elif error == \"ci\":\n",
    "            lo, hi = _bootstrap_ci_mean(vals)\n",
    "            e = (hi - lo) / 2.0\n",
    "        else:\n",
    "            e = 0.0\n",
    "        errs.append(e)\n",
    "\n",
    "    # 3) figura\n",
    "    fig, ax = plt.subplots(figsize=(9, 5), dpi=140)\n",
    "\n",
    "    # linhas horizontais (barras suaves)\n",
    "    for yi, m in zip(y, means):\n",
    "        ax.hlines(y=yi, xmin=0, xmax=m, linewidth=8, alpha=0.25)\n",
    "\n",
    "    # pontos no final\n",
    "    ax.scatter(means, y, s=70, linewidths=1.5)\n",
    "\n",
    "    # erro opcional\n",
    "    if error is not None:\n",
    "        ax.errorbar(means, y, xerr=errs, fmt=\"none\", capsize=4, linewidth=1)\n",
    "\n",
    "    # eixos e estÃ©tica\n",
    "    ax.set_yticks(y)\n",
    "    ax.set_yticklabels([str(r) for r in ratios_sorted])\n",
    "    ax.set_xlabel(xlabel, fontsize=14, labelpad=10)\n",
    "    ax.set_title(title, fontsize=20, loc=\"left\", pad=8)\n",
    "\n",
    "    # sem grid vertical nem horizontal\n",
    "    ax.grid(False)\n",
    "\n",
    "    # remover spines\n",
    "    for spine in [\"top\", \"right\"]:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "\n",
    "    # inverter eixo y (0 no topo)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    # margem Ã  direita\n",
    "    xmax = np.nanmax(means)\n",
    "    ax.set_xlim(left=0, right=xmax * 1.05)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"Saved: {fname} | error={error}\")\n",
    "\n",
    "# Exemplo de uso:\n",
    "plot_auc_lollipop_by_ratio(df_all, error=\"std\")\n",
    "# plot_auc_lollipop_by_ratio(df_all, error=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rodando vÃ¡rias vezes (Balanceado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "import os, random\n",
    "\n",
    "def _seed_everything(seed: int):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def run_k_times_balance(\n",
    "    k: int,\n",
    "    train_dataset,\n",
    "    test_dataset,\n",
    "    make_generator0_fn,   # -> G_class0 (nn.Module)\n",
    "    latent_dim: int,\n",
    "    step_ratio: float = 0.25,\n",
    "    batch_size: int = 64,\n",
    "    epochs: int = 5,\n",
    "    device: str | None = None\n",
    "):\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    all_runs = []\n",
    "    elapsed_times = []  # <-- novo\n",
    "\n",
    "    print(f\"\\n=== Iniciando {k} rodadas (BALANCEADO classe 0) ===\")\n",
    "    start_global = time.time()\n",
    "\n",
    "    for run_id in range(1, k + 1):\n",
    "        run_start = time.time()\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(f\"== Rodada {run_id}/{k}\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        # 1) Treinar/carregar gerador da classe 0 desta rodada\n",
    "        G_class0 = make_generator0_fn(run_id)\n",
    "\n",
    "        # 2) Executar experimento balanceado\n",
    "        df_k = balance_class0_experiment(\n",
    "            train_dataset=train_dataset,\n",
    "            test_dataset=test_dataset,\n",
    "            G_class0=G_class0,\n",
    "            latent_dim=latent_dim,\n",
    "            step_ratio=step_ratio,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            device=device\n",
    "        )\n",
    "        df_k[\"run_id\"] = run_id\n",
    "        all_runs.append(df_k)\n",
    "\n",
    "        # liberar memÃ³ria\n",
    "        del G_class0\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # 3) Tempos/estimativas (corrigido)\n",
    "        elapsed = time.time() - run_start\n",
    "        elapsed_times.append(elapsed)\n",
    "        avg_time = float(np.mean(elapsed_times))\n",
    "        remaining = avg_time * (k - run_id)\n",
    "        print(f\"â±ï¸  Tempo da rodada {run_id}: {elapsed/60:.2f} min\")\n",
    "        print(f\"ðŸ•  Estimativa restante: {remaining/60:.2f} min ({(remaining/3600):.2f} h)\")\n",
    "\n",
    "    total_time = time.time() - start_global\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"âœ… Todas as {k} rodadas (balanceado) concluÃ­das.\")\n",
    "    print(f\"â±ï¸  Tempo total: {total_time/60:.2f} min ({(total_time/3600):.2f} h)\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    # 4) Concatena e agrega mÃ©dia/desvio por ratio\n",
    "    df_all = pd.concat(all_runs, ignore_index=True)\n",
    "    metrics_cols = [\"acc\",\"prec\",\"rec\",\"f1\",\"auc\",\"tn\",\"fp\",\"fn\",\"tp\",\n",
    "                    \"added_class0_synth_total\",\"added_this_round\"]\n",
    "    agg = df_all.groupby(\"ratio\").agg({m:[\"mean\",\"std\"] for m in metrics_cols if m in df_all.columns}).reset_index()\n",
    "    agg.columns = ['_'.join(col).strip('_') for col in agg.columns.values]\n",
    "\n",
    "    return df_all, agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator0_fn_factory(train_loader, latent_dim: int, gan_epochs: int = 50, device: str | None = None):\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def make_generator0_fn(run_id: int):\n",
    "        seed = 2000 + run_id\n",
    "        print(f\"[GAN-0] Rodada {run_id}: treinando G_class0 do zero | seed={seed}\")\n",
    "        _seed_everything(seed)\n",
    "\n",
    "        G0 = DCGenerator(latent_dim=latent_dim).to(device)\n",
    "        D0 = DCDiscriminator(img_channels=1).to(device)\n",
    "        G0 = train_gan_for_class(\n",
    "            train_loader=train_loader,\n",
    "            label_target=0,\n",
    "            G=G0, D=D0,\n",
    "            latent_dim=latent_dim,\n",
    "            num_epochs=gan_epochs,\n",
    "            device=device\n",
    "        ).eval()\n",
    "        return G0\n",
    "\n",
    "    return make_generator0_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Iniciando 5 rodadas (BALANCEADO classe 0) ===\n",
      "\n",
      "======================================================================\n",
      "== Rodada 1/5\n",
      "======================================================================\n",
      "[GAN-0] Rodada 1: treinando G_class0 do zero | seed=2001\n",
      "Epoch 1/50 - Loss D: 0.945 | Loss G: 1.159\n",
      "Epoch 2/50 - Loss D: 0.403 | Loss G: 1.932\n",
      "Epoch 3/50 - Loss D: 0.256 | Loss G: 2.407\n",
      "Epoch 4/50 - Loss D: 0.172 | Loss G: 2.752\n",
      "Epoch 5/50 - Loss D: 0.163 | Loss G: 2.913\n",
      "Epoch 6/50 - Loss D: 0.152 | Loss G: 3.158\n",
      "Epoch 7/50 - Loss D: 0.124 | Loss G: 3.176\n",
      "Epoch 8/50 - Loss D: 0.190 | Loss G: 3.060\n",
      "Epoch 9/50 - Loss D: 0.167 | Loss G: 3.088\n",
      "Epoch 10/50 - Loss D: 0.158 | Loss G: 3.241\n",
      "Epoch 11/50 - Loss D: 0.193 | Loss G: 3.328\n",
      "Epoch 12/50 - Loss D: 0.197 | Loss G: 3.321\n",
      "Epoch 13/50 - Loss D: 0.344 | Loss G: 2.879\n",
      "Epoch 14/50 - Loss D: 0.246 | Loss G: 3.048\n",
      "Epoch 15/50 - Loss D: 0.214 | Loss G: 2.746\n",
      "Epoch 16/50 - Loss D: 0.642 | Loss G: 3.189\n",
      "Epoch 17/50 - Loss D: 0.336 | Loss G: 2.538\n",
      "Epoch 18/50 - Loss D: 0.356 | Loss G: 2.555\n",
      "Epoch 19/50 - Loss D: 0.496 | Loss G: 2.349\n",
      "Epoch 20/50 - Loss D: 0.384 | Loss G: 2.223\n",
      "Epoch 21/50 - Loss D: 0.499 | Loss G: 2.743\n",
      "Epoch 22/50 - Loss D: 0.443 | Loss G: 2.093\n",
      "Epoch 23/50 - Loss D: 0.621 | Loss G: 2.225\n",
      "Epoch 24/50 - Loss D: 0.654 | Loss G: 2.319\n",
      "Epoch 25/50 - Loss D: 0.780 | Loss G: 1.694\n",
      "Epoch 26/50 - Loss D: 0.636 | Loss G: 1.625\n",
      "Epoch 27/50 - Loss D: 0.970 | Loss G: 1.821\n",
      "Epoch 28/50 - Loss D: 0.856 | Loss G: 1.316\n",
      "Epoch 29/50 - Loss D: 0.969 | Loss G: 1.348\n",
      "Epoch 30/50 - Loss D: 1.024 | Loss G: 1.341\n",
      "Epoch 31/50 - Loss D: 0.891 | Loss G: 1.360\n",
      "Epoch 32/50 - Loss D: 0.978 | Loss G: 1.359\n",
      "Epoch 33/50 - Loss D: 0.971 | Loss G: 1.187\n",
      "Epoch 34/50 - Loss D: 0.925 | Loss G: 1.339\n",
      "Epoch 35/50 - Loss D: 0.945 | Loss G: 1.476\n",
      "Epoch 36/50 - Loss D: 0.967 | Loss G: 1.183\n",
      "Epoch 37/50 - Loss D: 0.885 | Loss G: 1.406\n",
      "Epoch 38/50 - Loss D: 0.919 | Loss G: 1.241\n",
      "Epoch 39/50 - Loss D: 0.985 | Loss G: 1.284\n",
      "Epoch 40/50 - Loss D: 0.971 | Loss G: 1.141\n",
      "Epoch 41/50 - Loss D: 0.997 | Loss G: 1.409\n",
      "Epoch 42/50 - Loss D: 0.925 | Loss G: 1.226\n",
      "Epoch 43/50 - Loss D: 0.992 | Loss G: 1.110\n",
      "Epoch 44/50 - Loss D: 0.932 | Loss G: 1.297\n",
      "Epoch 45/50 - Loss D: 0.878 | Loss G: 1.279\n",
      "Epoch 46/50 - Loss D: 0.959 | Loss G: 1.394\n",
      "Epoch 47/50 - Loss D: 1.080 | Loss G: 1.228\n",
      "Epoch 48/50 - Loss D: 0.932 | Loss G: 1.232\n",
      "Epoch 49/50 - Loss D: 1.109 | Loss G: 1.274\n",
      "Epoch 50/50 - Loss D: 0.955 | Loss G: 1.157\n",
      "[INFO] Reais: class0=147, class1=399 | dÃ©ficit(class0)=252\n",
      "[INFO] ratio=0: balancear primeiro (adicionar exatamente o dÃ©ficit na classe 0).\n",
      "[INFO] ratios seguintes: adicionar extra = int(dÃ©ficit * r) por cima do conjunto jÃ¡ balanceado.\n",
      "\n",
      "ratio=0.00: +252 (classe 0) â†’ total sintÃ©tico classe0=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio=0.25: +315 (classe 0; sendo 252 p/ balancear + 63 extra) â†’ total sintÃ©tico classe0=315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio=0.50: +378 (classe 0; sendo 252 p/ balancear + 126 extra) â†’ total sintÃ©tico classe0=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio=0.75: +441 (classe 0; sendo 252 p/ balancear + 189 extra) â†’ total sintÃ©tico classe0=441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio=1.00: +504 (classe 0; sendo 252 p/ balancear + 252 extra) â†’ total sintÃ©tico classe0=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â±ï¸  Tempo da rodada 1: 0.79 min\n",
      "ðŸ•  Estimativa restante: 3.16 min (0.05 h)\n",
      "\n",
      "======================================================================\n",
      "== Rodada 2/5\n",
      "======================================================================\n",
      "[GAN-0] Rodada 2: treinando G_class0 do zero | seed=2002\n",
      "Epoch 1/50 - Loss D: 1.008 | Loss G: 1.087\n",
      "Epoch 2/50 - Loss D: 0.430 | Loss G: 1.939\n",
      "Epoch 3/50 - Loss D: 0.264 | Loss G: 2.267\n",
      "Epoch 4/50 - Loss D: 0.277 | Loss G: 2.338\n",
      "Epoch 5/50 - Loss D: 0.236 | Loss G: 2.655\n",
      "Epoch 6/50 - Loss D: 0.127 | Loss G: 3.215\n",
      "Epoch 7/50 - Loss D: 0.089 | Loss G: 3.532\n",
      "Epoch 8/50 - Loss D: 0.064 | Loss G: 3.773\n",
      "Epoch 9/50 - Loss D: 0.050 | Loss G: 4.066\n",
      "Epoch 10/50 - Loss D: 0.067 | Loss G: 3.754\n",
      "Epoch 11/50 - Loss D: 0.171 | Loss G: 3.483\n",
      "Epoch 12/50 - Loss D: 0.135 | Loss G: 3.186\n",
      "Epoch 13/50 - Loss D: 0.145 | Loss G: 3.214\n",
      "Epoch 14/50 - Loss D: 0.225 | Loss G: 2.908\n",
      "Epoch 15/50 - Loss D: 0.338 | Loss G: 3.116\n",
      "Epoch 16/50 - Loss D: 0.234 | Loss G: 3.149\n",
      "Epoch 17/50 - Loss D: 0.177 | Loss G: 3.274\n",
      "Epoch 18/50 - Loss D: 0.181 | Loss G: 3.392\n",
      "Epoch 19/50 - Loss D: 0.171 | Loss G: 3.189\n",
      "Epoch 20/50 - Loss D: 0.188 | Loss G: 3.027\n",
      "Epoch 21/50 - Loss D: 0.946 | Loss G: 3.222\n",
      "Epoch 22/50 - Loss D: 0.517 | Loss G: 2.240\n",
      "Epoch 23/50 - Loss D: 0.502 | Loss G: 2.303\n",
      "Epoch 24/50 - Loss D: 0.494 | Loss G: 2.660\n",
      "Epoch 25/50 - Loss D: 0.352 | Loss G: 2.259\n",
      "Epoch 26/50 - Loss D: 0.319 | Loss G: 2.440\n",
      "Epoch 27/50 - Loss D: 0.342 | Loss G: 2.423\n",
      "Epoch 28/50 - Loss D: 0.586 | Loss G: 2.118\n",
      "Epoch 29/50 - Loss D: 0.390 | Loss G: 2.596\n",
      "Epoch 30/50 - Loss D: 0.992 | Loss G: 1.783\n",
      "Epoch 31/50 - Loss D: 0.642 | Loss G: 1.738\n",
      "Epoch 32/50 - Loss D: 0.650 | Loss G: 1.706\n",
      "Epoch 33/50 - Loss D: 0.936 | Loss G: 1.666\n",
      "Epoch 34/50 - Loss D: 0.873 | Loss G: 1.592\n",
      "Epoch 35/50 - Loss D: 0.853 | Loss G: 1.353\n",
      "Epoch 36/50 - Loss D: 0.736 | Loss G: 1.494\n",
      "Epoch 37/50 - Loss D: 0.985 | Loss G: 1.505\n",
      "Epoch 38/50 - Loss D: 0.870 | Loss G: 1.281\n",
      "Epoch 39/50 - Loss D: 0.969 | Loss G: 1.345\n",
      "Epoch 40/50 - Loss D: 0.890 | Loss G: 1.282\n",
      "Epoch 41/50 - Loss D: 0.859 | Loss G: 1.450\n",
      "Epoch 42/50 - Loss D: 0.882 | Loss G: 1.330\n",
      "Epoch 43/50 - Loss D: 0.957 | Loss G: 1.305\n",
      "Epoch 44/50 - Loss D: 0.916 | Loss G: 1.284\n",
      "Epoch 45/50 - Loss D: 1.039 | Loss G: 1.291\n",
      "Epoch 46/50 - Loss D: 0.966 | Loss G: 1.233\n",
      "Epoch 47/50 - Loss D: 0.925 | Loss G: 1.256\n",
      "Epoch 48/50 - Loss D: 1.062 | Loss G: 1.197\n",
      "Epoch 49/50 - Loss D: 1.030 | Loss G: 1.357\n",
      "Epoch 50/50 - Loss D: 0.890 | Loss G: 1.277\n",
      "[INFO] Reais: class0=147, class1=399 | dÃ©ficit(class0)=252\n",
      "[INFO] ratio=0: balancear primeiro (adicionar exatamente o dÃ©ficit na classe 0).\n",
      "[INFO] ratios seguintes: adicionar extra = int(dÃ©ficit * r) por cima do conjunto jÃ¡ balanceado.\n",
      "\n",
      "ratio=0.00: +252 (classe 0) â†’ total sintÃ©tico classe0=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio=0.25: +315 (classe 0; sendo 252 p/ balancear + 63 extra) â†’ total sintÃ©tico classe0=315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio=0.50: +378 (classe 0; sendo 252 p/ balancear + 126 extra) â†’ total sintÃ©tico classe0=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio=0.75: +441 (classe 0; sendo 252 p/ balancear + 189 extra) â†’ total sintÃ©tico classe0=441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio=1.00: +504 (classe 0; sendo 252 p/ balancear + 252 extra) â†’ total sintÃ©tico classe0=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â±ï¸  Tempo da rodada 2: 0.79 min\n",
      "ðŸ•  Estimativa restante: 2.37 min (0.04 h)\n",
      "\n",
      "======================================================================\n",
      "== Rodada 3/5\n",
      "======================================================================\n",
      "[GAN-0] Rodada 3: treinando G_class0 do zero | seed=2003\n",
      "Epoch 1/50 - Loss D: 1.010 | Loss G: 1.051\n",
      "Epoch 2/50 - Loss D: 0.515 | Loss G: 1.652\n",
      "Epoch 3/50 - Loss D: 0.357 | Loss G: 2.030\n",
      "Epoch 4/50 - Loss D: 0.242 | Loss G: 2.437\n",
      "Epoch 5/50 - Loss D: 0.239 | Loss G: 2.434\n",
      "Epoch 6/50 - Loss D: 0.249 | Loss G: 2.665\n",
      "Epoch 7/50 - Loss D: 0.183 | Loss G: 2.863\n",
      "Epoch 8/50 - Loss D: 0.146 | Loss G: 3.012\n",
      "Epoch 9/50 - Loss D: 0.153 | Loss G: 3.025\n",
      "Epoch 10/50 - Loss D: 0.149 | Loss G: 3.083\n",
      "Epoch 11/50 - Loss D: 0.151 | Loss G: 3.258\n",
      "Epoch 12/50 - Loss D: 0.181 | Loss G: 3.012\n",
      "Epoch 13/50 - Loss D: 0.185 | Loss G: 3.127\n",
      "Epoch 14/50 - Loss D: 0.596 | Loss G: 2.418\n",
      "Epoch 15/50 - Loss D: 0.430 | Loss G: 2.267\n",
      "Epoch 16/50 - Loss D: 0.353 | Loss G: 2.177\n",
      "Epoch 17/50 - Loss D: 0.594 | Loss G: 2.584\n",
      "Epoch 18/50 - Loss D: 0.399 | Loss G: 2.373\n",
      "Epoch 19/50 - Loss D: 0.385 | Loss G: 2.322\n",
      "Epoch 20/50 - Loss D: 1.019 | Loss G: 2.352\n",
      "Epoch 21/50 - Loss D: 0.785 | Loss G: 1.556\n",
      "Epoch 22/50 - Loss D: 0.605 | Loss G: 1.760\n",
      "Epoch 23/50 - Loss D: 0.616 | Loss G: 1.935\n",
      "Epoch 24/50 - Loss D: 0.952 | Loss G: 1.468\n",
      "Epoch 25/50 - Loss D: 0.693 | Loss G: 1.606\n",
      "Epoch 26/50 - Loss D: 0.729 | Loss G: 1.582\n",
      "Epoch 27/50 - Loss D: 0.967 | Loss G: 1.541\n",
      "Epoch 28/50 - Loss D: 0.908 | Loss G: 1.246\n",
      "Epoch 29/50 - Loss D: 0.896 | Loss G: 1.435\n",
      "Epoch 30/50 - Loss D: 0.882 | Loss G: 1.233\n",
      "Epoch 31/50 - Loss D: 0.990 | Loss G: 1.372\n",
      "Epoch 32/50 - Loss D: 1.020 | Loss G: 1.353\n",
      "Epoch 33/50 - Loss D: 0.966 | Loss G: 1.194\n",
      "Epoch 34/50 - Loss D: 0.874 | Loss G: 1.289\n",
      "Epoch 35/50 - Loss D: 1.040 | Loss G: 1.340\n",
      "Epoch 36/50 - Loss D: 0.939 | Loss G: 1.167\n",
      "Epoch 37/50 - Loss D: 0.925 | Loss G: 1.251\n",
      "Epoch 38/50 - Loss D: 0.932 | Loss G: 1.275\n",
      "Epoch 39/50 - Loss D: 0.895 | Loss G: 1.182\n",
      "Epoch 40/50 - Loss D: 0.880 | Loss G: 1.242\n",
      "Epoch 41/50 - Loss D: 1.068 | Loss G: 1.517\n",
      "Epoch 42/50 - Loss D: 1.129 | Loss G: 1.103\n",
      "Epoch 43/50 - Loss D: 1.077 | Loss G: 1.245\n",
      "Epoch 44/50 - Loss D: 1.003 | Loss G: 1.339\n",
      "Epoch 45/50 - Loss D: 1.097 | Loss G: 1.183\n",
      "Epoch 46/50 - Loss D: 1.006 | Loss G: 1.288\n",
      "Epoch 47/50 - Loss D: 1.000 | Loss G: 1.100\n",
      "Epoch 48/50 - Loss D: 0.954 | Loss G: 1.221\n",
      "Epoch 49/50 - Loss D: 1.043 | Loss G: 1.327\n",
      "Epoch 50/50 - Loss D: 1.357 | Loss G: 1.084\n",
      "[INFO] Reais: class0=147, class1=399 | dÃ©ficit(class0)=252\n",
      "[INFO] ratio=0: balancear primeiro (adicionar exatamente o dÃ©ficit na classe 0).\n",
      "[INFO] ratios seguintes: adicionar extra = int(dÃ©ficit * r) por cima do conjunto jÃ¡ balanceado.\n",
      "\n",
      "ratio=0.00: +252 (classe 0) â†’ total sintÃ©tico classe0=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio=0.25: +315 (classe 0; sendo 252 p/ balancear + 63 extra) â†’ total sintÃ©tico classe0=315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio=0.50: +378 (classe 0; sendo 252 p/ balancear + 126 extra) â†’ total sintÃ©tico classe0=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio=0.75: +441 (classe 0; sendo 252 p/ balancear + 189 extra) â†’ total sintÃ©tico classe0=441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio=1.00: +504 (classe 0; sendo 252 p/ balancear + 252 extra) â†’ total sintÃ©tico classe0=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â±ï¸  Tempo da rodada 3: 0.77 min\n",
      "ðŸ•  Estimativa restante: 1.57 min (0.03 h)\n",
      "\n",
      "======================================================================\n",
      "== Rodada 4/5\n",
      "======================================================================\n",
      "[GAN-0] Rodada 4: treinando G_class0 do zero | seed=2004\n",
      "Epoch 1/50 - Loss D: 0.894 | Loss G: 1.132\n",
      "Epoch 2/50 - Loss D: 0.517 | Loss G: 1.740\n",
      "Epoch 3/50 - Loss D: 0.377 | Loss G: 2.066\n",
      "Epoch 4/50 - Loss D: 0.293 | Loss G: 2.264\n",
      "Epoch 5/50 - Loss D: 0.255 | Loss G: 2.420\n",
      "Epoch 6/50 - Loss D: 0.212 | Loss G: 2.645\n",
      "Epoch 7/50 - Loss D: 0.188 | Loss G: 2.828\n",
      "Epoch 8/50 - Loss D: 0.168 | Loss G: 3.027\n",
      "Epoch 9/50 - Loss D: 0.169 | Loss G: 3.036\n",
      "Epoch 10/50 - Loss D: 0.245 | Loss G: 3.092\n",
      "Epoch 11/50 - Loss D: 0.188 | Loss G: 3.102\n",
      "Epoch 12/50 - Loss D: 0.176 | Loss G: 3.008\n",
      "Epoch 13/50 - Loss D: 0.220 | Loss G: 3.010\n",
      "Epoch 14/50 - Loss D: 0.194 | Loss G: 3.275\n",
      "Epoch 15/50 - Loss D: 0.246 | Loss G: 3.072\n",
      "Epoch 16/50 - Loss D: 0.612 | Loss G: 2.776\n",
      "Epoch 17/50 - Loss D: 0.463 | Loss G: 2.626\n",
      "Epoch 18/50 - Loss D: 0.337 | Loss G: 2.565\n",
      "Epoch 19/50 - Loss D: 0.353 | Loss G: 2.429\n",
      "Epoch 20/50 - Loss D: 0.354 | Loss G: 2.421\n",
      "Epoch 21/50 - Loss D: 0.468 | Loss G: 2.669\n",
      "Epoch 22/50 - Loss D: 0.441 | Loss G: 2.264\n",
      "Epoch 23/50 - Loss D: 0.374 | Loss G: 2.335\n",
      "Epoch 24/50 - Loss D: 0.730 | Loss G: 2.356\n",
      "Epoch 25/50 - Loss D: 0.560 | Loss G: 1.939\n",
      "Epoch 26/50 - Loss D: 0.899 | Loss G: 2.102\n",
      "Epoch 27/50 - Loss D: 0.934 | Loss G: 1.601\n",
      "Epoch 28/50 - Loss D: 0.857 | Loss G: 1.426\n",
      "Epoch 29/50 - Loss D: 0.745 | Loss G: 1.504\n",
      "Epoch 30/50 - Loss D: 0.872 | Loss G: 1.491\n",
      "Epoch 31/50 - Loss D: 0.905 | Loss G: 1.492\n",
      "Epoch 32/50 - Loss D: 0.804 | Loss G: 1.358\n",
      "Epoch 33/50 - Loss D: 0.771 | Loss G: 1.368\n",
      "Epoch 34/50 - Loss D: 1.060 | Loss G: 1.533\n",
      "Epoch 35/50 - Loss D: 0.786 | Loss G: 1.343\n",
      "Epoch 36/50 - Loss D: 0.884 | Loss G: 1.387\n",
      "Epoch 37/50 - Loss D: 0.737 | Loss G: 1.356\n",
      "Epoch 38/50 - Loss D: 0.843 | Loss G: 1.410\n",
      "Epoch 39/50 - Loss D: 0.859 | Loss G: 1.463\n",
      "Epoch 40/50 - Loss D: 0.799 | Loss G: 1.490\n",
      "Epoch 41/50 - Loss D: 0.861 | Loss G: 1.342\n",
      "Epoch 42/50 - Loss D: 0.915 | Loss G: 1.545\n",
      "Epoch 43/50 - Loss D: 0.873 | Loss G: 1.345\n",
      "Epoch 44/50 - Loss D: 0.855 | Loss G: 1.311\n",
      "Epoch 45/50 - Loss D: 0.942 | Loss G: 1.462\n",
      "Epoch 46/50 - Loss D: 1.010 | Loss G: 1.436\n",
      "Epoch 47/50 - Loss D: 0.806 | Loss G: 1.460\n",
      "Epoch 48/50 - Loss D: 0.979 | Loss G: 1.671\n",
      "Epoch 49/50 - Loss D: 0.889 | Loss G: 1.286\n",
      "Epoch 50/50 - Loss D: 0.777 | Loss G: 1.535\n",
      "[INFO] Reais: class0=147, class1=399 | dÃ©ficit(class0)=252\n",
      "[INFO] ratio=0: balancear primeiro (adicionar exatamente o dÃ©ficit na classe 0).\n",
      "[INFO] ratios seguintes: adicionar extra = int(dÃ©ficit * r) por cima do conjunto jÃ¡ balanceado.\n",
      "\n",
      "ratio=0.00: +252 (classe 0) â†’ total sintÃ©tico classe0=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio=0.25: +315 (classe 0; sendo 252 p/ balancear + 63 extra) â†’ total sintÃ©tico classe0=315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio=0.50: +378 (classe 0; sendo 252 p/ balancear + 126 extra) â†’ total sintÃ©tico classe0=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio=0.75: +441 (classe 0; sendo 252 p/ balancear + 189 extra) â†’ total sintÃ©tico classe0=441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio=1.00: +504 (classe 0; sendo 252 p/ balancear + 252 extra) â†’ total sintÃ©tico classe0=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â±ï¸  Tempo da rodada 4: 0.79 min\n",
      "ðŸ•  Estimativa restante: 0.79 min (0.01 h)\n",
      "\n",
      "======================================================================\n",
      "== Rodada 5/5\n",
      "======================================================================\n",
      "[GAN-0] Rodada 5: treinando G_class0 do zero | seed=2005\n",
      "Epoch 1/50 - Loss D: 0.900 | Loss G: 1.292\n",
      "Epoch 2/50 - Loss D: 0.330 | Loss G: 2.139\n",
      "Epoch 3/50 - Loss D: 0.182 | Loss G: 2.681\n",
      "Epoch 4/50 - Loss D: 0.141 | Loss G: 2.905\n",
      "Epoch 5/50 - Loss D: 0.103 | Loss G: 3.213\n",
      "Epoch 6/50 - Loss D: 0.076 | Loss G: 3.579\n",
      "Epoch 7/50 - Loss D: 0.050 | Loss G: 3.917\n",
      "Epoch 8/50 - Loss D: 0.094 | Loss G: 3.641\n",
      "Epoch 9/50 - Loss D: 0.098 | Loss G: 3.724\n",
      "Epoch 10/50 - Loss D: 0.064 | Loss G: 3.875\n",
      "Epoch 11/50 - Loss D: 0.153 | Loss G: 4.125\n",
      "Epoch 12/50 - Loss D: 0.053 | Loss G: 4.300\n",
      "Epoch 13/50 - Loss D: 0.038 | Loss G: 4.538\n",
      "Epoch 14/50 - Loss D: 0.025 | Loss G: 4.632\n",
      "Epoch 15/50 - Loss D: 0.019 | Loss G: 5.013\n",
      "Epoch 16/50 - Loss D: 0.013 | Loss G: 5.385\n",
      "Epoch 17/50 - Loss D: 0.012 | Loss G: 5.500\n",
      "Epoch 18/50 - Loss D: 0.011 | Loss G: 5.476\n",
      "Epoch 19/50 - Loss D: 0.010 | Loss G: 5.544\n",
      "Epoch 20/50 - Loss D: 0.009 | Loss G: 5.565\n",
      "Epoch 21/50 - Loss D: 0.008 | Loss G: 5.754\n",
      "Epoch 22/50 - Loss D: 0.011 | Loss G: 5.261\n",
      "Epoch 23/50 - Loss D: 0.012 | Loss G: 5.400\n",
      "Epoch 24/50 - Loss D: 0.091 | Loss G: 5.181\n",
      "Epoch 25/50 - Loss D: 0.042 | Loss G: 4.654\n",
      "Epoch 26/50 - Loss D: 0.072 | Loss G: 4.335\n",
      "Epoch 27/50 - Loss D: 0.093 | Loss G: 4.094\n",
      "Epoch 28/50 - Loss D: 0.565 | Loss G: 3.711\n",
      "Epoch 29/50 - Loss D: 0.271 | Loss G: 3.644\n",
      "Epoch 30/50 - Loss D: 0.239 | Loss G: 3.283\n",
      "Epoch 31/50 - Loss D: 0.221 | Loss G: 3.774\n",
      "Epoch 32/50 - Loss D: 0.203 | Loss G: 3.476\n",
      "Epoch 33/50 - Loss D: 0.234 | Loss G: 3.306\n",
      "Epoch 34/50 - Loss D: 0.273 | Loss G: 3.013\n",
      "Epoch 35/50 - Loss D: 0.970 | Loss G: 3.275\n",
      "Epoch 36/50 - Loss D: 0.450 | Loss G: 2.574\n",
      "Epoch 37/50 - Loss D: 0.502 | Loss G: 2.282\n",
      "Epoch 38/50 - Loss D: 0.502 | Loss G: 2.063\n",
      "Epoch 39/50 - Loss D: 0.844 | Loss G: 2.156\n",
      "Epoch 40/50 - Loss D: 0.795 | Loss G: 1.959\n",
      "Epoch 41/50 - Loss D: 0.630 | Loss G: 1.787\n",
      "Epoch 42/50 - Loss D: 0.834 | Loss G: 1.927\n",
      "Epoch 43/50 - Loss D: 0.571 | Loss G: 1.914\n",
      "Epoch 44/50 - Loss D: 0.807 | Loss G: 1.786\n",
      "Epoch 45/50 - Loss D: 0.889 | Loss G: 1.433\n",
      "Epoch 46/50 - Loss D: 0.765 | Loss G: 1.333\n",
      "Epoch 47/50 - Loss D: 0.928 | Loss G: 1.533\n",
      "Epoch 48/50 - Loss D: 0.755 | Loss G: 1.494\n",
      "Epoch 49/50 - Loss D: 0.731 | Loss G: 1.450\n",
      "Epoch 50/50 - Loss D: 0.893 | Loss G: 1.613\n",
      "[INFO] Reais: class0=147, class1=399 | dÃ©ficit(class0)=252\n",
      "[INFO] ratio=0: balancear primeiro (adicionar exatamente o dÃ©ficit na classe 0).\n",
      "[INFO] ratios seguintes: adicionar extra = int(dÃ©ficit * r) por cima do conjunto jÃ¡ balanceado.\n",
      "\n",
      "ratio=0.00: +252 (classe 0) â†’ total sintÃ©tico classe0=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio=0.25: +315 (classe 0; sendo 252 p/ balancear + 63 extra) â†’ total sintÃ©tico classe0=315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio=0.50: +378 (classe 0; sendo 252 p/ balancear + 126 extra) â†’ total sintÃ©tico classe0=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio=0.75: +441 (classe 0; sendo 252 p/ balancear + 189 extra) â†’ total sintÃ©tico classe0=441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio=1.00: +504 (classe 0; sendo 252 p/ balancear + 252 extra) â†’ total sintÃ©tico classe0=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1197133/271428978.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â±ï¸  Tempo da rodada 5: 0.79 min\n",
      "ðŸ•  Estimativa restante: 0.00 min (0.00 h)\n",
      "\n",
      "======================================================================\n",
      "âœ… Todas as 5 rodadas (balanceado) concluÃ­das.\n",
      "â±ï¸  Tempo total: 3.94 min (0.07 h)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "=== resumo (mÃ©dia e desvio por ratio) â€” BALANCEADO ===\n",
      "   ratio  acc_mean   acc_std  prec_mean  prec_std  rec_mean   rec_std  \\\n",
      "0   0.00  0.833333  0.023553   0.883815  0.020721  0.889474  0.033171   \n",
      "1   0.25  0.825641  0.024156   0.853149  0.038576  0.922807  0.020003   \n",
      "2   0.50  0.835897  0.021066   0.874571  0.030238  0.908772  0.068117   \n",
      "3   0.75  0.793590  0.042376   0.889643  0.035721  0.824561  0.103976   \n",
      "4   1.00  0.791026  0.025074   0.861813  0.077858  0.868421  0.110436   \n",
      "\n",
      "    f1_mean    f1_std  auc_mean  ...  fp_mean     fp_std  fn_mean     fn_std  \\\n",
      "0  0.886220  0.017046  0.785213  ...     13.4   2.880972     12.6   3.781534   \n",
      "1  0.885836  0.012141  0.742356  ...     18.4   5.899152      8.8   2.280351   \n",
      "2  0.889212  0.020520  0.773434  ...     15.2   4.969909     10.4   7.765307   \n",
      "3  0.851231  0.042561  0.767043  ...     12.2   5.848077     20.0  11.853270   \n",
      "4  0.856978  0.026879  0.724687  ...     17.6  11.886968     15.0  12.589678   \n",
      "\n",
      "   tp_mean     tp_std  added_class0_synth_total_mean  \\\n",
      "0    101.4   3.781534                          252.0   \n",
      "1    105.2   2.280351                          315.0   \n",
      "2    103.6   7.765307                          378.0   \n",
      "3     94.0  11.853270                          441.0   \n",
      "4     99.0  12.589678                          504.0   \n",
      "\n",
      "   added_class0_synth_total_std  added_this_round_mean  added_this_round_std  \n",
      "0                           0.0                  252.0                   0.0  \n",
      "1                           0.0                  315.0                   0.0  \n",
      "2                           0.0                  378.0                   0.0  \n",
      "3                           0.0                  441.0                   0.0  \n",
      "4                           0.0                  504.0                   0.0  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "make_generator0_fn = make_generator0_fn_factory(\n",
    "    train_loader=train_loader,\n",
    "    latent_dim=latent_dim,\n",
    "    gan_epochs=50,\n",
    "    device=None\n",
    ")\n",
    "\n",
    "df_all_bal, df_summary_bal = run_k_times_balance(\n",
    "    k=5,\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    make_generator0_fn=make_generator0_fn,  # << sÃ³ classe 0\n",
    "    latent_dim=latent_dim,\n",
    "    step_ratio=0.25,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    device=None\n",
    ")\n",
    "\n",
    "print(\"\\n=== resumo (mÃ©dia e desvio por ratio) â€” BALANCEADO ===\")\n",
    "print(df_summary_bal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratio</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>prec_mean</th>\n",
       "      <th>prec_std</th>\n",
       "      <th>rec_mean</th>\n",
       "      <th>rec_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>fp_mean</th>\n",
       "      <th>fp_std</th>\n",
       "      <th>fn_mean</th>\n",
       "      <th>fn_std</th>\n",
       "      <th>tp_mean</th>\n",
       "      <th>tp_std</th>\n",
       "      <th>added_class0_synth_total_mean</th>\n",
       "      <th>added_class0_synth_total_std</th>\n",
       "      <th>added_this_round_mean</th>\n",
       "      <th>added_this_round_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.023553</td>\n",
       "      <td>0.883815</td>\n",
       "      <td>0.020721</td>\n",
       "      <td>0.889474</td>\n",
       "      <td>0.033171</td>\n",
       "      <td>0.886220</td>\n",
       "      <td>0.017046</td>\n",
       "      <td>0.785213</td>\n",
       "      <td>...</td>\n",
       "      <td>13.4</td>\n",
       "      <td>2.880972</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3.781534</td>\n",
       "      <td>101.4</td>\n",
       "      <td>3.781534</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.825641</td>\n",
       "      <td>0.024156</td>\n",
       "      <td>0.853149</td>\n",
       "      <td>0.038576</td>\n",
       "      <td>0.922807</td>\n",
       "      <td>0.020003</td>\n",
       "      <td>0.885836</td>\n",
       "      <td>0.012141</td>\n",
       "      <td>0.742356</td>\n",
       "      <td>...</td>\n",
       "      <td>18.4</td>\n",
       "      <td>5.899152</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2.280351</td>\n",
       "      <td>105.2</td>\n",
       "      <td>2.280351</td>\n",
       "      <td>315.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.835897</td>\n",
       "      <td>0.021066</td>\n",
       "      <td>0.874571</td>\n",
       "      <td>0.030238</td>\n",
       "      <td>0.908772</td>\n",
       "      <td>0.068117</td>\n",
       "      <td>0.889212</td>\n",
       "      <td>0.020520</td>\n",
       "      <td>0.773434</td>\n",
       "      <td>...</td>\n",
       "      <td>15.2</td>\n",
       "      <td>4.969909</td>\n",
       "      <td>10.4</td>\n",
       "      <td>7.765307</td>\n",
       "      <td>103.6</td>\n",
       "      <td>7.765307</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.793590</td>\n",
       "      <td>0.042376</td>\n",
       "      <td>0.889643</td>\n",
       "      <td>0.035721</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.103976</td>\n",
       "      <td>0.851231</td>\n",
       "      <td>0.042561</td>\n",
       "      <td>0.767043</td>\n",
       "      <td>...</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5.848077</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.853270</td>\n",
       "      <td>94.0</td>\n",
       "      <td>11.853270</td>\n",
       "      <td>441.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.791026</td>\n",
       "      <td>0.025074</td>\n",
       "      <td>0.861813</td>\n",
       "      <td>0.077858</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.110436</td>\n",
       "      <td>0.856978</td>\n",
       "      <td>0.026879</td>\n",
       "      <td>0.724687</td>\n",
       "      <td>...</td>\n",
       "      <td>17.6</td>\n",
       "      <td>11.886968</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.589678</td>\n",
       "      <td>99.0</td>\n",
       "      <td>12.589678</td>\n",
       "      <td>504.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ratio  acc_mean   acc_std  prec_mean  prec_std  rec_mean   rec_std  \\\n",
       "0   0.00  0.833333  0.023553   0.883815  0.020721  0.889474  0.033171   \n",
       "1   0.25  0.825641  0.024156   0.853149  0.038576  0.922807  0.020003   \n",
       "2   0.50  0.835897  0.021066   0.874571  0.030238  0.908772  0.068117   \n",
       "3   0.75  0.793590  0.042376   0.889643  0.035721  0.824561  0.103976   \n",
       "4   1.00  0.791026  0.025074   0.861813  0.077858  0.868421  0.110436   \n",
       "\n",
       "    f1_mean    f1_std  auc_mean  ...  fp_mean     fp_std  fn_mean     fn_std  \\\n",
       "0  0.886220  0.017046  0.785213  ...     13.4   2.880972     12.6   3.781534   \n",
       "1  0.885836  0.012141  0.742356  ...     18.4   5.899152      8.8   2.280351   \n",
       "2  0.889212  0.020520  0.773434  ...     15.2   4.969909     10.4   7.765307   \n",
       "3  0.851231  0.042561  0.767043  ...     12.2   5.848077     20.0  11.853270   \n",
       "4  0.856978  0.026879  0.724687  ...     17.6  11.886968     15.0  12.589678   \n",
       "\n",
       "   tp_mean     tp_std  added_class0_synth_total_mean  \\\n",
       "0    101.4   3.781534                          252.0   \n",
       "1    105.2   2.280351                          315.0   \n",
       "2    103.6   7.765307                          378.0   \n",
       "3     94.0  11.853270                          441.0   \n",
       "4     99.0  12.589678                          504.0   \n",
       "\n",
       "   added_class0_synth_total_std  added_this_round_mean  added_this_round_std  \n",
       "0                           0.0                  252.0                   0.0  \n",
       "1                           0.0                  315.0                   0.0  \n",
       "2                           0.0                  378.0                   0.0  \n",
       "3                           0.0                  441.0                   0.0  \n",
       "4                           0.0                  504.0                   0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1260x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: auc_by_ratio_lollipop.png | error=std\n"
     ]
    }
   ],
   "source": [
    "plot_auc_lollipop_by_ratio(df_all_bal, error=\"std\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

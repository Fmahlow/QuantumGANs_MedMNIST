{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85df51d3",
   "metadata": {},
   "source": [
    "# Balanceamento da Classe 0 com GANs Cl\u00e1ssicosEste notebook reproduz o pipeline definido em `balance_class0_runs.py`, estruturando-o em c\u00e9lulaspara facilitar a experimenta\u00e7\u00e3o iterativa. O fluxo completo executa as seguintes etapas:1. Treina um DCGAN para a classe 0 do conjunto escolhido do MedMNIST.2. Gera amostras sint\u00e9ticas para balancear as classes.3. Treina diversas vezes um classificador ResNet-18 sobre o conjunto balanceado.4. Registra m\u00e9tricas e estat\u00edsticas agregadas.Configure os par\u00e2metros na se\u00e7\u00e3o **Execu\u00e7\u00e3o do experimento** para repetir os ensaios desejados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c236319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa\u00e7\u00f5es futuras\n",
    "from __future__ import annotations\n",
    "\n",
    "# Importa\u00e7\u00f5es padr\u00e3o\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Sequence, Tuple\n",
    "\n",
    "# Bibliotecas cient\u00edficas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "# TorchVision\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# M\u00f3dulos personalizados\n",
    "from classical_gans import (\n",
    "    CGANDiscriminator,\n",
    "    CGANGenerator,\n",
    "    DCDiscriminator,\n",
    "    DCGenerator,\n",
    "    WGANGPCritic,\n",
    "    WGANGPGenerator,\n",
    "    train_cgan,\n",
    "    train_gan_for_class,\n",
    "    train_wgangp,\n",
    ")\n",
    "from medmnist_data import load_medmnist_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96863de8-3c80-46ff-9024-914f645b7563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Constantes e dataclasses auxiliares\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# M\u00e9tricas de classifica\u00e7\u00e3o\n",
    "CLASSIFICATION_METRICS = [\n",
    "    \"acc\", \"prec\", \"rec\", \"f1\", \"auc\", \"tn\", \"fp\", \"fn\", \"tp\"\n",
    "]\n",
    "\n",
    "# M\u00e9tricas de tempo\n",
    "TIME_METRICS = [\n",
    "    \"gan_training_time_sec\",\n",
    "    \"synthetic_generation_time_sec\",\n",
    "    \"classifier_training_time_sec\",\n",
    "    \"classifier_eval_time_sec\",\n",
    "]\n",
    "\n",
    "# Campos num\u00e9ricos adicionais\n",
    "ADDITIONAL_NUMERIC_FIELDS = [\n",
    "    \"ratio\",\n",
    "    \"synthetic_class0_count\",\n",
    "    \"balanced_dataset_size\",\n",
    "    \"total_real_samples\",\n",
    "    \"real_class0_count\",\n",
    "    \"real_class1_count\",\n",
    "]\n",
    "\n",
    "# Campos agregados\n",
    "AGGREGATION_FIELDS = CLASSIFICATION_METRICS + TIME_METRICS + ADDITIONAL_NUMERIC_FIELDS\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Dataclasses auxiliares\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class StrategySpec:\n",
    "    \"\"\"Define uma estrat\u00e9gia de balanceamento utilizada nos experimentos.\"\"\"\n",
    "\n",
    "    key: str\n",
    "    display_name: str\n",
    "    uses_gan: bool = False\n",
    "    conditional_label: Optional[int] = None\n",
    "\n",
    "\n",
    "BALANCING_STRATEGIES: List[StrategySpec] = [\n",
    "    StrategySpec(\"baseline\", \"ResNet sem balanceamento\"),\n",
    "    StrategySpec(\"dcgan\", \"DCGAN (classe 0)\", uses_gan=True, conditional_label=0),\n",
    "    StrategySpec(\"cgan\", \"CGAN (classe 0)\", uses_gan=True, conditional_label=0),\n",
    "    StrategySpec(\"wgan\", \"WGAN-GP (classe 0)\", uses_gan=True, conditional_label=0),\n",
    "    StrategySpec(\"smote\", \"SMOTE (classe 0)\"),\n",
    "    StrategySpec(\"undersample\", \"Undersampling da classe 1\"),\n",
    "    StrategySpec(\"oversample\", \"Oversampling por repeti\u00e7\u00e3o (classe 0)\"),\n",
    "]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    \"\"\"Configura\u00e7\u00e3o do experimento multietapas.\"\"\"\n",
    "\n",
    "    data_flag: str = \"breastmnist\"\n",
    "    data_batch_size: int = 128\n",
    "    latent_dim: int = 100\n",
    "    gan_epochs: int = 50\n",
    "    classifier_epochs: int = 5\n",
    "    num_gan_runs: int = 10\n",
    "    num_generation_runs: int = 10\n",
    "    num_classifier_runs: int = 10\n",
    "    classifier_batch_size: int = 64\n",
    "    device: Optional[str] = None\n",
    "    base_seed: int = 2024\n",
    "    output_dir: Path = Path(\"balance_class0_runs\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class StageSeeds:\n",
    "    \"\"\"Agrupa as sementes de (GAN, gera\u00e7\u00e3o, classificador) para cada execu\u00e7\u00e3o.\"\"\"\n",
    "\n",
    "    gan_seed: int\n",
    "    generation_seed: int\n",
    "    classifier_seed: int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efa6d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Fun\u00e7\u00f5es utilit\u00e1rias\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "from typing import Optional, Dict, List, Tuple\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "\n",
    "\n",
    "def _resolve_device(device: Optional[str]) -> torch.device:\n",
    "    \"\"\"Seleciona automaticamente o dispositivo (CPU ou GPU).\"\"\"\n",
    "    if device is None or device == \"auto\":\n",
    "        return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    return torch.device(device)\n",
    "\n",
    "\n",
    "def _seed_everything(seed: int) -> None:\n",
    "    \"\"\"Define todas as sementes aleat\u00f3rias para reprodutibilidade.\"\"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def _to_scalar(y: Tensor | np.ndarray | int | float) -> int:\n",
    "    \"\"\"Converte um tensor, array ou n\u00famero em escalar inteiro.\"\"\"\n",
    "    if isinstance(y, torch.Tensor):\n",
    "        return int(y.detach().view(-1)[0].item())\n",
    "    y_np = np.asarray(y)\n",
    "    return int(y_np.reshape(-1)[0].item())\n",
    "\n",
    "\n",
    "def count_class_samples(dataset: Dataset) -> Dict[int, int]:\n",
    "    \"\"\"Conta o n\u00famero de amostras por classe em um dataset PyTorch.\"\"\"\n",
    "    counts: Dict[int, int] = {}\n",
    "    for _, label in dataset:\n",
    "        label_int = _to_scalar(label)\n",
    "        counts[label_int] = counts.get(label_int, 0) + 1\n",
    "    return counts\n",
    "\n",
    "\n",
    "def tensorize_dataset(dataset: Dataset) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"Converte um ``Dataset`` em tensores (imagens, r\u00f3tulos).\"\"\"\n",
    "    images: List[Tensor] = []\n",
    "    labels: List[int] = []\n",
    "\n",
    "    for img, label in dataset:\n",
    "        if not isinstance(img, torch.Tensor):\n",
    "            img = torch.as_tensor(img)\n",
    "        images.append(img.to(torch.float32))\n",
    "        labels.append(_to_scalar(label))\n",
    "\n",
    "    stacked_images = torch.stack(images, dim=0)\n",
    "    stacked_labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return stacked_images, stacked_labels\n",
    "\n",
    "\n",
    "def compute_class_ratio(labels: Tensor) -> float:\n",
    "    \"\"\"Retorna a propor\u00e7\u00e3o da classe 0 em rela\u00e7\u00e3o ao total de exemplos.\"\"\"\n",
    "    if labels.numel() == 0:\n",
    "        return float(\"nan\")\n",
    "    class0 = (labels == 0).sum().item()\n",
    "    return float(class0 / labels.numel())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f67c2ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Manipula\u00e7\u00e3o de dados\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "from typing import Sequence, Tuple, List, Optional\n",
    "import time\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "\n",
    "def custom_collate_fn(batch: Sequence[Tuple[Tensor, Tensor]]) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Fun\u00e7\u00e3o de colagem personalizada para DataLoader.\n",
    "    Concatena imagens e converte r\u00f3tulos (tensors ou inteiros) em tensores de inteiros.\n",
    "    \"\"\"\n",
    "    images, labels = zip(*batch)\n",
    "    xs = torch.stack(images, dim=0)\n",
    "    ys_list: List[int] = []\n",
    "\n",
    "    for label in labels:\n",
    "        if isinstance(label, torch.Tensor):\n",
    "            if label.numel() == 1:\n",
    "                ys_list.append(int(label.item()))\n",
    "            else:\n",
    "                ys_list.append(int(label.argmax().item()))\n",
    "        else:\n",
    "            ys_list.append(int(label))\n",
    "\n",
    "    ys = torch.tensor(ys_list, dtype=torch.long)\n",
    "    return xs, ys\n",
    "\n",
    "\n",
    "def _generate_gan_samples(\n",
    "    generator: nn.Module,\n",
    "    *,\n",
    "    latent_dim: int,\n",
    "    sample_count: int,\n",
    "    device: torch.device,\n",
    "    seed: int,\n",
    "    conditional_label: Optional[int] = None,\n",
    ") -> Tensor:\n",
    "    \"\"\"Gera amostras sint\u00e9ticas utilizando um gerador treinado.\"\"\"\n",
    "    if sample_count <= 0:\n",
    "        raise ValueError(\"sample_count deve ser positivo para gera\u00e7\u00e3o de amostras\")\n",
    "\n",
    "    _seed_everything(seed)\n",
    "    generator = generator.to(device).eval()\n",
    "\n",
    "    noise = torch.randn(sample_count, latent_dim, 1, 1, device=device, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if conditional_label is not None:\n",
    "            labels = torch.full((sample_count,), conditional_label, device=device, dtype=torch.long)\n",
    "            synth_imgs = generator(noise, labels)\n",
    "        else:\n",
    "            synth_imgs = generator(noise)\n",
    "\n",
    "    if synth_imgs.dim() == 3:\n",
    "        synth_imgs = synth_imgs.unsqueeze(1)\n",
    "\n",
    "    return synth_imgs.to(torch.float32).cpu()\n",
    "\n",
    "\n",
    "def build_baseline_dataset(images: Tensor, labels: Tensor) -> Tuple[TensorDataset, int, float, float]:\n",
    "    \"\"\"Retorna o dataset original sem modifica\u00e7\u00f5es.\"\"\"\n",
    "    dataset = TensorDataset(images, labels)\n",
    "    ratio = compute_class_ratio(labels)\n",
    "    return dataset, 0, ratio, 0.0\n",
    "\n",
    "\n",
    "def build_gan_balanced_dataset(\n",
    "    images: Tensor,\n",
    "    labels: Tensor,\n",
    "    generator: nn.Module,\n",
    "    *,\n",
    "    latent_dim: int,\n",
    "    synthetic_count: int,\n",
    "    device: torch.device,\n",
    "    seed: int,\n",
    "    conditional_label: Optional[int] = None,\n",
    ") -> Tuple[TensorDataset, int, float, float]:\n",
    "    \"\"\"Balanceia o dataset adicionando amostras sint\u00e9ticas geradas por GAN.\"\"\"\n",
    "    if synthetic_count <= 0:\n",
    "        return build_baseline_dataset(images, labels)\n",
    "\n",
    "    start = time.time()\n",
    "    synth_imgs = _generate_gan_samples(\n",
    "        generator,\n",
    "        latent_dim=latent_dim,\n",
    "        sample_count=synthetic_count,\n",
    "        device=device,\n",
    "        seed=seed,\n",
    "        conditional_label=conditional_label,\n",
    "    )\n",
    "    synth_labels = torch.zeros(synthetic_count, dtype=torch.long)\n",
    "\n",
    "    balanced_images = torch.cat([images, synth_imgs], dim=0)\n",
    "    balanced_labels = torch.cat([labels, synth_labels], dim=0)\n",
    "    ratio = compute_class_ratio(balanced_labels)\n",
    "\n",
    "    dataset = TensorDataset(balanced_images, balanced_labels)\n",
    "    elapsed = time.time() - start\n",
    "    return dataset, synthetic_count, ratio, elapsed\n",
    "\n",
    "\n",
    "def build_smote_dataset(\n",
    "    images: Tensor,\n",
    "    labels: Tensor,\n",
    "    *,\n",
    "    target_minority: int,\n",
    "    seed: int,\n",
    ") -> Tuple[TensorDataset, int, float, float]:\n",
    "    \"\"\"Aplica SMOTE na classe 0 at\u00e9 atingir ``target_minority`` exemplos.\"\"\"\n",
    "    minority_mask = labels == 0\n",
    "    minority_images = images[minority_mask]\n",
    "    minority_count = minority_images.size(0)\n",
    "    synthetic_count = max(0, target_minority - minority_count)\n",
    "\n",
    "    if synthetic_count <= 0:\n",
    "        return build_baseline_dataset(images, labels)\n",
    "\n",
    "    start = time.time()\n",
    "    flat_minority = minority_images.view(minority_count, -1).cpu().numpy()\n",
    "\n",
    "    if minority_count == 1:\n",
    "        synthetic_flat = np.repeat(flat_minority, synthetic_count, axis=0)\n",
    "    else:\n",
    "        from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "        k_neighbors = min(5, minority_count)\n",
    "        nbrs = NearestNeighbors(n_neighbors=k_neighbors)\n",
    "        nbrs.fit(flat_minority)\n",
    "\n",
    "        rng = np.random.default_rng(seed)\n",
    "        base_indices = rng.integers(0, minority_count, size=synthetic_count)\n",
    "        neighbor_choices = nbrs.kneighbors(flat_minority[base_indices], return_distance=False)\n",
    "        neighbor_indices = rng.integers(1, neighbor_choices.shape[1], size=synthetic_count)\n",
    "\n",
    "        diffs = flat_minority[neighbor_choices[np.arange(synthetic_count), neighbor_indices]] - flat_minority[base_indices]\n",
    "        steps = rng.random((synthetic_count, flat_minority.shape[1]))\n",
    "        synthetic_flat = flat_minority[base_indices] + steps * diffs\n",
    "\n",
    "    synthetic_flat = np.clip(synthetic_flat, -1.0, 1.0)\n",
    "    synth_imgs = torch.from_numpy(synthetic_flat).view(-1, *images.shape[1:]).to(torch.float32)\n",
    "    synth_labels = torch.zeros(synthetic_count, dtype=torch.long)\n",
    "\n",
    "    balanced_images = torch.cat([images, synth_imgs], dim=0)\n",
    "    balanced_labels = torch.cat([labels, synth_labels], dim=0)\n",
    "    ratio = compute_class_ratio(balanced_labels)\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    dataset = TensorDataset(balanced_images, balanced_labels)\n",
    "    return dataset, synthetic_count, ratio, elapsed\n",
    "\n",
    "\n",
    "def build_undersampled_dataset(\n",
    "    images: Tensor,\n",
    "    labels: Tensor,\n",
    "    *,\n",
    "    minority_count: int,\n",
    "    seed: int,\n",
    ") -> Tuple[TensorDataset, int, float, float]:\n",
    "    \"\"\"Reduz a classe 1 para a quantidade de exemplos da classe minorit\u00e1ria.\"\"\"\n",
    "    start = time.time()\n",
    "    minority_indices = (labels == 0).nonzero(as_tuple=False).view(-1)\n",
    "    majority_indices = (labels == 1).nonzero(as_tuple=False).view(-1)\n",
    "\n",
    "    if majority_indices.numel() <= minority_count:\n",
    "        return build_baseline_dataset(images, labels)\n",
    "\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    perm = torch.randperm(majority_indices.numel(), generator=g)\n",
    "    selected_majority = majority_indices[perm[:minority_count]]\n",
    "\n",
    "    selected_indices = torch.cat([minority_indices, selected_majority], dim=0)\n",
    "    balanced_images = images[selected_indices]\n",
    "    balanced_labels = labels[selected_indices]\n",
    "    ratio = compute_class_ratio(balanced_labels)\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    dataset = TensorDataset(balanced_images, balanced_labels)\n",
    "    return dataset, 0, ratio, elapsed\n",
    "\n",
    "\n",
    "def build_oversampled_dataset(\n",
    "    images: Tensor,\n",
    "    labels: Tensor,\n",
    "    *,\n",
    "    target_minority: int,\n",
    "    seed: int,\n",
    ") -> Tuple[TensorDataset, int, float, float]:\n",
    "    \"\"\"Replica amostras da classe 0 at\u00e9 atingir ``target_minority`` exemplos.\"\"\"\n",
    "    minority_indices = (labels == 0).nonzero(as_tuple=False).view(-1)\n",
    "    minority_count = minority_indices.numel()\n",
    "    additional = max(0, target_minority - minority_count)\n",
    "\n",
    "    if additional <= 0 or minority_count == 0:\n",
    "        return build_baseline_dataset(images, labels)\n",
    "\n",
    "    start = time.time()\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    rand_indices = torch.randint(0, minority_count, (additional,), generator=g)\n",
    "    sampled_indices = minority_indices[rand_indices]\n",
    "\n",
    "    synth_images = images[sampled_indices]\n",
    "    synth_labels = labels[sampled_indices]\n",
    "\n",
    "    balanced_images = torch.cat([images, synth_images], dim=0)\n",
    "    balanced_labels = torch.cat([labels, synth_labels], dim=0)\n",
    "    ratio = compute_class_ratio(balanced_labels)\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    dataset = TensorDataset(balanced_images, balanced_labels)\n",
    "    return dataset, additional, ratio, elapsed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f9ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Treinamento\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Optional\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def train_class0_gan(\n",
    "    train_loader: DataLoader,\n",
    "    *,\n",
    "    latent_dim: int,\n",
    "    gan_epochs: int,\n",
    "    device: torch.device,\n",
    "    seed: int,\n",
    "    img_channels: int,\n",
    ") -> Tuple[nn.Module, float]:\n",
    "    \"\"\"\n",
    "    Treina um DCGAN para a classe 0 e retorna o gerador treinado e o tempo de execu\u00e7\u00e3o.\n",
    "\n",
    "    Args:\n",
    "        train_loader: DataLoader com amostras reais da classe 0.\n",
    "        latent_dim: Dimens\u00e3o do vetor latente de entrada do gerador.\n",
    "        gan_epochs: N\u00famero de \u00e9pocas de treino do GAN.\n",
    "        device: Dispositivo (CPU/GPU).\n",
    "        seed: Semente aleat\u00f3ria para reprodutibilidade.\n",
    "        img_channels: N\u00famero de canais da imagem (ex: 1 para grayscale, 3 para RGB).\n",
    "\n",
    "    Returns:\n",
    "        generator: Modelo gerador treinado.\n",
    "        elapsed: Tempo total de treinamento (em segundos).\n",
    "    \"\"\"\n",
    "    _seed_everything(seed)\n",
    "    start = time.time()\n",
    "\n",
    "    generator = DCGenerator(latent_dim=latent_dim, img_channels=img_channels).to(device)\n",
    "    discriminator = DCDiscriminator(img_channels=img_channels).to(device)\n",
    "\n",
    "    generator = train_gan_for_class(\n",
    "        train_loader=train_loader,\n",
    "        label_target=0,\n",
    "        G=generator,\n",
    "        D=discriminator,\n",
    "        latent_dim=latent_dim,\n",
    "        num_epochs=gan_epochs,\n",
    "        device=device,\n",
    "    ).eval()\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    return generator, elapsed\n",
    "\n",
    "\n",
    "def train_class0_cgan(\n",
    "    train_loader: DataLoader,\n",
    "    *,\n",
    "    latent_dim: int,\n",
    "    gan_epochs: int,\n",
    "    device: torch.device,\n",
    "    seed: int,\n",
    "    img_channels: int,\n",
    "    num_classes: int,\n",
    ") -> Tuple[nn.Module, float]:\n",
    "    \"\"\"Treina um CGAN focado na classe 0.\"\"\"\n",
    "    _seed_everything(seed)\n",
    "    start = time.time()\n",
    "\n",
    "    generator = CGANGenerator(\n",
    "        latent_dim=latent_dim,\n",
    "        num_classes=num_classes,\n",
    "        img_channels=img_channels,\n",
    "    ).to(device)\n",
    "    discriminator = CGANDiscriminator(\n",
    "        num_classes=num_classes,\n",
    "        img_channels=img_channels,\n",
    "    ).to(device)\n",
    "\n",
    "    generator = train_cgan(\n",
    "        train_loader=train_loader,\n",
    "        G=generator,\n",
    "        D=discriminator,\n",
    "        latent_dim=latent_dim,\n",
    "        num_classes=num_classes,\n",
    "        num_epochs=gan_epochs,\n",
    "        device=device,\n",
    "        label_target=0,\n",
    "    ).eval()\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    return generator, elapsed\n",
    "\n",
    "\n",
    "def train_class0_wgan(\n",
    "    train_loader: DataLoader,\n",
    "    *,\n",
    "    latent_dim: int,\n",
    "    gan_epochs: int,\n",
    "    device: torch.device,\n",
    "    seed: int,\n",
    "    img_channels: int,\n",
    ") -> Tuple[nn.Module, float]:\n",
    "    \"\"\"Treina um WGAN-GP restrito \u00e0 classe 0.\"\"\"\n",
    "    _seed_everything(seed)\n",
    "    start = time.time()\n",
    "\n",
    "    generator = WGANGPGenerator(latent_dim=latent_dim, img_channels=img_channels).to(device)\n",
    "    critic = WGANGPCritic(img_channels=img_channels).to(device)\n",
    "\n",
    "    generator = train_wgangp(\n",
    "        train_loader=train_loader,\n",
    "        G=generator,\n",
    "        D=critic,\n",
    "        latent_dim=latent_dim,\n",
    "        num_epochs=gan_epochs,\n",
    "        device=device,\n",
    "        label_target=0,\n",
    "    ).eval()\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    return generator, elapsed\n",
    "\n",
    "\n",
    "def train_gan_for_strategy(\n",
    "    strategy: StrategySpec,\n",
    "    train_loader: DataLoader,\n",
    "    *,\n",
    "    latent_dim: int,\n",
    "    gan_epochs: int,\n",
    "    device: torch.device,\n",
    "    seed: int,\n",
    "    img_channels: int,\n",
    "    num_classes: int,\n",
    ") -> Tuple[Optional[nn.Module], float]:\n",
    "    \"\"\"Seleciona e treina o gerador adequado para a estrat\u00e9gia informada.\"\"\"\n",
    "    if not strategy.uses_gan:\n",
    "        return None, 0.0\n",
    "\n",
    "    if strategy.key == \"dcgan\":\n",
    "        return train_class0_gan(\n",
    "            train_loader,\n",
    "            latent_dim=latent_dim,\n",
    "            gan_epochs=gan_epochs,\n",
    "            device=device,\n",
    "            seed=seed,\n",
    "            img_channels=img_channels,\n",
    "        )\n",
    "    if strategy.key == \"cgan\":\n",
    "        return train_class0_cgan(\n",
    "            train_loader,\n",
    "            latent_dim=latent_dim,\n",
    "            gan_epochs=gan_epochs,\n",
    "            device=device,\n",
    "            seed=seed,\n",
    "            img_channels=img_channels,\n",
    "            num_classes=num_classes,\n",
    "        )\n",
    "    if strategy.key == \"wgan\":\n",
    "        return train_class0_wgan(\n",
    "            train_loader,\n",
    "            latent_dim=latent_dim,\n",
    "            gan_epochs=gan_epochs,\n",
    "            device=device,\n",
    "            seed=seed,\n",
    "            img_channels=img_channels,\n",
    "        )\n",
    "\n",
    "    raise ValueError(f\"Estrat\u00e9gia desconhecida para treinamento de GAN: {strategy.key}\")\n",
    "\n",
    "\n",
    "def train_classifier(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    *,\n",
    "    epochs: int,\n",
    "    device: torch.device,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Treina um classificador supervisionado usando Cross-Entropy Loss.\n",
    "\n",
    "    Args:\n",
    "        model: Rede neural PyTorch.\n",
    "        loader: DataLoader com os dados de treino.\n",
    "        epochs: N\u00famero de \u00e9pocas de treinamento.\n",
    "        device: Dispositivo (CPU/GPU).\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def evaluate_classifier(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    *,\n",
    "    device: torch.device,\n",
    ") -> Tuple[float, float, float, float, float, int, int, int, int]:\n",
    "    \"\"\"\n",
    "    Avalia o classificador em um conjunto de dados e calcula m\u00e9tricas de desempenho.\"\"\"\n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score,\n",
    "        confusion_matrix,\n",
    "        f1_score,\n",
    "        precision_score,\n",
    "        recall_score,\n",
    "        roc_auc_score,\n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    preds: List[Tensor] = []\n",
    "    labels: List[Tensor] = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            out = model(x)\n",
    "            preds.append(out.argmax(dim=1).cpu())\n",
    "            labels.append(y)\n",
    "\n",
    "    y_true = torch.cat(labels).numpy()\n",
    "    y_pred = torch.cat(preds).numpy()\n",
    "\n",
    "    def _safe_metric(func, default=np.nan):\n",
    "        try:\n",
    "            return float(func(y_true, y_pred))\n",
    "        except Exception:\n",
    "            return float(default)\n",
    "\n",
    "    acc = _safe_metric(accuracy_score)\n",
    "    prec = _safe_metric(lambda yt, yp: precision_score(yt, yp, zero_division=0))\n",
    "    rec = _safe_metric(lambda yt, yp: recall_score(yt, yp, zero_division=0))\n",
    "    f1 = _safe_metric(lambda yt, yp: f1_score(yt, yp, zero_division=0))\n",
    "    auc = _safe_metric(roc_auc_score, default=np.nan)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    return acc, prec, rec, f1, auc, int(tn), int(fp), int(fn), int(tp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Execu\u00e7\u00e3o do experimento\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Fun\u00e7\u00f5es auxiliares\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def compute_stage_seeds(\n",
    "    config: ExperimentConfig,\n",
    "    strategy_index: int,\n",
    "    gan_id: int,\n",
    "    gen_id: int,\n",
    "    clf_id: int,\n",
    ") -> StageSeeds:\n",
    "    \"\"\"Gera sementes determin\u00edsticas para as tr\u00eas fases do experimento.\"\"\"\n",
    "    base = config.base_seed + strategy_index * 10_000_000\n",
    "    gan_seed = base + gan_id\n",
    "    generation_seed = base + 1_000 * gan_id + gen_id\n",
    "    classifier_seed = base + 1_000_000 * gan_id + 1_000 * gen_id + clf_id\n",
    "    return StageSeeds(\n",
    "        gan_seed=gan_seed,\n",
    "        generation_seed=generation_seed,\n",
    "        classifier_seed=classifier_seed,\n",
    "    )\n",
    "\n",
    "\n",
    "def prepare_resnet(device: torch.device) -> nn.Module:\n",
    "    \"\"\"Cria e retorna uma inst\u00e2ncia de ResNet18 adaptada para imagens monocanais (1 canal).\"\"\"\n",
    "    model = resnet18(num_classes=2)\n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Pipeline principal de execu\u00e7\u00e3o\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def run_balance_experiments(config: ExperimentConfig) -> Tuple[pd.DataFrame, Dict[str, pd.DataFrame], Dict[str, object]]:\n",
    "    \"\"\"\n",
    "    Executa o pipeline completo de balanceamento com diferentes estrat\u00e9gias.\"\"\"\n",
    "    device = _resolve_device(config.device)\n",
    "\n",
    "    bundle = load_medmnist_data(\n",
    "        data_flag=config.data_flag,\n",
    "        batch_size=config.data_batch_size,\n",
    "        download=True,\n",
    "    )\n",
    "\n",
    "    train_dataset = bundle.train_dataset\n",
    "    test_dataset = bundle.test_dataset\n",
    "    train_loader = bundle.train_loader\n",
    "    eval_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config.classifier_batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=device.type == \"cuda\",\n",
    "        drop_last=False,\n",
    "        collate_fn=custom_collate_fn,\n",
    "    )\n",
    "\n",
    "    images, labels = tensorize_dataset(train_dataset)\n",
    "    base_dataset = TensorDataset(images, labels)\n",
    "\n",
    "    counts = count_class_samples(base_dataset)\n",
    "    real_class0 = counts.get(0, 0)\n",
    "    real_class1 = counts.get(1, 0)\n",
    "    total_real_samples = len(base_dataset)\n",
    "    deficit = max(0, real_class1 - real_class0)\n",
    "\n",
    "    results: List[Dict[str, object]] = []\n",
    "    img_channels = images.shape[1]\n",
    "    num_classes = bundle.num_classes if hasattr(bundle, \"num_classes\") else 2\n",
    "\n",
    "    strategy_order = {spec.key: idx for idx, spec in enumerate(BALANCING_STRATEGIES, start=1)}\n",
    "    strategy_names = {spec.key: spec.display_name for spec in BALANCING_STRATEGIES}\n",
    "\n",
    "    for strategy_idx, strategy in enumerate(BALANCING_STRATEGIES, start=1):\n",
    "        for gan_run in range(1, config.num_gan_runs + 1):\n",
    "            seeds_for_gan = compute_stage_seeds(config, strategy_idx, gan_run, 0, 0)\n",
    "            generator = None\n",
    "            gan_time = 0.0\n",
    "\n",
    "            if strategy.uses_gan:\n",
    "                generator, gan_time = train_gan_for_strategy(\n",
    "                    strategy,\n",
    "                    train_loader,\n",
    "                    latent_dim=config.latent_dim,\n",
    "                    gan_epochs=config.gan_epochs,\n",
    "                    device=device,\n",
    "                    seed=seeds_for_gan.gan_seed,\n",
    "                    img_channels=img_channels,\n",
    "                    num_classes=num_classes,\n",
    "                )\n",
    "\n",
    "            try:\n",
    "                for gen_run in range(1, config.num_generation_runs + 1):\n",
    "                    seeds_for_generation = compute_stage_seeds(\n",
    "                        config, strategy_idx, gan_run, gen_run, 0\n",
    "                    )\n",
    "\n",
    "                    if strategy.key == \"baseline\":\n",
    "                        balanced_dataset, synth_count, ratio, generation_time = build_baseline_dataset(\n",
    "                            images, labels\n",
    "                        )\n",
    "                    elif strategy.key in {\"dcgan\", \"cgan\", \"wgan\"}:\n",
    "                        balanced_dataset, synth_count, ratio, generation_time = build_gan_balanced_dataset(\n",
    "                            images,\n",
    "                            labels,\n",
    "                            generator,\n",
    "                            latent_dim=config.latent_dim,\n",
    "                            synthetic_count=deficit,\n",
    "                            device=device,\n",
    "                            seed=seeds_for_generation.generation_seed,\n",
    "                            conditional_label=strategy.conditional_label,\n",
    "                        )\n",
    "                    elif strategy.key == \"smote\":\n",
    "                        balanced_dataset, synth_count, ratio, generation_time = build_smote_dataset(\n",
    "                            images,\n",
    "                            labels,\n",
    "                            target_minority=real_class1,\n",
    "                            seed=seeds_for_generation.generation_seed,\n",
    "                        )\n",
    "                    elif strategy.key == \"undersample\":\n",
    "                        balanced_dataset, synth_count, ratio, generation_time = build_undersampled_dataset(\n",
    "                            images,\n",
    "                            labels,\n",
    "                            minority_count=real_class0,\n",
    "                            seed=seeds_for_generation.generation_seed,\n",
    "                        )\n",
    "                    elif strategy.key == \"oversample\":\n",
    "                        balanced_dataset, synth_count, ratio, generation_time = build_oversampled_dataset(\n",
    "                            images,\n",
    "                            labels,\n",
    "                            target_minority=real_class1,\n",
    "                            seed=seeds_for_generation.generation_seed,\n",
    "                        )\n",
    "                    else:\n",
    "                        raise ValueError(f\"Estrat\u00e9gia de balanceamento desconhecida: {strategy.key}\")\n",
    "\n",
    "                    loader = DataLoader(\n",
    "                        balanced_dataset,\n",
    "                        batch_size=config.classifier_batch_size,\n",
    "                        shuffle=True,\n",
    "                        pin_memory=device.type == \"cuda\",\n",
    "                        drop_last=False,\n",
    "                        collate_fn=custom_collate_fn,\n",
    "                    )\n",
    "\n",
    "                    for clf_run in range(1, config.num_classifier_runs + 1):\n",
    "                        seeds = compute_stage_seeds(\n",
    "                            config, strategy_idx, gan_run, gen_run, clf_run\n",
    "                        )\n",
    "                        _seed_everything(seeds.classifier_seed)\n",
    "\n",
    "                        model = prepare_resnet(device)\n",
    "\n",
    "                        train_start = time.time()\n",
    "                        train_classifier(\n",
    "                            model,\n",
    "                            loader,\n",
    "                            epochs=config.classifier_epochs,\n",
    "                            device=device,\n",
    "                        )\n",
    "                        train_time = time.time() - train_start\n",
    "\n",
    "                        eval_start = time.time()\n",
    "                        acc, prec, rec, f1, auc, tn, fp, fn, tp = evaluate_classifier(\n",
    "                            model,\n",
    "                            eval_loader,\n",
    "                            device=device,\n",
    "                        )\n",
    "                        eval_time = time.time() - eval_start\n",
    "\n",
    "                        result = {\n",
    "                            \"strategy\": strategy.key,\n",
    "                            \"strategy_display_name\": strategy.display_name,\n",
    "                            \"strategy_index\": strategy_order[strategy.key],\n",
    "                            \"gan_run_id\": gan_run,\n",
    "                            \"generation_run_id\": gen_run,\n",
    "                            \"classifier_run_id\": clf_run,\n",
    "                            \"ratio\": ratio,\n",
    "                            \"acc\": acc,\n",
    "                            \"prec\": prec,\n",
    "                            \"rec\": rec,\n",
    "                            \"f1\": f1,\n",
    "                            \"auc\": auc,\n",
    "                            \"tn\": tn,\n",
    "                            \"fp\": fp,\n",
    "                            \"fn\": fn,\n",
    "                            \"tp\": tp,\n",
    "                            \"synthetic_class0_count\": synth_count,\n",
    "                            \"balanced_dataset_size\": len(balanced_dataset),\n",
    "                            \"total_real_samples\": total_real_samples,\n",
    "                            \"real_class0_count\": real_class0,\n",
    "                            \"real_class1_count\": real_class1,\n",
    "                            \"gan_training_time_sec\": gan_time,\n",
    "                            \"synthetic_generation_time_sec\": generation_time,\n",
    "                            \"classifier_training_time_sec\": train_time,\n",
    "                            \"classifier_eval_time_sec\": eval_time,\n",
    "                            \"gan_seed\": seeds_for_gan.gan_seed,\n",
    "                            \"generation_seed\": seeds_for_generation.generation_seed,\n",
    "                            \"classifier_seed\": seeds.classifier_seed,\n",
    "                        }\n",
    "\n",
    "                        results.append(result)\n",
    "            finally:\n",
    "                if generator is not None:\n",
    "                    generator.cpu()\n",
    "                    del generator\n",
    "                    if device.type == \"cuda\":\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "\n",
    "    summary_tables: Dict[str, pd.DataFrame] = {\n",
    "        \"overall\": aggregate_metrics(df_results, []),\n",
    "        \"by_gan\": aggregate_metrics(df_results, [\"strategy\", \"gan_run_id\"]),\n",
    "        \"by_gan_generation\": aggregate_metrics(\n",
    "            df_results, [\"strategy\", \"gan_run_id\", \"generation_run_id\"]\n",
    "        ),\n",
    "        \"by_strategy\": aggregate_metrics(df_results, [\"strategy\"]),\n",
    "    }\n",
    "\n",
    "    summary = summary_tables[\"by_strategy\"]\n",
    "    if not summary.empty:\n",
    "        summary[\"strategy_display_name\"] = summary[\"strategy\"].map(strategy_names)\n",
    "        summary[\"strategy_order\"] = summary[\"strategy\"].map(strategy_order)\n",
    "        summary = summary.sort_values(\"strategy_order\").drop(columns=[\"strategy_order\"])\n",
    "        cols = [\n",
    "            \"strategy_display_name\",\n",
    "            \"strategy\",\n",
    "        ] + [c for c in summary.columns if c not in {\"strategy_display_name\", \"strategy\"}]\n",
    "        summary_tables[\"by_strategy\"] = summary[cols]\n",
    "\n",
    "    metadata: Dict[str, object] = {\n",
    "        \"data_flag\": config.data_flag,\n",
    "        \"latent_dim\": config.latent_dim,\n",
    "        \"gan_epochs\": config.gan_epochs,\n",
    "        \"classifier_epochs\": config.classifier_epochs,\n",
    "        \"num_gan_runs\": config.num_gan_runs,\n",
    "        \"num_generation_runs\": config.num_generation_runs,\n",
    "        \"num_classifier_runs\": config.num_classifier_runs,\n",
    "        \"classifier_batch_size\": config.classifier_batch_size,\n",
    "        \"data_batch_size\": config.data_batch_size,\n",
    "        \"device\": str(device),\n",
    "        \"base_seed\": config.base_seed,\n",
    "        \"real_class0_count\": real_class0,\n",
    "        \"real_class1_count\": real_class1,\n",
    "        \"synthetic_needed_for_balance\": deficit,\n",
    "        \"total_real_samples\": total_real_samples,\n",
    "        \"strategies\": [spec.display_name for spec in BALANCING_STRATEGIES],\n",
    "        \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "    }\n",
    "\n",
    "    return df_results, summary_tables, metadata\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Agrega\u00e7\u00e3o de m\u00e9tricas\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def aggregate_metrics(df: pd.DataFrame, group_cols: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Agrega m\u00e9tricas de classifica\u00e7\u00e3o, tempo e estat\u00edsticas por grupo de execu\u00e7\u00f5es.\"\"\"\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=group_cols + [f\"{m}_mean\" for m in AGGREGATION_FIELDS])\n",
    "\n",
    "    grouped = df.groupby(group_cols) if group_cols else [((), df)]\n",
    "    rows: List[Dict[str, object]] = []\n",
    "\n",
    "    for key, group in grouped:\n",
    "        if not isinstance(key, tuple):\n",
    "            key = (key,)\n",
    "\n",
    "        row: Dict[str, object] = {}\n",
    "        for idx, col in enumerate(group_cols):\n",
    "            row[col] = key[idx]\n",
    "\n",
    "        row[\"num_rows\"] = len(group)\n",
    "\n",
    "        for metric in AGGREGATION_FIELDS:\n",
    "            if metric in group:\n",
    "                row[f\"{metric}_mean\"] = float(group[metric].mean())\n",
    "                row[f\"{metric}_std\"] = float(group[metric].std(ddof=0))\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc2f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Persist\u00eancia de resultados\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def save_results(\n",
    "    df_results: pd.DataFrame,\n",
    "    summary_tables: Dict[str, pd.DataFrame],\n",
    "    metadata: Dict[str, object],\n",
    "    output_dir: Path,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Salva os resultados do experimento (tabelas e metadados) em arquivos CSV e JSON.\n",
    "\n",
    "    Args:\n",
    "        df_results: DataFrame contendo os resultados detalhados de todas as execu\u00e7\u00f5es.\n",
    "        summary_tables: Dicion\u00e1rio com tabelas agregadas de m\u00e9tricas.\n",
    "        metadata: Dicion\u00e1rio com informa\u00e7\u00f5es da configura\u00e7\u00e3o e execu\u00e7\u00e3o do experimento.\n",
    "        output_dir: Diret\u00f3rio de sa\u00edda onde os arquivos ser\u00e3o salvos.\n",
    "\n",
    "    Sa\u00eddas:\n",
    "        - balance_class0_results.csv: Resultados completos.\n",
    "        - summary_*.csv: Tabelas de resumo (overall, por GAN, etc.).\n",
    "        - metadata.json: Informa\u00e7\u00f5es descritivas e par\u00e2metros da execu\u00e7\u00e3o.\n",
    "    \"\"\"\n",
    "    # Cria o diret\u00f3rio de sa\u00edda, se necess\u00e1rio\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Salva resultados completos\n",
    "    results_path = output_dir / \"balance_class0_results.csv\"\n",
    "    df_results.to_csv(results_path, index=False)\n",
    "\n",
    "    # Salva tabelas agregadas\n",
    "    for name, df in summary_tables.items():\n",
    "        df.to_csv(output_dir / f\"summary_{name}.csv\", index=False)\n",
    "\n",
    "    # Salva metadados como JSON\n",
    "    with open(output_dir / \"metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metadata, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f405194",
   "metadata": {},
   "source": [
    "## Execu\u00e7\u00e3o do experimento. Ajuste os hiperpar\u00e2metros abaixo conforme necess\u00e1rio. Dependendo dos valores escolhidos(as execu\u00e7\u00f5es padr\u00e3o s\u00e3o 10\u00d710\u00d710), o processo pode ser bastante demorado. Para testes r\u00e1pidos,reduza os contadores de repeti\u00e7\u00f5es e \u00e9pocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff0f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Exemplo de configura\u00e7\u00e3o enxuta para testes r\u00e1pidos\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    data_flag=\"breastmnist\",\n",
    "    data_batch_size=128,\n",
    "    latent_dim=100,\n",
    "    gan_epochs=50,\n",
    "    classifier_epochs=1,\n",
    "    num_gan_runs=1,\n",
    "    num_generation_runs=1,\n",
    "    num_classifier_runs=1,\n",
    "    classifier_batch_size=64,\n",
    "    device=\"auto\",\n",
    "    base_seed=2024,\n",
    "    output_dir=Path(\"balance_class0_runs_demo\"),\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Execu\u00e7\u00e3o opcional do pipeline completo\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Descomente as linhas abaixo para executar todo o experimento.\n",
    "# Isso ir\u00e1:\n",
    "# 1. Treinar os geradores necess\u00e1rios para cada estrat\u00e9gia (quando aplic\u00e1vel).\n",
    "# 2. Gerar datasets balanceados para cada abordagem.\n",
    "# 3. Treinar e avaliar diversas vezes o classificador ResNet-18.\n",
    "# 4. Salvar os resultados e metadados no diret\u00f3rio especificado.\n",
    "\n",
    "# df_results, summary_tables, metadata = run_balance_experiments(config)\n",
    "# save_results(df_results, summary_tables, metadata, config.output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8149d0-37b7-4491-bbe8-32721ecbdf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exiba os resultados agregados por estrat\u00e9gia ap\u00f3s executar o pipeline\n",
    "# summary_tables[\"by_strategy\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f209d4",
   "metadata": {},
   "source": [
    "## Utilit\u00e1rio de linha de comando (opcional)As fun\u00e7\u00f5es abaixo permitem reutilizar o parser de argumentos do script original, casoqueira invocar o notebook via `papermill` ou semelhante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712accba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Parser de argumentos para execu\u00e7\u00e3o program\u00e1tica\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def parse_args() -> ExperimentConfig:\n",
    "    \"\"\"\n",
    "    Cria e interpreta argumentos de linha de comando para configurar o experimento.\n",
    "\n",
    "    Em um notebook, o parse_args([]) evita erros por aus\u00eancia de argumentos\n",
    "    e retorna um objeto ExperimentConfig com valores padr\u00e3o ou definidos manualmente.\n",
    "\n",
    "    Returns:\n",
    "        ExperimentConfig: Objeto de configura\u00e7\u00e3o preenchido com os par\u00e2metros fornecidos.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Run repeated class-0 balancing experiments with DCGAN and ResNet-18\",\n",
    "    )\n",
    "\n",
    "    # Argumentos principais\n",
    "    parser.add_argument(\"--data-flag\", default=\"breastmnist\", help=\"MedMNIST dataset flag\")\n",
    "    parser.add_argument(\"--data-batch-size\", type=int, default=128, help=\"Batch size for the GAN data loader\")\n",
    "    parser.add_argument(\"--latent-dim\", type=int, default=100, help=\"Latent dimension for the GAN\")\n",
    "    parser.add_argument(\"--gan-epochs\", type=int, default=50, help=\"Number of epochs for GAN training\")\n",
    "    parser.add_argument(\n",
    "        \"--classifier-epochs\",\n",
    "        type=int,\n",
    "        default=5,\n",
    "        help=\"Number of epochs for each ResNet-18 training run\",\n",
    "    )\n",
    "    parser.add_argument(\"--num-gan-runs\", type=int, default=10, help=\"How many times to retrain the GAN\")\n",
    "    parser.add_argument(\n",
    "        \"--num-generation-runs\",\n",
    "        type=int,\n",
    "        default=10,\n",
    "        help=\"How many synthetic datasets to generate per GAN training\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num-classifier-runs\",\n",
    "        type=int,\n",
    "        default=10,\n",
    "        help=\"How many classifier trainings per synthetic dataset\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--classifier-batch-size\",\n",
    "        type=int,\n",
    "        default=64,\n",
    "        help=\"Batch size for the ResNet-18 training and evaluation\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\",\n",
    "        default=\"auto\",\n",
    "        help=\"Device to use (cuda, cpu or auto)\",\n",
    "    )\n",
    "    parser.add_argument(\"--base-seed\", type=int, default=2024, help=\"Base seed for reproducibility\")\n",
    "    parser.add_argument(\n",
    "        \"--output-dir\",\n",
    "        type=Path,\n",
    "        default=Path(\"balance_class0_runs\"),\n",
    "        help=\"Directory where CSV and metadata files will be stored\",\n",
    "    )\n",
    "\n",
    "    # parse_args([]) evita conflitos de CLI em ambientes interativos\n",
    "    args = parser.parse_args([])\n",
    "\n",
    "    return ExperimentConfig(\n",
    "        data_flag=args.data_flag,\n",
    "        data_batch_size=args.data_batch_size,\n",
    "        latent_dim=args.latent_dim,\n",
    "        gan_epochs=args.gan_epochs,\n",
    "        classifier_epochs=args.classifier_epochs,\n",
    "        num_gan_runs=args.num_gan_runs,\n",
    "        num_generation_runs=args.num_generation_runs,\n",
    "        num_classifier_runs=args.num_classifier_runs,\n",
    "        classifier_batch_size=args.classifier_batch_size,\n",
    "        device=args.device,\n",
    "        base_seed=args.base_seed,\n",
    "        output_dir=args.output_dir,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe515352-d686-41fc-871c-2ea7f4b4cd3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85df51d3",
   "metadata": {},
   "source": [
    "# Balanceamento da Classe 0 com GANs ClássicosEste notebook reproduz o pipeline definido em `balance_class0_runs.py`, estruturando-o em célulaspara facilitar a experimentação iterativa. O fluxo completo executa as seguintes etapas:1. Treina um DCGAN para a classe 0 do conjunto escolhido do MedMNIST.2. Gera amostras sintéticas para balancear as classes.3. Treina diversas vezes um classificador ResNet-18 sobre o conjunto balanceado.4. Registra métricas e estatísticas agregadas.Configure os parâmetros na seção **Execução do experimento** para repetir os ensaios desejados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c236319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações futuras\n",
    "from __future__ import annotations\n",
    "\n",
    "# Importações padrão\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Sequence, Tuple\n",
    "\n",
    "# Bibliotecas científicas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset, TensorDataset\n",
    "\n",
    "# TorchVision\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# Módulos personalizados\n",
    "from classical_gans import DCDiscriminator, DCGenerator, train_gan_for_class\n",
    "from medmnist_data import load_medmnist_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96863de8-3c80-46ff-9024-914f645b7563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Constantes e dataclasses auxiliares\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Métricas de classificação\n",
    "CLASSIFICATION_METRICS = [\n",
    "    \"acc\", \"prec\", \"rec\", \"f1\", \"auc\", \"tn\", \"fp\", \"fn\", \"tp\"\n",
    "]\n",
    "\n",
    "# Métricas de tempo\n",
    "TIME_METRICS = [\n",
    "    \"gan_training_time_sec\",\n",
    "    \"synthetic_generation_time_sec\",\n",
    "    \"classifier_training_time_sec\",\n",
    "    \"classifier_eval_time_sec\",\n",
    "]\n",
    "\n",
    "# Campos numéricos adicionais\n",
    "ADDITIONAL_NUMERIC_FIELDS = [\n",
    "    \"synthetic_class0_count\",\n",
    "    \"balanced_dataset_size\",\n",
    "    \"total_real_samples\",\n",
    "    \"real_class0_count\",\n",
    "    \"real_class1_count\",\n",
    "]\n",
    "\n",
    "# Campos agregados\n",
    "AGGREGATION_FIELDS = CLASSIFICATION_METRICS + TIME_METRICS + ADDITIONAL_NUMERIC_FIELDS\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Dataclasses auxiliares\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    \"\"\"Configuração do experimento multietapas.\"\"\"\n",
    "    data_flag: str = \"breastmnist\"\n",
    "    data_batch_size: int = 128\n",
    "    latent_dim: int = 100\n",
    "    gan_epochs: int = 50\n",
    "    classifier_epochs: int = 5\n",
    "    num_gan_runs: int = 10\n",
    "    num_generation_runs: int = 10\n",
    "    num_classifier_runs: int = 10\n",
    "    classifier_batch_size: int = 64\n",
    "    device: Optional[str] = None\n",
    "    base_seed: int = 2024\n",
    "    output_dir: Path = Path(\"balance_class0_runs\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class StageSeeds:\n",
    "    \"\"\"Agrupa as sementes de (GAN, geração, classificador) para cada execução.\"\"\"\n",
    "    gan_seed: int\n",
    "    generation_seed: int\n",
    "    classifier_seed: int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efa6d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Funções utilitárias\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "from typing import Optional, Dict\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "def _resolve_device(device: Optional[str]) -> torch.device:\n",
    "    \"\"\"Seleciona automaticamente o dispositivo (CPU ou GPU).\"\"\"\n",
    "    if device is None or device == \"auto\":\n",
    "        return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    return torch.device(device)\n",
    "\n",
    "\n",
    "def _seed_everything(seed: int) -> None:\n",
    "    \"\"\"Define todas as sementes aleatórias para reprodutibilidade.\"\"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def _to_scalar(y: Tensor | np.ndarray | int | float) -> int:\n",
    "    \"\"\"Converte um tensor, array ou número em escalar inteiro.\"\"\"\n",
    "    if isinstance(y, torch.Tensor):\n",
    "        return int(y.detach().view(-1)[0].item())\n",
    "    y_np = np.asarray(y)\n",
    "    return int(y_np.reshape(-1)[0].item())\n",
    "\n",
    "\n",
    "def count_class_samples(dataset: Dataset) -> Dict[int, int]:\n",
    "    \"\"\"Conta o número de amostras por classe em um dataset PyTorch.\"\"\"\n",
    "    counts: Dict[int, int] = {}\n",
    "    for _, label in dataset:\n",
    "        cls = _to_scalar(label)\n",
    "        counts[cls] = counts.get(cls, 0) + 1\n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f67c2ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Manipulação de dados\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "from typing import Sequence, Tuple, List, Dict\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.utils.data import Dataset, TensorDataset, ConcatDataset\n",
    "\n",
    "\n",
    "def custom_collate_fn(batch: Sequence[Tuple[Tensor, Tensor]]) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Função de colagem personalizada para DataLoader.\n",
    "    Concatena imagens e converte rótulos (tensors ou inteiros) em tensores de inteiros.\n",
    "    \"\"\"\n",
    "    images, labels = zip(*batch)\n",
    "    xs = torch.stack(images, dim=0)\n",
    "    ys_list: List[int] = []\n",
    "\n",
    "    for label in labels:\n",
    "        if isinstance(label, torch.Tensor):\n",
    "            if label.numel() == 1:\n",
    "                ys_list.append(int(label.item()))\n",
    "            else:\n",
    "                ys_list.append(int(label.argmax().item()))\n",
    "        else:\n",
    "            ys_list.append(int(label))\n",
    "\n",
    "    ys = torch.tensor(ys_list, dtype=torch.long)\n",
    "    return xs, ys\n",
    "\n",
    "\n",
    "def build_balanced_dataset(\n",
    "    train_dataset: Dataset,\n",
    "    generator: nn.Module,\n",
    "    *,\n",
    "    latent_dim: int,\n",
    "    synthetic_count: int,\n",
    "    device: torch.device,\n",
    "    seed: int,\n",
    ") -> Tuple[Dataset, int]:\n",
    "    \"\"\"\n",
    "    Retorna um dataset com amostras sintéticas adicionais da classe 0.\n",
    "\n",
    "    Args:\n",
    "        train_dataset: Dataset real de treino.\n",
    "        generator: Modelo gerador treinado (GAN).\n",
    "        latent_dim: Dimensão do vetor latente usado pelo gerador.\n",
    "        synthetic_count: Quantidade de amostras sintéticas a gerar.\n",
    "        device: Dispositivo (CPU/GPU) onde o gerador será executado.\n",
    "        seed: Semente aleatória para reprodutibilidade.\n",
    "\n",
    "    Returns:\n",
    "        combined_dataset: Dataset concatenado (real + sintético).\n",
    "        synthetic_count: Quantidade de amostras sintéticas adicionadas.\n",
    "    \"\"\"\n",
    "    if synthetic_count <= 0:\n",
    "        return train_dataset, 0\n",
    "\n",
    "    _seed_everything(seed)\n",
    "    generator = generator.to(device).eval()\n",
    "\n",
    "    noise = torch.randn(\n",
    "        synthetic_count,\n",
    "        latent_dim,\n",
    "        1,\n",
    "        1,\n",
    "        device=device,\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        synth_imgs = generator(noise)\n",
    "\n",
    "    if synth_imgs.dim() == 3:\n",
    "        synth_imgs = synth_imgs.unsqueeze(1)\n",
    "\n",
    "    synth_imgs = synth_imgs.to(torch.float32).cpu()\n",
    "    synth_labels = torch.zeros(synthetic_count, dtype=torch.long)\n",
    "\n",
    "    synthetic_dataset = TensorDataset(synth_imgs, synth_labels)\n",
    "    combined_dataset = ConcatDataset([train_dataset, synthetic_dataset])\n",
    "\n",
    "    return combined_dataset, synthetic_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f9ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Treinamento\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from classical_gans import DCGenerator, DCDiscriminator, train_gan_for_class\n",
    "\n",
    "\n",
    "def train_class0_gan(\n",
    "    train_loader: DataLoader,\n",
    "    *,\n",
    "    latent_dim: int,\n",
    "    gan_epochs: int,\n",
    "    device: torch.device,\n",
    "    seed: int,\n",
    "    img_channels: int,\n",
    ") -> Tuple[nn.Module, float]:\n",
    "    \"\"\"\n",
    "    Treina um DCGAN para a classe 0 e retorna o gerador treinado e o tempo de execução.\n",
    "\n",
    "    Args:\n",
    "        train_loader: DataLoader com amostras reais da classe 0.\n",
    "        latent_dim: Dimensão do vetor latente de entrada do gerador.\n",
    "        gan_epochs: Número de épocas de treino do GAN.\n",
    "        device: Dispositivo (CPU/GPU).\n",
    "        seed: Semente aleatória para reprodutibilidade.\n",
    "        img_channels: Número de canais da imagem (ex: 1 para grayscale, 3 para RGB).\n",
    "\n",
    "    Returns:\n",
    "        generator: Modelo gerador treinado.\n",
    "        elapsed: Tempo total de treinamento (em segundos).\n",
    "    \"\"\"\n",
    "    _seed_everything(seed)\n",
    "    start = time.time()\n",
    "\n",
    "    generator = DCGenerator(latent_dim=latent_dim, img_channels=img_channels).to(device)\n",
    "    discriminator = DCDiscriminator(img_channels=img_channels).to(device)\n",
    "\n",
    "    generator = train_gan_for_class(\n",
    "        train_loader=train_loader,\n",
    "        label_target=0,\n",
    "        G=generator,\n",
    "        D=discriminator,\n",
    "        latent_dim=latent_dim,\n",
    "        num_epochs=gan_epochs,\n",
    "        device=device,\n",
    "    ).eval()\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    return generator, elapsed\n",
    "\n",
    "\n",
    "def train_classifier(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    *,\n",
    "    epochs: int,\n",
    "    device: torch.device,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Treina um classificador supervisionado usando Cross-Entropy Loss.\n",
    "\n",
    "    Args:\n",
    "        model: Rede neural PyTorch.\n",
    "        loader: DataLoader com os dados de treino.\n",
    "        epochs: Número de épocas de treinamento.\n",
    "        device: Dispositivo (CPU/GPU).\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def evaluate_classifier(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    *,\n",
    "    device: torch.device,\n",
    ") -> Tuple[float, float, float, float, float, int, int, int, int]:\n",
    "    \"\"\"\n",
    "    Avalia o classificador em um conjunto de dados e calcula métricas de desempenho.\n",
    "\n",
    "    Args:\n",
    "        model: Modelo treinado.\n",
    "        loader: DataLoader com os dados de teste/validação.\n",
    "        device: Dispositivo (CPU/GPU).\n",
    "\n",
    "    Returns:\n",
    "        acc, prec, rec, f1, auc, tn, fp, fn, tp: Métricas de classificação.\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score,\n",
    "        confusion_matrix,\n",
    "        f1_score,\n",
    "        precision_score,\n",
    "        recall_score,\n",
    "        roc_auc_score,\n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    preds: List[Tensor] = []\n",
    "    labels: List[Tensor] = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            out = model(x)\n",
    "            preds.append(out.argmax(dim=1).cpu())\n",
    "            labels.append(y)\n",
    "\n",
    "    y_true = torch.cat(labels).numpy()\n",
    "    y_pred = torch.cat(preds).numpy()\n",
    "\n",
    "    def _safe_metric(func, default=np.nan):\n",
    "        try:\n",
    "            return float(func(y_true, y_pred))\n",
    "        except Exception:\n",
    "            return float(default)\n",
    "\n",
    "    acc = _safe_metric(accuracy_score)\n",
    "    prec = _safe_metric(lambda yt, yp: precision_score(yt, yp, zero_division=0))\n",
    "    rec = _safe_metric(lambda yt, yp: recall_score(yt, yp, zero_division=0))\n",
    "    f1 = _safe_metric(lambda yt, yp: f1_score(yt, yp, zero_division=0))\n",
    "    auc = _safe_metric(roc_auc_score, default=np.nan)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    return acc, prec, rec, f1, auc, int(tn), int(fp), int(fn), int(tp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a84a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Execução do experimento\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Funções auxiliares\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def compute_stage_seeds(config: ExperimentConfig, gan_id: int, gen_id: int, clf_id: int) -> StageSeeds:\n",
    "    \"\"\"\n",
    "    Gera sementes determinísticas para as três fases do experimento (GAN, geração e classificador).\n",
    "\n",
    "    Args:\n",
    "        config: Objeto de configuração principal do experimento.\n",
    "        gan_id: Índice da execução do GAN.\n",
    "        gen_id: Índice da execução de geração sintética.\n",
    "        clf_id: Índice da execução do classificador.\n",
    "\n",
    "    Returns:\n",
    "        StageSeeds: Estrutura contendo as sementes de cada fase.\n",
    "    \"\"\"\n",
    "    gan_seed = config.base_seed + gan_id\n",
    "    generation_seed = config.base_seed + 1000 * gan_id + gen_id\n",
    "    classifier_seed = config.base_seed + 1_000_000 * gan_id + 1_000 * gen_id + clf_id\n",
    "    return StageSeeds(\n",
    "        gan_seed=gan_seed,\n",
    "        generation_seed=generation_seed,\n",
    "        classifier_seed=classifier_seed\n",
    "    )\n",
    "\n",
    "\n",
    "def prepare_resnet(device: torch.device) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Cria e retorna uma instância de ResNet18 adaptada para imagens monocanais (1 canal).\n",
    "    \"\"\"\n",
    "    model = resnet18(num_classes=2)\n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Pipeline principal de execução\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def run_balance_experiments(config: ExperimentConfig) -> Tuple[pd.DataFrame, Dict[str, pd.DataFrame], Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Executa o pipeline completo de balanceamento com GANs e classificadores.\n",
    "\n",
    "    Retorna:\n",
    "        - df_results: DataFrame com resultados de todas as execuções.\n",
    "        - summary_tables: Dicionário com tabelas agregadas.\n",
    "        - metadata: Dicionário com informações de configuração e execução.\n",
    "    \"\"\"\n",
    "    device = _resolve_device(config.device)\n",
    "\n",
    "    # Carrega dados MedMNIST\n",
    "    bundle = load_medmnist_data(\n",
    "        data_flag=config.data_flag,\n",
    "        batch_size=config.data_batch_size,\n",
    "        download=True,\n",
    "    )\n",
    "\n",
    "    train_dataset = bundle.train_dataset\n",
    "    test_dataset = bundle.test_dataset\n",
    "    train_loader = bundle.train_loader\n",
    "\n",
    "    counts = count_class_samples(train_dataset)\n",
    "    real_class0 = counts.get(0, 0)\n",
    "    real_class1 = counts.get(1, 0)\n",
    "    deficit = max(0, real_class1 - real_class0)\n",
    "\n",
    "    results: List[Dict[str, object]] = []\n",
    "    img_channels = train_dataset[0][0].shape[0]\n",
    "    total_real_samples = len(train_dataset)\n",
    "\n",
    "    # Loop principal\n",
    "    for gan_run in range(1, config.num_gan_runs + 1):\n",
    "        seeds_for_gan = compute_stage_seeds(config, gan_run, 0, 0)\n",
    "        generator, gan_time = train_class0_gan(\n",
    "            train_loader,\n",
    "            latent_dim=config.latent_dim,\n",
    "            gan_epochs=config.gan_epochs,\n",
    "            device=device,\n",
    "            seed=seeds_for_gan.gan_seed,\n",
    "            img_channels=img_channels,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            for gen_run in range(1, config.num_generation_runs + 1):\n",
    "                seeds_for_generation = compute_stage_seeds(config, gan_run, gen_run, 0)\n",
    "\n",
    "                gen_start = time.time()\n",
    "                balanced_dataset, synth_count = build_balanced_dataset(\n",
    "                    train_dataset,\n",
    "                    generator,\n",
    "                    latent_dim=config.latent_dim,\n",
    "                    synthetic_count=deficit,\n",
    "                    device=device,\n",
    "                    seed=seeds_for_generation.generation_seed,\n",
    "                )\n",
    "                generation_time = time.time() - gen_start\n",
    "\n",
    "                for clf_run in range(1, config.num_classifier_runs + 1):\n",
    "                    seeds = compute_stage_seeds(config, gan_run, gen_run, clf_run)\n",
    "                    _seed_everything(seeds.classifier_seed)\n",
    "\n",
    "                    loader = DataLoader(\n",
    "                        balanced_dataset,\n",
    "                        batch_size=config.classifier_batch_size,\n",
    "                        shuffle=True,\n",
    "                        pin_memory=device.type == \"cuda\",\n",
    "                        drop_last=False,\n",
    "                        collate_fn=custom_collate_fn,\n",
    "                    )\n",
    "\n",
    "                    model = prepare_resnet(device)\n",
    "\n",
    "                    # Treinamento\n",
    "                    train_start = time.time()\n",
    "                    train_classifier(\n",
    "                        model,\n",
    "                        loader,\n",
    "                        epochs=config.classifier_epochs,\n",
    "                        device=device,\n",
    "                    )\n",
    "                    train_time = time.time() - train_start\n",
    "\n",
    "                    # Avaliação\n",
    "                    eval_loader = DataLoader(\n",
    "                        test_dataset,\n",
    "                        batch_size=config.classifier_batch_size,\n",
    "                        shuffle=False,\n",
    "                        pin_memory=device.type == \"cuda\",\n",
    "                        drop_last=False,\n",
    "                        collate_fn=custom_collate_fn,\n",
    "                    )\n",
    "\n",
    "                    eval_start = time.time()\n",
    "                    acc, prec, rec, f1, auc, tn, fp, fn, tp = evaluate_classifier(\n",
    "                        model, eval_loader, device=device\n",
    "                    )\n",
    "                    eval_time = time.time() - eval_start\n",
    "\n",
    "                    # Registro dos resultados\n",
    "                    result = {\n",
    "                        \"gan_run_id\": gan_run,\n",
    "                        \"generation_run_id\": gen_run,\n",
    "                        \"classifier_run_id\": clf_run,\n",
    "                        \"ratio\": 0.0,\n",
    "                        \"acc\": acc,\n",
    "                        \"prec\": prec,\n",
    "                        \"rec\": rec,\n",
    "                        \"f1\": f1,\n",
    "                        \"auc\": auc,\n",
    "                        \"tn\": tn,\n",
    "                        \"fp\": fp,\n",
    "                        \"fn\": fn,\n",
    "                        \"tp\": tp,\n",
    "                        \"synthetic_class0_count\": synth_count,\n",
    "                        \"balanced_dataset_size\": len(balanced_dataset),\n",
    "                        \"total_real_samples\": total_real_samples,\n",
    "                        \"real_class0_count\": real_class0,\n",
    "                        \"real_class1_count\": real_class1,\n",
    "                        \"gan_training_time_sec\": gan_time,\n",
    "                        \"synthetic_generation_time_sec\": generation_time,\n",
    "                        \"classifier_training_time_sec\": train_time,\n",
    "                        \"classifier_eval_time_sec\": eval_time,\n",
    "                        \"gan_seed\": seeds_for_gan.gan_seed,\n",
    "                        \"generation_seed\": seeds_for_generation.generation_seed,\n",
    "                        \"classifier_seed\": seeds.classifier_seed,\n",
    "                    }\n",
    "\n",
    "                    results.append(result)\n",
    "\n",
    "        finally:\n",
    "            # Libera memória de GPU entre execuções do GAN\n",
    "            generator.cpu()\n",
    "            del generator\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    # Agregação final de resultados\n",
    "    df_results = pd.DataFrame(results)\n",
    "    summary_tables = {\n",
    "        \"overall\": aggregate_metrics(df_results, []),\n",
    "        \"by_gan\": aggregate_metrics(df_results, [\"gan_run_id\"]),\n",
    "        \"by_gan_generation\": aggregate_metrics(df_results, [\"gan_run_id\", \"generation_run_id\"]),\n",
    "    }\n",
    "\n",
    "    metadata = {\n",
    "        \"data_flag\": config.data_flag,\n",
    "        \"latent_dim\": config.latent_dim,\n",
    "        \"gan_epochs\": config.gan_epochs,\n",
    "        \"classifier_epochs\": config.classifier_epochs,\n",
    "        \"num_gan_runs\": config.num_gan_runs,\n",
    "        \"num_generation_runs\": config.num_generation_runs,\n",
    "        \"num_classifier_runs\": config.num_classifier_runs,\n",
    "        \"classifier_batch_size\": config.classifier_batch_size,\n",
    "        \"data_batch_size\": config.data_batch_size,\n",
    "        \"device\": str(device),\n",
    "        \"base_seed\": config.base_seed,\n",
    "        \"real_class0_count\": real_class0,\n",
    "        \"real_class1_count\": real_class1,\n",
    "        \"synthetic_needed_for_balance\": deficit,\n",
    "        \"total_real_samples\": total_real_samples,\n",
    "        \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "    }\n",
    "\n",
    "    return df_results, summary_tables, metadata\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Agregação de métricas\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def aggregate_metrics(df: pd.DataFrame, group_cols: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Agrega métricas de classificação, tempo e estatísticas por grupo de execuções.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame com resultados completos.\n",
    "        group_cols: Colunas de agrupamento (ex: [\"gan_run_id\"]).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame com médias e desvios padrão das métricas.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=group_cols + [f\"{m}_mean\" for m in AGGREGATION_FIELDS])\n",
    "\n",
    "    grouped = df.groupby(group_cols) if group_cols else [((), df)]\n",
    "    rows: List[Dict[str, object]] = []\n",
    "\n",
    "    for key, group in grouped:\n",
    "        if not isinstance(key, tuple):\n",
    "            key = (key,)\n",
    "\n",
    "        row: Dict[str, object] = {}\n",
    "        for idx, col in enumerate(group_cols):\n",
    "            row[col] = key[idx]\n",
    "\n",
    "        row[\"num_rows\"] = len(group)\n",
    "\n",
    "        for metric in AGGREGATION_FIELDS:\n",
    "            if metric in group:\n",
    "                row[f\"{metric}_mean\"] = float(group[metric].mean())\n",
    "                row[f\"{metric}_std\"] = float(group[metric].std(ddof=0))\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bc2f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Persistência de resultados\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def save_results(\n",
    "    df_results: pd.DataFrame,\n",
    "    summary_tables: Dict[str, pd.DataFrame],\n",
    "    metadata: Dict[str, object],\n",
    "    output_dir: Path,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Salva os resultados do experimento (tabelas e metadados) em arquivos CSV e JSON.\n",
    "\n",
    "    Args:\n",
    "        df_results: DataFrame contendo os resultados detalhados de todas as execuções.\n",
    "        summary_tables: Dicionário com tabelas agregadas de métricas.\n",
    "        metadata: Dicionário com informações da configuração e execução do experimento.\n",
    "        output_dir: Diretório de saída onde os arquivos serão salvos.\n",
    "\n",
    "    Saídas:\n",
    "        - balance_class0_results.csv: Resultados completos.\n",
    "        - summary_*.csv: Tabelas de resumo (overall, por GAN, etc.).\n",
    "        - metadata.json: Informações descritivas e parâmetros da execução.\n",
    "    \"\"\"\n",
    "    # Cria o diretório de saída, se necessário\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Salva resultados completos\n",
    "    results_path = output_dir / \"balance_class0_results.csv\"\n",
    "    df_results.to_csv(results_path, index=False)\n",
    "\n",
    "    # Salva tabelas agregadas\n",
    "    for name, df in summary_tables.items():\n",
    "        df.to_csv(output_dir / f\"summary_{name}.csv\", index=False)\n",
    "\n",
    "    # Salva metadados como JSON\n",
    "    with open(output_dir / \"metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metadata, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f405194",
   "metadata": {},
   "source": [
    "## Execução do experimento. Ajuste os hiperparâmetros abaixo conforme necessário. Dependendo dos valores escolhidos(as execuções padrão são 10×10×10), o processo pode ser bastante demorado. Para testes rápidos,reduza os contadores de repetições e épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ff0f9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/mahlow/.medmnist/breastmnist.npz\n",
      "Using downloaded and verified file: /home/mahlow/.medmnist/breastmnist.npz\n",
      "Epoch 1/5 - Loss D: 1.350 | Loss G: 0.885\n",
      "Epoch 2/5 - Loss D: 0.886 | Loss G: 1.125\n",
      "Epoch 3/5 - Loss D: 0.638 | Loss G: 1.436\n",
      "Epoch 4/5 - Loss D: 0.536 | Loss G: 1.693\n",
      "Epoch 5/5 - Loss D: 0.450 | Loss G: 1.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_538779/2751922055.py:27: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  ys_list.append(int(label))\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Exemplo de configuração enxuta para testes rápidos\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    data_flag=\"breastmnist\",\n",
    "    data_batch_size=128,\n",
    "    latent_dim=100,\n",
    "    gan_epochs=50,\n",
    "    classifier_epochs=1,\n",
    "    num_gan_runs=1,\n",
    "    num_generation_runs=1,\n",
    "    num_classifier_runs=1,\n",
    "    classifier_batch_size=64,\n",
    "    device=\"auto\",\n",
    "    base_seed=2024,\n",
    "    output_dir=Path(\"balance_class0_runs_demo\"),\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Execução opcional do pipeline completo\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Descomente as linhas abaixo para executar todo o experimento.\n",
    "# Isso irá:\n",
    "# 1. Treinar um GAN para a classe 0.\n",
    "# 2. Gerar amostras sintéticas para balanceamento.\n",
    "# 3. Treinar e avaliar classificadores.\n",
    "# 4. Salvar os resultados e metadados no diretório especificado.\n",
    "\n",
    "df_results, summary_tables, metadata = run_balance_experiments(config)\n",
    "save_results(df_results, summary_tables, metadata, config.output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e8149d0-37b7-4491-bbe8-32721ecbdf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gan_run_id</th>\n",
       "      <th>generation_run_id</th>\n",
       "      <th>classifier_run_id</th>\n",
       "      <th>ratio</th>\n",
       "      <th>acc</th>\n",
       "      <th>prec</th>\n",
       "      <th>rec</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>tn</th>\n",
       "      <th>...</th>\n",
       "      <th>total_real_samples</th>\n",
       "      <th>real_class0_count</th>\n",
       "      <th>real_class1_count</th>\n",
       "      <th>gan_training_time_sec</th>\n",
       "      <th>synthetic_generation_time_sec</th>\n",
       "      <th>classifier_training_time_sec</th>\n",
       "      <th>classifier_eval_time_sec</th>\n",
       "      <th>gan_seed</th>\n",
       "      <th>generation_seed</th>\n",
       "      <th>classifier_seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.622807</td>\n",
       "      <td>0.67619</td>\n",
       "      <td>0.513784</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>546</td>\n",
       "      <td>147</td>\n",
       "      <td>399</td>\n",
       "      <td>2.440485</td>\n",
       "      <td>0.070227</td>\n",
       "      <td>6.281519</td>\n",
       "      <td>0.206907</td>\n",
       "      <td>2025</td>\n",
       "      <td>3025</td>\n",
       "      <td>1003025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gan_run_id  generation_run_id  classifier_run_id  ratio       acc  \\\n",
       "0           1                  1                  1    0.0  0.564103   \n",
       "\n",
       "       prec       rec       f1       auc  tn  ...  total_real_samples  \\\n",
       "0  0.739583  0.622807  0.67619  0.513784  17  ...                 546   \n",
       "\n",
       "   real_class0_count  real_class1_count  gan_training_time_sec  \\\n",
       "0                147                399               2.440485   \n",
       "\n",
       "   synthetic_generation_time_sec  classifier_training_time_sec  \\\n",
       "0                       0.070227                      6.281519   \n",
       "\n",
       "   classifier_eval_time_sec  gan_seed  generation_seed  classifier_seed  \n",
       "0                  0.206907      2025             3025          1003025  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f209d4",
   "metadata": {},
   "source": [
    "## Utilitário de linha de comando (opcional)As funções abaixo permitem reutilizar o parser de argumentos do script original, casoqueira invocar o notebook via `papermill` ou semelhante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "712accba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Parser de argumentos para execução programática\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def parse_args() -> ExperimentConfig:\n",
    "    \"\"\"\n",
    "    Cria e interpreta argumentos de linha de comando para configurar o experimento.\n",
    "\n",
    "    Em um notebook, o parse_args([]) evita erros por ausência de argumentos\n",
    "    e retorna um objeto ExperimentConfig com valores padrão ou definidos manualmente.\n",
    "\n",
    "    Returns:\n",
    "        ExperimentConfig: Objeto de configuração preenchido com os parâmetros fornecidos.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Run repeated class-0 balancing experiments with DCGAN and ResNet-18\",\n",
    "    )\n",
    "\n",
    "    # Argumentos principais\n",
    "    parser.add_argument(\"--data-flag\", default=\"breastmnist\", help=\"MedMNIST dataset flag\")\n",
    "    parser.add_argument(\"--data-batch-size\", type=int, default=128, help=\"Batch size for the GAN data loader\")\n",
    "    parser.add_argument(\"--latent-dim\", type=int, default=100, help=\"Latent dimension for the GAN\")\n",
    "    parser.add_argument(\"--gan-epochs\", type=int, default=50, help=\"Number of epochs for GAN training\")\n",
    "    parser.add_argument(\n",
    "        \"--classifier-epochs\",\n",
    "        type=int,\n",
    "        default=5,\n",
    "        help=\"Number of epochs for each ResNet-18 training run\",\n",
    "    )\n",
    "    parser.add_argument(\"--num-gan-runs\", type=int, default=10, help=\"How many times to retrain the GAN\")\n",
    "    parser.add_argument(\n",
    "        \"--num-generation-runs\",\n",
    "        type=int,\n",
    "        default=10,\n",
    "        help=\"How many synthetic datasets to generate per GAN training\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num-classifier-runs\",\n",
    "        type=int,\n",
    "        default=10,\n",
    "        help=\"How many classifier trainings per synthetic dataset\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--classifier-batch-size\",\n",
    "        type=int,\n",
    "        default=64,\n",
    "        help=\"Batch size for the ResNet-18 training and evaluation\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\",\n",
    "        default=\"auto\",\n",
    "        help=\"Device to use (cuda, cpu or auto)\",\n",
    "    )\n",
    "    parser.add_argument(\"--base-seed\", type=int, default=2024, help=\"Base seed for reproducibility\")\n",
    "    parser.add_argument(\n",
    "        \"--output-dir\",\n",
    "        type=Path,\n",
    "        default=Path(\"balance_class0_runs\"),\n",
    "        help=\"Directory where CSV and metadata files will be stored\",\n",
    "    )\n",
    "\n",
    "    # parse_args([]) evita conflitos de CLI em ambientes interativos\n",
    "    args = parser.parse_args([])\n",
    "\n",
    "    return ExperimentConfig(\n",
    "        data_flag=args.data_flag,\n",
    "        data_batch_size=args.data_batch_size,\n",
    "        latent_dim=args.latent_dim,\n",
    "        gan_epochs=args.gan_epochs,\n",
    "        classifier_epochs=args.classifier_epochs,\n",
    "        num_gan_runs=args.num_gan_runs,\n",
    "        num_generation_runs=args.num_generation_runs,\n",
    "        num_classifier_runs=args.num_classifier_runs,\n",
    "        classifier_batch_size=args.classifier_batch_size,\n",
    "        device=args.device,\n",
    "        base_seed=args.base_seed,\n",
    "        output_dir=args.output_dir,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe515352-d686-41fc-871c-2ea7f4b4cd3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

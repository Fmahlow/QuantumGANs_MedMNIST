{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85df51d3",
   "metadata": {},
   "source": [
    "# Balanceamento da Classe 0 com GANs ClássicosEste notebook reproduz o pipeline definido em `balance_class0_runs.py`, estruturando-o em célulaspara facilitar a experimentação iterativa. O fluxo completo executa as seguintes etapas:1. Treina um DCGAN para a classe 0 do conjunto escolhido do MedMNIST.2. Gera amostras sintéticas para balancear as classes.3. Treina diversas vezes um classificador ResNet-18 sobre o conjunto balanceado.4. Registra métricas e estatísticas agregadas.Configure os parâmetros na seção **Execução do experimento** para repetir os ensaios desejados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c236319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações futuras\n",
    "from __future__ import annotations\n",
    "\n",
    "# Importações padrão\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Sequence, Tuple\n",
    "\n",
    "# Bibliotecas científicas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "# TorchVision\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# Módulos personalizados\n",
    "from classical_gans import (\n",
    "    CGANDiscriminator,\n",
    "    CGANGenerator,\n",
    "    DCDiscriminator,\n",
    "    DCGenerator,\n",
    "    WGANGPCritic,\n",
    "    WGANGPGenerator,\n",
    "    train_cgan,\n",
    "    train_gan_for_class,\n",
    "    train_wgangp,\n",
    ")\n",
    "from medmnist_data import load_medmnist_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96863de8-3c80-46ff-9024-914f645b7563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Constantes e dataclasses auxiliares\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Métricas de classificação\n",
    "CLASSIFICATION_METRICS = [\n",
    "    \"acc\", \"prec\", \"rec\", \"f1\", \"auc\", \"tn\", \"fp\", \"fn\", \"tp\"\n",
    "]\n",
    "\n",
    "# Métricas de tempo\n",
    "TIME_METRICS = [\n",
    "    \"gan_training_time_sec\",\n",
    "    \"synthetic_generation_time_sec\",\n",
    "    \"classifier_training_time_sec\",\n",
    "    \"classifier_eval_time_sec\",\n",
    "]\n",
    "\n",
    "# Campos numéricos adicionais\n",
    "ADDITIONAL_NUMERIC_FIELDS = [\n",
    "    \"ratio\",\n",
    "    \"synthetic_class0_count\",\n",
    "    \"balanced_dataset_size\",\n",
    "    \"total_real_samples\",\n",
    "    \"real_class0_count\",\n",
    "    \"real_class1_count\",\n",
    "]\n",
    "\n",
    "# Campos agregados\n",
    "AGGREGATION_FIELDS = CLASSIFICATION_METRICS + TIME_METRICS + ADDITIONAL_NUMERIC_FIELDS\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Dataclasses auxiliares\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class StrategySpec:\n",
    "    \"\"\"Define uma estratégia de balanceamento utilizada nos experimentos.\"\"\"\n",
    "\n",
    "    key: str\n",
    "    display_name: str\n",
    "    uses_gan: bool = False\n",
    "    conditional_label: Optional[int] = None\n",
    "\n",
    "\n",
    "BALANCING_STRATEGIES: List[StrategySpec] = [\n",
    "    StrategySpec(\"baseline\", \"ResNet sem balanceamento\"),\n",
    "    StrategySpec(\"dcgan\", \"DCGAN (classe 0)\", uses_gan=True, conditional_label=0),\n",
    "    StrategySpec(\"cgan\", \"CGAN (classe 0)\", uses_gan=True, conditional_label=0),\n",
    "    StrategySpec(\"wgan\", \"WGAN-GP (classe 0)\", uses_gan=True, conditional_label=0),\n",
    "    StrategySpec(\"smote\", \"SMOTE (classe 0)\"),\n",
    "    StrategySpec(\"undersample\", \"Undersampling da classe 1\"),\n",
    "    StrategySpec(\"oversample\", \"Oversampling por repetição (classe 0)\"),\n",
    "]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    \"\"\"Configuração do experimento multietapas.\"\"\"\n",
    "\n",
    "    data_flag: str = \"breastmnist\"\n",
    "    data_batch_size: int = 128\n",
    "    latent_dim: int = 100\n",
    "    gan_epochs: int = 50\n",
    "    classifier_epochs: int = 5\n",
    "    num_gan_runs: int = 10\n",
    "    num_generation_runs: int = 10\n",
    "    num_classifier_runs: int = 10\n",
    "    classifier_batch_size: int = 64\n",
    "    device: Optional[str] = None\n",
    "    base_seed: int = 2024\n",
    "    output_dir: Path = Path(\"balance_class0_runs\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class StageSeeds:\n",
    "    \"\"\"Agrupa as sementes de (GAN, geração, classificador) para cada execução.\"\"\"\n",
    "\n",
    "    gan_seed: int\n",
    "    generation_seed: int\n",
    "    classifier_seed: int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efa6d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Funções utilitárias\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "from typing import Optional, Dict, List, Tuple\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "\n",
    "\n",
    "def _resolve_device(device: Optional[str]) -> torch.device:\n",
    "    \"\"\"Seleciona automaticamente o dispositivo (CPU ou GPU).\"\"\"\n",
    "    if device is None or device == \"auto\":\n",
    "        return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    return torch.device(device)\n",
    "\n",
    "\n",
    "def _seed_everything(seed: int) -> None:\n",
    "    \"\"\"Define todas as sementes aleatórias para reprodutibilidade.\"\"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def _to_scalar(y: Tensor | np.ndarray | int | float) -> int:\n",
    "    \"\"\"Converte um tensor, array ou número em escalar inteiro.\"\"\"\n",
    "    if isinstance(y, torch.Tensor):\n",
    "        return int(y.detach().view(-1)[0].item())\n",
    "    y_np = np.asarray(y)\n",
    "    return int(y_np.reshape(-1)[0].item())\n",
    "\n",
    "\n",
    "def count_class_samples(dataset: Dataset) -> Dict[int, int]:\n",
    "    \"\"\"Conta o número de amostras por classe em um dataset PyTorch.\"\"\"\n",
    "    counts: Dict[int, int] = {}\n",
    "    for _, label in dataset:\n",
    "        label_int = _to_scalar(label)\n",
    "        counts[label_int] = counts.get(label_int, 0) + 1\n",
    "    return counts\n",
    "\n",
    "\n",
    "def tensorize_dataset(dataset: Dataset) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"Converte um ``Dataset`` em tensores (imagens, rótulos).\"\"\"\n",
    "    images: List[Tensor] = []\n",
    "    labels: List[int] = []\n",
    "\n",
    "    for img, label in dataset:\n",
    "        if not isinstance(img, torch.Tensor):\n",
    "            img = torch.as_tensor(img)\n",
    "        images.append(img.to(torch.float32))\n",
    "        labels.append(_to_scalar(label))\n",
    "\n",
    "    stacked_images = torch.stack(images, dim=0)\n",
    "    stacked_labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return stacked_images, stacked_labels\n",
    "\n",
    "\n",
    "def compute_class_ratio(labels: Tensor) -> float:\n",
    "    \"\"\"Retorna a proporção da classe 0 em relação ao total de exemplos.\"\"\"\n",
    "    if labels.numel() == 0:\n",
    "        return float(\"nan\")\n",
    "    class0 = (labels == 0).sum().item()\n",
    "    return float(class0 / labels.numel())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f67c2ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Manipulação de dados\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "from typing import Sequence, Tuple, List, Optional\n",
    "import time\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "\n",
    "def custom_collate_fn(batch: Sequence[Tuple[Tensor, Tensor]]) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Função de colagem personalizada para DataLoader.\n",
    "    Concatena imagens e converte rótulos (tensors ou inteiros) em tensores de inteiros.\n",
    "    \"\"\"\n",
    "    images, labels = zip(*batch)\n",
    "    xs = torch.stack(images, dim=0)\n",
    "    ys_list: List[int] = []\n",
    "\n",
    "    for label in labels:\n",
    "        if isinstance(label, torch.Tensor):\n",
    "            if label.numel() == 1:\n",
    "                ys_list.append(int(label.item()))\n",
    "            else:\n",
    "                ys_list.append(int(label.argmax().item()))\n",
    "        else:\n",
    "            ys_list.append(int(label))\n",
    "\n",
    "    ys = torch.tensor(ys_list, dtype=torch.long)\n",
    "    return xs, ys\n",
    "\n",
    "\n",
    "def _generate_gan_samples(\n",
    "    generator: nn.Module,\n",
    "    *,\n",
    "    latent_dim: int,\n",
    "    sample_count: int,\n",
    "    device: torch.device,\n",
    "    seed: int,\n",
    "    conditional_label: Optional[int] = None,\n",
    ") -> Tensor:\n",
    "    \"\"\"Gera amostras sintéticas utilizando um gerador treinado.\"\"\"\n",
    "    if sample_count <= 0:\n",
    "        raise ValueError(\"sample_count deve ser positivo para geração de amostras\")\n",
    "\n",
    "    _seed_everything(seed)\n",
    "    generator = generator.to(device).eval()\n",
    "\n",
    "    noise = torch.randn(sample_count, latent_dim, 1, 1, device=device, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if conditional_label is not None:\n",
    "            labels = torch.full((sample_count,), conditional_label, device=device, dtype=torch.long)\n",
    "            synth_imgs = generator(noise, labels)\n",
    "        else:\n",
    "            synth_imgs = generator(noise)\n",
    "\n",
    "    if synth_imgs.dim() == 3:\n",
    "        synth_imgs = synth_imgs.unsqueeze(1)\n",
    "\n",
    "    return synth_imgs.to(torch.float32).cpu()\n",
    "\n",
    "\n",
    "def build_baseline_dataset(images: Tensor, labels: Tensor) -> Tuple[TensorDataset, int, float, float]:\n",
    "    \"\"\"Retorna o dataset original sem modificações.\"\"\"\n",
    "    dataset = TensorDataset(images, labels)\n",
    "    ratio = compute_class_ratio(labels)\n",
    "    return dataset, 0, ratio, 0.0\n",
    "\n",
    "\n",
    "def build_gan_balanced_dataset(\n",
    "    images: Tensor,\n",
    "    labels: Tensor,\n",
    "    generator: nn.Module,\n",
    "    *,\n",
    "    latent_dim: int,\n",
    "    synthetic_count: int,\n",
    "    device: torch.device,\n",
    "    seed: int,\n",
    "    conditional_label: Optional[int] = None,\n",
    ") -> Tuple[TensorDataset, int, float, float]:\n",
    "    \"\"\"Balanceia o dataset adicionando amostras sintéticas geradas por GAN.\"\"\"\n",
    "    if synthetic_count <= 0:\n",
    "        return build_baseline_dataset(images, labels)\n",
    "\n",
    "    start = time.time()\n",
    "    synth_imgs = _generate_gan_samples(\n",
    "        generator,\n",
    "        latent_dim=latent_dim,\n",
    "        sample_count=synthetic_count,\n",
    "        device=device,\n",
    "        seed=seed,\n",
    "        conditional_label=conditional_label,\n",
    "    )\n",
    "    synth_labels = torch.zeros(synthetic_count, dtype=torch.long)\n",
    "\n",
    "    balanced_images = torch.cat([images, synth_imgs], dim=0)\n",
    "    balanced_labels = torch.cat([labels, synth_labels], dim=0)\n",
    "    ratio = compute_class_ratio(balanced_labels)\n",
    "\n",
    "    dataset = TensorDataset(balanced_images, balanced_labels)\n",
    "    elapsed = time.time() - start\n",
    "    return dataset, synthetic_count, ratio, elapsed\n",
    "\n",
    "\n",
    "def build_smote_dataset(\n",
    "    images: Tensor,\n",
    "    labels: Tensor,\n",
    "    *,\n",
    "    target_minority: int,\n",
    "    seed: int,\n",
    ") -> Tuple[TensorDataset, int, float, float]:\n",
    "    \"\"\"Aplica SMOTE na classe 0 até atingir ``target_minority`` exemplos.\"\"\"\n",
    "    minority_mask = labels == 0\n",
    "    minority_images = images[minority_mask]\n",
    "    minority_count = minority_images.size(0)\n",
    "    synthetic_count = max(0, target_minority - minority_count)\n",
    "\n",
    "    if synthetic_count <= 0:\n",
    "        return build_baseline_dataset(images, labels)\n",
    "\n",
    "    start = time.time()\n",
    "    flat_minority = minority_images.view(minority_count, -1).cpu().numpy()\n",
    "\n",
    "    if minority_count == 1:\n",
    "        synthetic_flat = np.repeat(flat_minority, synthetic_count, axis=0)\n",
    "    else:\n",
    "        from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "        k_neighbors = min(5, minority_count)\n",
    "        nbrs = NearestNeighbors(n_neighbors=k_neighbors)\n",
    "        nbrs.fit(flat_minority)\n",
    "\n",
    "        rng = np.random.default_rng(seed)\n",
    "        base_indices = rng.integers(0, minority_count, size=synthetic_count)\n",
    "        neighbor_choices = nbrs.kneighbors(flat_minority[base_indices], return_distance=False)\n",
    "        neighbor_indices = rng.integers(1, neighbor_choices.shape[1], size=synthetic_count)\n",
    "\n",
    "        diffs = flat_minority[neighbor_choices[np.arange(synthetic_count), neighbor_indices]] - flat_minority[base_indices]\n",
    "        steps = rng.random((synthetic_count, flat_minority.shape[1]))\n",
    "        synthetic_flat = flat_minority[base_indices] + steps * diffs\n",
    "\n",
    "    synthetic_flat = np.clip(synthetic_flat, -1.0, 1.0)\n",
    "    synth_imgs = torch.from_numpy(synthetic_flat).view(-1, *images.shape[1:]).to(torch.float32)\n",
    "    synth_labels = torch.zeros(synthetic_count, dtype=torch.long)\n",
    "\n",
    "    balanced_images = torch.cat([images, synth_imgs], dim=0)\n",
    "    balanced_labels = torch.cat([labels, synth_labels], dim=0)\n",
    "    ratio = compute_class_ratio(balanced_labels)\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    dataset = TensorDataset(balanced_images, balanced_labels)\n",
    "    return dataset, synthetic_count, ratio, elapsed\n",
    "\n",
    "\n",
    "def build_undersampled_dataset(\n",
    "    images: Tensor,\n",
    "    labels: Tensor,\n",
    "    *,\n",
    "    minority_count: int,\n",
    "    seed: int,\n",
    ") -> Tuple[TensorDataset, int, float, float]:\n",
    "    \"\"\"Reduz a classe 1 para a quantidade de exemplos da classe minoritária.\"\"\"\n",
    "    start = time.time()\n",
    "    minority_indices = (labels == 0).nonzero(as_tuple=False).view(-1)\n",
    "    majority_indices = (labels == 1).nonzero(as_tuple=False).view(-1)\n",
    "\n",
    "    if majority_indices.numel() <= minority_count:\n",
    "        return build_baseline_dataset(images, labels)\n",
    "\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    perm = torch.randperm(majority_indices.numel(), generator=g)\n",
    "    selected_majority = majority_indices[perm[:minority_count]]\n",
    "\n",
    "    selected_indices = torch.cat([minority_indices, selected_majority], dim=0)\n",
    "    balanced_images = images[selected_indices]\n",
    "    balanced_labels = labels[selected_indices]\n",
    "    ratio = compute_class_ratio(balanced_labels)\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    dataset = TensorDataset(balanced_images, balanced_labels)\n",
    "    return dataset, 0, ratio, elapsed\n",
    "\n",
    "\n",
    "def build_oversampled_dataset(\n",
    "    images: Tensor,\n",
    "    labels: Tensor,\n",
    "    *,\n",
    "    target_minority: int,\n",
    "    seed: int,\n",
    ") -> Tuple[TensorDataset, int, float, float]:\n",
    "    \"\"\"Replica amostras da classe 0 até atingir ``target_minority`` exemplos.\"\"\"\n",
    "    minority_indices = (labels == 0).nonzero(as_tuple=False).view(-1)\n",
    "    minority_count = minority_indices.numel()\n",
    "    additional = max(0, target_minority - minority_count)\n",
    "\n",
    "    if additional <= 0 or minority_count == 0:\n",
    "        return build_baseline_dataset(images, labels)\n",
    "\n",
    "    start = time.time()\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    rand_indices = torch.randint(0, minority_count, (additional,), generator=g)\n",
    "    sampled_indices = minority_indices[rand_indices]\n",
    "\n",
    "    synth_images = images[sampled_indices]\n",
    "    synth_labels = labels[sampled_indices]\n",
    "\n",
    "    balanced_images = torch.cat([images, synth_images], dim=0)\n",
    "    balanced_labels = torch.cat([labels, synth_labels], dim=0)\n",
    "    ratio = compute_class_ratio(balanced_labels)\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    dataset = TensorDataset(balanced_images, balanced_labels)\n",
    "    return dataset, additional, ratio, elapsed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f9ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Treinamento\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Optional\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def train_class0_gan(\n",
    "    train_loader: DataLoader,\n",
    "    *,\n",
    "    latent_dim: int,\n",
    "    gan_epochs: int,\n",
    "    device: torch.device,\n",
    "    seed: int,\n",
    "    img_channels: int,\n",
    ") -> Tuple[nn.Module, float]:\n",
    "    \"\"\"\n",
    "    Treina um DCGAN para a classe 0 e retorna o gerador treinado e o tempo de execução.\n",
    "\n",
    "    Args:\n",
    "        train_loader: DataLoader com amostras reais da classe 0.\n",
    "        latent_dim: Dimensão do vetor latente de entrada do gerador.\n",
    "        gan_epochs: Número de épocas de treino do GAN.\n",
    "        device: Dispositivo (CPU/GPU).\n",
    "        seed: Semente aleatória para reprodutibilidade.\n",
    "        img_channels: Número de canais da imagem (ex: 1 para grayscale, 3 para RGB).\n",
    "\n",
    "    Returns:\n",
    "        generator: Modelo gerador treinado.\n",
    "        elapsed: Tempo total de treinamento (em segundos).\n",
    "    \"\"\"\n",
    "    _seed_everything(seed)\n",
    "    start = time.time()\n",
    "\n",
    "    generator = DCGenerator(latent_dim=latent_dim, img_channels=img_channels).to(device)\n",
    "    discriminator = DCDiscriminator(img_channels=img_channels).to(device)\n",
    "\n",
    "    generator = train_gan_for_class(\n",
    "        train_loader=train_loader,\n",
    "        label_target=0,\n",
    "        G=generator,\n",
    "        D=discriminator,\n",
    "        latent_dim=latent_dim,\n",
    "        num_epochs=gan_epochs,\n",
    "        device=device,\n",
    "    ).eval()\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    return generator, elapsed\n",
    "\n",
    "\n",
    "def train_class0_cgan(\n",
    "    train_loader: DataLoader,\n",
    "    *,\n",
    "    latent_dim: int,\n",
    "    gan_epochs: int,\n",
    "    device: torch.device,\n",
    "    seed: int,\n",
    "    img_channels: int,\n",
    "    num_classes: int,\n",
    ") -> Tuple[nn.Module, float]:\n",
    "    \"\"\"Treina um CGAN focado na classe 0.\"\"\"\n",
    "    _seed_everything(seed)\n",
    "    start = time.time()\n",
    "\n",
    "    generator = CGANGenerator(\n",
    "        latent_dim=latent_dim,\n",
    "        num_classes=num_classes,\n",
    "        img_channels=img_channels,\n",
    "    ).to(device)\n",
    "    discriminator = CGANDiscriminator(\n",
    "        num_classes=num_classes,\n",
    "        img_channels=img_channels,\n",
    "    ).to(device)\n",
    "\n",
    "    generator = train_cgan(\n",
    "        train_loader=train_loader,\n",
    "        G=generator,\n",
    "        D=discriminator,\n",
    "        latent_dim=latent_dim,\n",
    "        num_classes=num_classes,\n",
    "        num_epochs=gan_epochs,\n",
    "        device=device,\n",
    "        label_target=0,\n",
    "    ).eval()\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    return generator, elapsed\n",
    "\n",
    "\n",
    "def train_class0_wgan(\n",
    "    train_loader: DataLoader,\n",
    "    *,\n",
    "    latent_dim: int,\n",
    "    gan_epochs: int,\n",
    "    device: torch.device,\n",
    "    seed: int,\n",
    "    img_channels: int,\n",
    ") -> Tuple[nn.Module, float]:\n",
    "    \"\"\"Treina um WGAN-GP restrito à classe 0.\"\"\"\n",
    "    _seed_everything(seed)\n",
    "    start = time.time()\n",
    "\n",
    "    generator = WGANGPGenerator(latent_dim=latent_dim, img_channels=img_channels).to(device)\n",
    "    critic = WGANGPCritic(img_channels=img_channels).to(device)\n",
    "\n",
    "    generator = train_wgangp(\n",
    "        train_loader=train_loader,\n",
    "        G=generator,\n",
    "        D=critic,\n",
    "        latent_dim=latent_dim,\n",
    "        num_epochs=gan_epochs,\n",
    "        device=device,\n",
    "        label_target=0,\n",
    "    ).eval()\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    return generator, elapsed\n",
    "\n",
    "\n",
    "def train_gan_for_strategy(\n",
    "    strategy: StrategySpec,\n",
    "    train_loader: DataLoader,\n",
    "    *,\n",
    "    latent_dim: int,\n",
    "    gan_epochs: int,\n",
    "    device: torch.device,\n",
    "    seed: int,\n",
    "    img_channels: int,\n",
    "    num_classes: int,\n",
    ") -> Tuple[Optional[nn.Module], float]:\n",
    "    \"\"\"Seleciona e treina o gerador adequado para a estratégia informada.\"\"\"\n",
    "    if not strategy.uses_gan:\n",
    "        return None, 0.0\n",
    "\n",
    "    if strategy.key == \"dcgan\":\n",
    "        return train_class0_gan(\n",
    "            train_loader,\n",
    "            latent_dim=latent_dim,\n",
    "            gan_epochs=gan_epochs,\n",
    "            device=device,\n",
    "            seed=seed,\n",
    "            img_channels=img_channels,\n",
    "        )\n",
    "    if strategy.key == \"cgan\":\n",
    "        return train_class0_cgan(\n",
    "            train_loader,\n",
    "            latent_dim=latent_dim,\n",
    "            gan_epochs=gan_epochs,\n",
    "            device=device,\n",
    "            seed=seed,\n",
    "            img_channels=img_channels,\n",
    "            num_classes=num_classes,\n",
    "        )\n",
    "    if strategy.key == \"wgan\":\n",
    "        return train_class0_wgan(\n",
    "            train_loader,\n",
    "            latent_dim=latent_dim,\n",
    "            gan_epochs=gan_epochs,\n",
    "            device=device,\n",
    "            seed=seed,\n",
    "            img_channels=img_channels,\n",
    "        )\n",
    "\n",
    "    raise ValueError(f\"Estratégia desconhecida para treinamento de GAN: {strategy.key}\")\n",
    "\n",
    "\n",
    "def train_classifier(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    *,\n",
    "    epochs: int,\n",
    "    device: torch.device,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Treina um classificador supervisionado usando Cross-Entropy Loss.\n",
    "\n",
    "    Args:\n",
    "        model: Rede neural PyTorch.\n",
    "        loader: DataLoader com os dados de treino.\n",
    "        epochs: Número de épocas de treinamento.\n",
    "        device: Dispositivo (CPU/GPU).\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def evaluate_classifier(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    *,\n",
    "    device: torch.device,\n",
    ") -> Tuple[float, float, float, float, float, int, int, int, int]:\n",
    "    \"\"\"\n",
    "    Avalia o classificador em um conjunto de dados e calcula métricas de desempenho.\"\"\"\n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score,\n",
    "        confusion_matrix,\n",
    "        f1_score,\n",
    "        precision_score,\n",
    "        recall_score,\n",
    "        roc_auc_score,\n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    preds: List[Tensor] = []\n",
    "    labels: List[Tensor] = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            out = model(x)\n",
    "            preds.append(out.argmax(dim=1).cpu())\n",
    "            labels.append(y)\n",
    "\n",
    "    y_true = torch.cat(labels).numpy()\n",
    "    y_pred = torch.cat(preds).numpy()\n",
    "\n",
    "    def _safe_metric(func, default=np.nan):\n",
    "        try:\n",
    "            return float(func(y_true, y_pred))\n",
    "        except Exception:\n",
    "            return float(default)\n",
    "\n",
    "    acc = _safe_metric(accuracy_score)\n",
    "    prec = _safe_metric(lambda yt, yp: precision_score(yt, yp, zero_division=0))\n",
    "    rec = _safe_metric(lambda yt, yp: recall_score(yt, yp, zero_division=0))\n",
    "    f1 = _safe_metric(lambda yt, yp: f1_score(yt, yp, zero_division=0))\n",
    "    auc = _safe_metric(roc_auc_score, default=np.nan)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    return acc, prec, rec, f1, auc, int(tn), int(fp), int(fn), int(tp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a84a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Execução do experimento\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Funções auxiliares\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def compute_stage_seeds(\n",
    "    config: ExperimentConfig,\n",
    "    strategy_index: int,\n",
    "    gan_id: int,\n",
    "    gen_id: int,\n",
    "    clf_id: int,\n",
    ") -> StageSeeds:\n",
    "    \"\"\"Gera sementes determinísticas para as três fases do experimento.\"\"\"\n",
    "    base = config.base_seed + strategy_index * 10_000_000\n",
    "    gan_seed = base + gan_id\n",
    "    generation_seed = base + 1_000 * gan_id + gen_id\n",
    "    classifier_seed = base + 1_000_000 * gan_id + 1_000 * gen_id + clf_id\n",
    "    return StageSeeds(\n",
    "        gan_seed=gan_seed,\n",
    "        generation_seed=generation_seed,\n",
    "        classifier_seed=classifier_seed,\n",
    "    )\n",
    "\n",
    "\n",
    "def prepare_resnet(device: torch.device) -> nn.Module:\n",
    "    \"\"\"Cria e retorna uma instância de ResNet18 adaptada para imagens monocanais (1 canal).\"\"\"\n",
    "    model = resnet18(num_classes=2)\n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Pipeline principal de execução\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def run_balance_experiments(config: ExperimentConfig) -> Tuple[pd.DataFrame, Dict[str, pd.DataFrame], Dict[str, object]]:\n",
    "    \"\"\"\n",
    "    Executa o pipeline completo de balanceamento com diferentes estratégias.\"\"\"\n",
    "    device = _resolve_device(config.device)\n",
    "\n",
    "    bundle = load_medmnist_data(\n",
    "        data_flag=config.data_flag,\n",
    "        batch_size=config.data_batch_size,\n",
    "        download=True,\n",
    "    )\n",
    "\n",
    "    train_dataset = bundle.train_dataset\n",
    "    test_dataset = bundle.test_dataset\n",
    "    train_loader = bundle.train_loader\n",
    "    eval_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config.classifier_batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=device.type == \"cuda\",\n",
    "        drop_last=False,\n",
    "        collate_fn=custom_collate_fn,\n",
    "    )\n",
    "\n",
    "    images, labels = tensorize_dataset(train_dataset)\n",
    "    base_dataset = TensorDataset(images, labels)\n",
    "\n",
    "    counts = count_class_samples(base_dataset)\n",
    "    real_class0 = counts.get(0, 0)\n",
    "    real_class1 = counts.get(1, 0)\n",
    "    total_real_samples = len(base_dataset)\n",
    "    deficit = max(0, real_class1 - real_class0)\n",
    "\n",
    "    results: List[Dict[str, object]] = []\n",
    "    img_channels = images.shape[1]\n",
    "    num_classes = bundle.num_classes if hasattr(bundle, \"num_classes\") else 2\n",
    "\n",
    "    strategy_order = {spec.key: idx for idx, spec in enumerate(BALANCING_STRATEGIES, start=1)}\n",
    "    strategy_names = {spec.key: spec.display_name for spec in BALANCING_STRATEGIES}\n",
    "\n",
    "    for strategy_idx, strategy in enumerate(BALANCING_STRATEGIES, start=1):\n",
    "        for gan_run in range(1, config.num_gan_runs + 1):\n",
    "            seeds_for_gan = compute_stage_seeds(config, strategy_idx, gan_run, 0, 0)\n",
    "            generator = None\n",
    "            gan_time = 0.0\n",
    "\n",
    "            if strategy.uses_gan:\n",
    "                generator, gan_time = train_gan_for_strategy(\n",
    "                    strategy,\n",
    "                    train_loader,\n",
    "                    latent_dim=config.latent_dim,\n",
    "                    gan_epochs=config.gan_epochs,\n",
    "                    device=device,\n",
    "                    seed=seeds_for_gan.gan_seed,\n",
    "                    img_channels=img_channels,\n",
    "                    num_classes=num_classes,\n",
    "                )\n",
    "\n",
    "            try:\n",
    "                for gen_run in range(1, config.num_generation_runs + 1):\n",
    "                    seeds_for_generation = compute_stage_seeds(\n",
    "                        config, strategy_idx, gan_run, gen_run, 0\n",
    "                    )\n",
    "\n",
    "                    if strategy.key == \"baseline\":\n",
    "                        balanced_dataset, synth_count, ratio, generation_time = build_baseline_dataset(\n",
    "                            images, labels\n",
    "                        )\n",
    "                    elif strategy.key in {\"dcgan\", \"cgan\", \"wgan\"}:\n",
    "                        balanced_dataset, synth_count, ratio, generation_time = build_gan_balanced_dataset(\n",
    "                            images,\n",
    "                            labels,\n",
    "                            generator,\n",
    "                            latent_dim=config.latent_dim,\n",
    "                            synthetic_count=deficit,\n",
    "                            device=device,\n",
    "                            seed=seeds_for_generation.generation_seed,\n",
    "                            conditional_label=strategy.conditional_label,\n",
    "                        )\n",
    "                    elif strategy.key == \"smote\":\n",
    "                        balanced_dataset, synth_count, ratio, generation_time = build_smote_dataset(\n",
    "                            images,\n",
    "                            labels,\n",
    "                            target_minority=real_class1,\n",
    "                            seed=seeds_for_generation.generation_seed,\n",
    "                        )\n",
    "                    elif strategy.key == \"undersample\":\n",
    "                        balanced_dataset, synth_count, ratio, generation_time = build_undersampled_dataset(\n",
    "                            images,\n",
    "                            labels,\n",
    "                            minority_count=real_class0,\n",
    "                            seed=seeds_for_generation.generation_seed,\n",
    "                        )\n",
    "                    elif strategy.key == \"oversample\":\n",
    "                        balanced_dataset, synth_count, ratio, generation_time = build_oversampled_dataset(\n",
    "                            images,\n",
    "                            labels,\n",
    "                            target_minority=real_class1,\n",
    "                            seed=seeds_for_generation.generation_seed,\n",
    "                        )\n",
    "                    else:\n",
    "                        raise ValueError(f\"Estratégia de balanceamento desconhecida: {strategy.key}\")\n",
    "\n",
    "                    loader = DataLoader(\n",
    "                        balanced_dataset,\n",
    "                        batch_size=config.classifier_batch_size,\n",
    "                        shuffle=True,\n",
    "                        pin_memory=device.type == \"cuda\",\n",
    "                        drop_last=False,\n",
    "                        collate_fn=custom_collate_fn,\n",
    "                    )\n",
    "\n",
    "                    for clf_run in range(1, config.num_classifier_runs + 1):\n",
    "                        seeds = compute_stage_seeds(\n",
    "                            config, strategy_idx, gan_run, gen_run, clf_run\n",
    "                        )\n",
    "                        _seed_everything(seeds.classifier_seed)\n",
    "\n",
    "                        model = prepare_resnet(device)\n",
    "\n",
    "                        train_start = time.time()\n",
    "                        train_classifier(\n",
    "                            model,\n",
    "                            loader,\n",
    "                            epochs=config.classifier_epochs,\n",
    "                            device=device,\n",
    "                        )\n",
    "                        train_time = time.time() - train_start\n",
    "\n",
    "                        eval_start = time.time()\n",
    "                        acc, prec, rec, f1, auc, tn, fp, fn, tp = evaluate_classifier(\n",
    "                            model,\n",
    "                            eval_loader,\n",
    "                            device=device,\n",
    "                        )\n",
    "                        eval_time = time.time() - eval_start\n",
    "\n",
    "                        result = {\n",
    "                            \"strategy\": strategy.key,\n",
    "                            \"strategy_display_name\": strategy.display_name,\n",
    "                            \"strategy_index\": strategy_order[strategy.key],\n",
    "                            \"gan_run_id\": gan_run,\n",
    "                            \"generation_run_id\": gen_run,\n",
    "                            \"classifier_run_id\": clf_run,\n",
    "                            \"ratio\": ratio,\n",
    "                            \"acc\": acc,\n",
    "                            \"prec\": prec,\n",
    "                            \"rec\": rec,\n",
    "                            \"f1\": f1,\n",
    "                            \"auc\": auc,\n",
    "                            \"tn\": tn,\n",
    "                            \"fp\": fp,\n",
    "                            \"fn\": fn,\n",
    "                            \"tp\": tp,\n",
    "                            \"synthetic_class0_count\": synth_count,\n",
    "                            \"balanced_dataset_size\": len(balanced_dataset),\n",
    "                            \"total_real_samples\": total_real_samples,\n",
    "                            \"real_class0_count\": real_class0,\n",
    "                            \"real_class1_count\": real_class1,\n",
    "                            \"gan_training_time_sec\": gan_time,\n",
    "                            \"synthetic_generation_time_sec\": generation_time,\n",
    "                            \"classifier_training_time_sec\": train_time,\n",
    "                            \"classifier_eval_time_sec\": eval_time,\n",
    "                            \"gan_seed\": seeds_for_gan.gan_seed,\n",
    "                            \"generation_seed\": seeds_for_generation.generation_seed,\n",
    "                            \"classifier_seed\": seeds.classifier_seed,\n",
    "                        }\n",
    "\n",
    "                        results.append(result)\n",
    "            finally:\n",
    "                if generator is not None:\n",
    "                    generator.cpu()\n",
    "                    del generator\n",
    "                    if device.type == \"cuda\":\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "\n",
    "    summary_tables: Dict[str, pd.DataFrame] = {\n",
    "        \"overall\": aggregate_metrics(df_results, []),\n",
    "        \"by_gan\": aggregate_metrics(df_results, [\"strategy\", \"gan_run_id\"]),\n",
    "        \"by_gan_generation\": aggregate_metrics(\n",
    "            df_results, [\"strategy\", \"gan_run_id\", \"generation_run_id\"]\n",
    "        ),\n",
    "        \"by_strategy\": aggregate_metrics(df_results, [\"strategy\"]),\n",
    "    }\n",
    "\n",
    "    summary = summary_tables[\"by_strategy\"]\n",
    "    if not summary.empty:\n",
    "        summary[\"strategy_display_name\"] = summary[\"strategy\"].map(strategy_names)\n",
    "        summary[\"strategy_order\"] = summary[\"strategy\"].map(strategy_order)\n",
    "        summary = summary.sort_values(\"strategy_order\").drop(columns=[\"strategy_order\"])\n",
    "        cols = [\n",
    "            \"strategy_display_name\",\n",
    "            \"strategy\",\n",
    "        ] + [c for c in summary.columns if c not in {\"strategy_display_name\", \"strategy\"}]\n",
    "        summary_tables[\"by_strategy\"] = summary[cols]\n",
    "\n",
    "    metadata: Dict[str, object] = {\n",
    "        \"data_flag\": config.data_flag,\n",
    "        \"latent_dim\": config.latent_dim,\n",
    "        \"gan_epochs\": config.gan_epochs,\n",
    "        \"classifier_epochs\": config.classifier_epochs,\n",
    "        \"num_gan_runs\": config.num_gan_runs,\n",
    "        \"num_generation_runs\": config.num_generation_runs,\n",
    "        \"num_classifier_runs\": config.num_classifier_runs,\n",
    "        \"classifier_batch_size\": config.classifier_batch_size,\n",
    "        \"data_batch_size\": config.data_batch_size,\n",
    "        \"device\": str(device),\n",
    "        \"base_seed\": config.base_seed,\n",
    "        \"real_class0_count\": real_class0,\n",
    "        \"real_class1_count\": real_class1,\n",
    "        \"synthetic_needed_for_balance\": deficit,\n",
    "        \"total_real_samples\": total_real_samples,\n",
    "        \"strategies\": [spec.display_name for spec in BALANCING_STRATEGIES],\n",
    "        \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "    }\n",
    "\n",
    "    return df_results, summary_tables, metadata\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Agregação de métricas\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def aggregate_metrics(df: pd.DataFrame, group_cols: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Agrega métricas de classificação, tempo e estatísticas por grupo de execuções.\"\"\"\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=group_cols + [f\"{m}_mean\" for m in AGGREGATION_FIELDS])\n",
    "\n",
    "    grouped = df.groupby(group_cols) if group_cols else [((), df)]\n",
    "    rows: List[Dict[str, object]] = []\n",
    "\n",
    "    for key, group in grouped:\n",
    "        if not isinstance(key, tuple):\n",
    "            key = (key,)\n",
    "\n",
    "        row: Dict[str, object] = {}\n",
    "        for idx, col in enumerate(group_cols):\n",
    "            row[col] = key[idx]\n",
    "\n",
    "        row[\"num_rows\"] = len(group)\n",
    "\n",
    "        for metric in AGGREGATION_FIELDS:\n",
    "            if metric in group:\n",
    "                row[f\"{metric}_mean\"] = float(group[metric].mean())\n",
    "                row[f\"{metric}_std\"] = float(group[metric].std(ddof=0))\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bc2f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Persistência de resultados\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def save_results(\n",
    "    df_results: pd.DataFrame,\n",
    "    summary_tables: Dict[str, pd.DataFrame],\n",
    "    metadata: Dict[str, object],\n",
    "    output_dir: Path,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Salva os resultados do experimento (tabelas e metadados) em arquivos CSV e JSON.\n",
    "\n",
    "    Args:\n",
    "        df_results: DataFrame contendo os resultados detalhados de todas as execuções.\n",
    "        summary_tables: Dicionário com tabelas agregadas de métricas.\n",
    "        metadata: Dicionário com informações da configuração e execução do experimento.\n",
    "        output_dir: Diretório de saída onde os arquivos serão salvos.\n",
    "\n",
    "    Saídas:\n",
    "        - balance_class0_results.csv: Resultados completos.\n",
    "        - summary_*.csv: Tabelas de resumo (overall, por GAN, etc.).\n",
    "        - metadata.json: Informações descritivas e parâmetros da execução.\n",
    "    \"\"\"\n",
    "    # Cria o diretório de saída, se necessário\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Salva resultados completos\n",
    "    results_path = output_dir / \"balance_class0_results.csv\"\n",
    "    df_results.to_csv(results_path, index=False)\n",
    "\n",
    "    # Salva tabelas agregadas\n",
    "    for name, df in summary_tables.items():\n",
    "        df.to_csv(output_dir / f\"summary_{name}.csv\", index=False)\n",
    "\n",
    "    # Salva metadados como JSON\n",
    "    with open(output_dir / \"metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metadata, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f405194",
   "metadata": {},
   "source": [
    "## Execução do experimento. Ajuste os hiperparâmetros abaixo conforme necessário. Dependendo dos valores escolhidos(as execuções padrão são 10×10×10), o processo pode ser bastante demorado. Para testes rápidos,reduza os contadores de repetições e épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ff0f9a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/mahlow/.medmnist/breastmnist.npz\n",
      "Using downloaded and verified file: /home/mahlow/.medmnist/breastmnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_595721/3240726967.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  ys_list.append(int(label))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Loss D: 1.296 | Loss G: 0.868\n",
      "Epoch 2/50 - Loss D: 0.813 | Loss G: 1.175\n",
      "Epoch 3/50 - Loss D: 0.567 | Loss G: 1.496\n",
      "Epoch 4/50 - Loss D: 0.446 | Loss G: 1.780\n",
      "Epoch 5/50 - Loss D: 0.351 | Loss G: 2.056\n",
      "Epoch 6/50 - Loss D: 0.261 | Loss G: 2.259\n",
      "Epoch 7/50 - Loss D: 0.260 | Loss G: 2.368\n",
      "Epoch 8/50 - Loss D: 0.194 | Loss G: 2.464\n",
      "Epoch 9/50 - Loss D: 0.203 | Loss G: 2.556\n",
      "Epoch 10/50 - Loss D: 0.139 | Loss G: 2.787\n",
      "Epoch 11/50 - Loss D: 0.130 | Loss G: 3.005\n",
      "Epoch 12/50 - Loss D: 0.105 | Loss G: 3.075\n",
      "Epoch 13/50 - Loss D: 0.101 | Loss G: 3.220\n",
      "Epoch 14/50 - Loss D: 0.084 | Loss G: 3.326\n",
      "Epoch 15/50 - Loss D: 0.080 | Loss G: 3.334\n",
      "Epoch 16/50 - Loss D: 0.076 | Loss G: 3.418\n",
      "Epoch 17/50 - Loss D: 0.070 | Loss G: 3.472\n",
      "Epoch 18/50 - Loss D: 0.062 | Loss G: 3.549\n",
      "Epoch 19/50 - Loss D: 0.054 | Loss G: 3.752\n",
      "Epoch 20/50 - Loss D: 0.053 | Loss G: 3.678\n",
      "Epoch 21/50 - Loss D: 0.204 | Loss G: 3.052\n",
      "Epoch 22/50 - Loss D: 0.122 | Loss G: 3.750\n",
      "Epoch 23/50 - Loss D: 0.111 | Loss G: 3.742\n",
      "Epoch 24/50 - Loss D: 0.072 | Loss G: 3.725\n",
      "Epoch 25/50 - Loss D: 0.053 | Loss G: 3.912\n",
      "Epoch 26/50 - Loss D: 0.052 | Loss G: 3.923\n",
      "Epoch 27/50 - Loss D: 0.067 | Loss G: 3.709\n",
      "Epoch 28/50 - Loss D: 0.057 | Loss G: 3.950\n",
      "Epoch 29/50 - Loss D: 0.077 | Loss G: 3.972\n",
      "Epoch 30/50 - Loss D: 0.055 | Loss G: 4.025\n",
      "Epoch 31/50 - Loss D: 0.047 | Loss G: 4.215\n",
      "Epoch 32/50 - Loss D: 0.059 | Loss G: 3.967\n",
      "Epoch 33/50 - Loss D: 0.071 | Loss G: 3.778\n",
      "Epoch 34/50 - Loss D: 0.081 | Loss G: 3.776\n",
      "Epoch 35/50 - Loss D: 0.124 | Loss G: 3.492\n",
      "Epoch 36/50 - Loss D: 0.122 | Loss G: 3.636\n",
      "Epoch 37/50 - Loss D: 0.161 | Loss G: 3.379\n",
      "Epoch 38/50 - Loss D: 0.165 | Loss G: 3.351\n",
      "Epoch 39/50 - Loss D: 0.241 | Loss G: 3.341\n",
      "Epoch 40/50 - Loss D: 0.415 | Loss G: 3.157\n",
      "Epoch 41/50 - Loss D: 0.672 | Loss G: 2.979\n",
      "Epoch 42/50 - Loss D: 0.386 | Loss G: 3.898\n",
      "Epoch 43/50 - Loss D: 0.300 | Loss G: 2.927\n",
      "Epoch 44/50 - Loss D: 0.235 | Loss G: 3.213\n",
      "Epoch 45/50 - Loss D: 0.282 | Loss G: 2.953\n",
      "Epoch 46/50 - Loss D: 0.421 | Loss G: 2.656\n",
      "Epoch 47/50 - Loss D: 0.270 | Loss G: 3.340\n",
      "Epoch 48/50 - Loss D: 0.192 | Loss G: 3.273\n",
      "Epoch 49/50 - Loss D: 0.229 | Loss G: 3.179\n",
      "Epoch 50/50 - Loss D: 0.184 | Loss G: 3.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_595721/3240726967.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  ys_list.append(int(label))\n",
      "/tmp/ipykernel_595721/3240726967.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  ys_list.append(int(label))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Loss D: -1.2006 | Loss G: 0.4956\n",
      "Epoch 2/50 | Loss D: -4.5872 | Loss G: 1.0913\n",
      "Epoch 3/50 | Loss D: -6.0631 | Loss G: 1.5362\n",
      "Epoch 4/50 | Loss D: -7.9754 | Loss G: 2.1832\n",
      "Epoch 5/50 | Loss D: -9.2319 | Loss G: 2.6307\n",
      "Epoch 6/50 | Loss D: -10.1630 | Loss G: 3.4293\n",
      "Epoch 7/50 | Loss D: -12.2373 | Loss G: 3.9435\n",
      "Epoch 8/50 | Loss D: -13.9389 | Loss G: 4.5702\n",
      "Epoch 9/50 | Loss D: -13.0932 | Loss G: 4.9185\n",
      "Epoch 10/50 | Loss D: -15.3010 | Loss G: 5.0502\n",
      "Epoch 11/50 | Loss D: -16.1803 | Loss G: 5.8140\n",
      "Epoch 12/50 | Loss D: -17.5843 | Loss G: 6.2687\n",
      "Epoch 13/50 | Loss D: -17.9028 | Loss G: 6.2935\n",
      "Epoch 14/50 | Loss D: -19.6762 | Loss G: 6.8740\n",
      "Epoch 15/50 | Loss D: -19.0058 | Loss G: 7.2204\n",
      "Epoch 16/50 | Loss D: -19.8783 | Loss G: 7.1760\n",
      "Epoch 17/50 | Loss D: -21.1980 | Loss G: 7.6468\n",
      "Epoch 18/50 | Loss D: -22.4456 | Loss G: 7.3861\n",
      "Epoch 19/50 | Loss D: -23.1469 | Loss G: 8.1046\n",
      "Epoch 20/50 | Loss D: -23.8352 | Loss G: 8.5580\n",
      "Epoch 21/50 | Loss D: -22.0286 | Loss G: 8.4055\n",
      "Epoch 22/50 | Loss D: -22.4022 | Loss G: 8.2380\n",
      "Epoch 23/50 | Loss D: -24.8937 | Loss G: 8.1653\n",
      "Epoch 24/50 | Loss D: -27.6265 | Loss G: 8.5261\n",
      "Epoch 25/50 | Loss D: -27.9540 | Loss G: 8.9091\n",
      "Epoch 26/50 | Loss D: -28.9131 | Loss G: 8.9534\n",
      "Epoch 27/50 | Loss D: -29.1079 | Loss G: 8.2168\n",
      "Epoch 28/50 | Loss D: -25.2674 | Loss G: 8.5612\n",
      "Epoch 29/50 | Loss D: -28.9422 | Loss G: 8.4965\n",
      "Epoch 30/50 | Loss D: -29.9916 | Loss G: 8.2720\n",
      "Epoch 31/50 | Loss D: -26.7622 | Loss G: 7.4720\n",
      "Epoch 32/50 | Loss D: -27.4383 | Loss G: 7.8373\n",
      "Epoch 33/50 | Loss D: -24.4710 | Loss G: 7.7742\n",
      "Epoch 34/50 | Loss D: -32.6193 | Loss G: 7.1712\n",
      "Epoch 35/50 | Loss D: -31.5965 | Loss G: 7.2757\n",
      "Epoch 36/50 | Loss D: -23.0074 | Loss G: 7.2915\n",
      "Epoch 37/50 | Loss D: -33.4313 | Loss G: 6.7204\n",
      "Epoch 38/50 | Loss D: -32.4412 | Loss G: 6.2387\n",
      "Epoch 39/50 | Loss D: -32.6370 | Loss G: 6.1149\n",
      "Epoch 40/50 | Loss D: -31.8723 | Loss G: 5.8606\n",
      "Epoch 41/50 | Loss D: -32.1044 | Loss G: 5.3716\n",
      "Epoch 42/50 | Loss D: -28.5829 | Loss G: 5.1201\n",
      "Epoch 43/50 | Loss D: -32.0633 | Loss G: 4.9322\n",
      "Epoch 44/50 | Loss D: -32.5695 | Loss G: 5.0555\n",
      "Epoch 45/50 | Loss D: -30.9499 | Loss G: 4.4774\n",
      "Epoch 46/50 | Loss D: -35.2259 | Loss G: 4.9766\n",
      "Epoch 47/50 | Loss D: -37.0959 | Loss G: 4.2254\n",
      "Epoch 48/50 | Loss D: -37.4740 | Loss G: 4.2448\n",
      "Epoch 49/50 | Loss D: -31.3805 | Loss G: 3.7311\n",
      "Epoch 50/50 | Loss D: -28.7992 | Loss G: 3.8206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_595721/3240726967.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  ys_list.append(int(label))\n",
      "/tmp/ipykernel_595721/3240726967.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  ys_list.append(int(label))\n",
      "/tmp/ipykernel_595721/3240726967.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  ys_list.append(int(label))\n",
      "/tmp/ipykernel_595721/3240726967.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  ys_list.append(int(label))\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Exemplo de configuração enxuta para testes rápidos\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    data_flag=\"breastmnist\",\n",
    "    data_batch_size=128,\n",
    "    latent_dim=100,\n",
    "    gan_epochs=50,\n",
    "    classifier_epochs=1,\n",
    "    num_gan_runs=1,\n",
    "    num_generation_runs=1,\n",
    "    num_classifier_runs=1,\n",
    "    classifier_batch_size=64,\n",
    "    device=\"auto\",\n",
    "    base_seed=2024,\n",
    "    output_dir=Path(\"balance_class0_runs_demo\"),\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Execução opcional do pipeline completo\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Descomente as linhas abaixo para executar todo o experimento.\n",
    "# Isso irá:\n",
    "# 1. Treinar os geradores necessários para cada estratégia (quando aplicável).\n",
    "# 2. Gerar datasets balanceados para cada abordagem.\n",
    "# 3. Treinar e avaliar diversas vezes o classificador ResNet-18.\n",
    "# 4. Salvar os resultados e metadados no diretório especificado.\n",
    "\n",
    "df_results, summary_tables, metadata = run_balance_experiments(config)\n",
    "save_results(df_results, summary_tables, metadata, config.output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e8149d0-37b7-4491-bbe8-32721ecbdf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strategy_display_name</th>\n",
       "      <th>strategy</th>\n",
       "      <th>num_rows</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>prec_mean</th>\n",
       "      <th>prec_std</th>\n",
       "      <th>rec_mean</th>\n",
       "      <th>rec_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>synthetic_class0_count_mean</th>\n",
       "      <th>synthetic_class0_count_std</th>\n",
       "      <th>balanced_dataset_size_mean</th>\n",
       "      <th>balanced_dataset_size_std</th>\n",
       "      <th>total_real_samples_mean</th>\n",
       "      <th>total_real_samples_std</th>\n",
       "      <th>real_class0_count_mean</th>\n",
       "      <th>real_class0_count_std</th>\n",
       "      <th>real_class1_count_mean</th>\n",
       "      <th>real_class1_count_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ResNet sem balanceamento</td>\n",
       "      <td>baseline</td>\n",
       "      <td>1</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DCGAN (classe 0)</td>\n",
       "      <td>dcgan</td>\n",
       "      <td>1</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>...</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>798.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CGAN (classe 0)</td>\n",
       "      <td>cgan</td>\n",
       "      <td>1</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.901408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.691892</td>\n",
       "      <td>...</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>798.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WGAN-GP (classe 0)</td>\n",
       "      <td>wgan</td>\n",
       "      <td>1</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>...</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>798.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTE (classe 0)</td>\n",
       "      <td>smote</td>\n",
       "      <td>1</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>...</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>798.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Undersampling da classe 1</td>\n",
       "      <td>undersample</td>\n",
       "      <td>1</td>\n",
       "      <td>0.371795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oversampling por repetição (classe 0)</td>\n",
       "      <td>oversample</td>\n",
       "      <td>1</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>...</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>798.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   strategy_display_name     strategy  num_rows  acc_mean  \\\n",
       "0               ResNet sem balanceamento     baseline         1  0.717949   \n",
       "2                       DCGAN (classe 0)        dcgan         1  0.730769   \n",
       "1                        CGAN (classe 0)         cgan         1  0.634615   \n",
       "6                     WGAN-GP (classe 0)         wgan         1  0.730769   \n",
       "4                       SMOTE (classe 0)        smote         1  0.487179   \n",
       "5              Undersampling da classe 1  undersample         1  0.371795   \n",
       "3  Oversampling por repetição (classe 0)   oversample         1  0.384615   \n",
       "\n",
       "   acc_std  prec_mean  prec_std  rec_mean  rec_std   f1_mean  ...  \\\n",
       "0      0.0   0.769231       0.0  0.877193      0.0  0.819672  ...   \n",
       "2      0.0   0.730769       0.0  1.000000      0.0  0.844444  ...   \n",
       "1      0.0   0.901408       0.0  0.561404      0.0  0.691892  ...   \n",
       "6      0.0   0.740000       0.0  0.973684      0.0  0.840909  ...   \n",
       "4      0.0   0.904762       0.0  0.333333      0.0  0.487179  ...   \n",
       "5      0.0   0.900000       0.0  0.157895      0.0  0.268657  ...   \n",
       "3      0.0   0.875000       0.0  0.184211      0.0  0.304348  ...   \n",
       "\n",
       "   synthetic_class0_count_mean  synthetic_class0_count_std  \\\n",
       "0                          0.0                         0.0   \n",
       "2                        252.0                         0.0   \n",
       "1                        252.0                         0.0   \n",
       "6                        252.0                         0.0   \n",
       "4                        252.0                         0.0   \n",
       "5                          0.0                         0.0   \n",
       "3                        252.0                         0.0   \n",
       "\n",
       "   balanced_dataset_size_mean  balanced_dataset_size_std  \\\n",
       "0                       546.0                        0.0   \n",
       "2                       798.0                        0.0   \n",
       "1                       798.0                        0.0   \n",
       "6                       798.0                        0.0   \n",
       "4                       798.0                        0.0   \n",
       "5                       294.0                        0.0   \n",
       "3                       798.0                        0.0   \n",
       "\n",
       "   total_real_samples_mean  total_real_samples_std  real_class0_count_mean  \\\n",
       "0                    546.0                     0.0                   147.0   \n",
       "2                    546.0                     0.0                   147.0   \n",
       "1                    546.0                     0.0                   147.0   \n",
       "6                    546.0                     0.0                   147.0   \n",
       "4                    546.0                     0.0                   147.0   \n",
       "5                    546.0                     0.0                   147.0   \n",
       "3                    546.0                     0.0                   147.0   \n",
       "\n",
       "   real_class0_count_std  real_class1_count_mean  real_class1_count_std  \n",
       "0                    0.0                   399.0                    0.0  \n",
       "2                    0.0                   399.0                    0.0  \n",
       "1                    0.0                   399.0                    0.0  \n",
       "6                    0.0                   399.0                    0.0  \n",
       "4                    0.0                   399.0                    0.0  \n",
       "5                    0.0                   399.0                    0.0  \n",
       "3                    0.0                   399.0                    0.0  \n",
       "\n",
       "[7 rows x 41 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exiba os resultados agregados por estratégia após executar o pipeline\n",
    "summary_tables[\"by_strategy\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f209d4",
   "metadata": {},
   "source": [
    "## Utilitário de linha de comando (opcional)As funções abaixo permitem reutilizar o parser de argumentos do script original, casoqueira invocar o notebook via `papermill` ou semelhante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712accba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Parser de argumentos para execução programática\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def parse_args() -> ExperimentConfig:\n",
    "    \"\"\"\n",
    "    Cria e interpreta argumentos de linha de comando para configurar o experimento.\n",
    "\n",
    "    Em um notebook, o parse_args([]) evita erros por ausência de argumentos\n",
    "    e retorna um objeto ExperimentConfig com valores padrão ou definidos manualmente.\n",
    "\n",
    "    Returns:\n",
    "        ExperimentConfig: Objeto de configuração preenchido com os parâmetros fornecidos.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Run repeated class-0 balancing experiments with DCGAN and ResNet-18\",\n",
    "    )\n",
    "\n",
    "    # Argumentos principais\n",
    "    parser.add_argument(\"--data-flag\", default=\"breastmnist\", help=\"MedMNIST dataset flag\")\n",
    "    parser.add_argument(\"--data-batch-size\", type=int, default=128, help=\"Batch size for the GAN data loader\")\n",
    "    parser.add_argument(\"--latent-dim\", type=int, default=100, help=\"Latent dimension for the GAN\")\n",
    "    parser.add_argument(\"--gan-epochs\", type=int, default=50, help=\"Number of epochs for GAN training\")\n",
    "    parser.add_argument(\n",
    "        \"--classifier-epochs\",\n",
    "        type=int,\n",
    "        default=5,\n",
    "        help=\"Number of epochs for each ResNet-18 training run\",\n",
    "    )\n",
    "    parser.add_argument(\"--num-gan-runs\", type=int, default=10, help=\"How many times to retrain the GAN\")\n",
    "    parser.add_argument(\n",
    "        \"--num-generation-runs\",\n",
    "        type=int,\n",
    "        default=10,\n",
    "        help=\"How many synthetic datasets to generate per GAN training\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num-classifier-runs\",\n",
    "        type=int,\n",
    "        default=10,\n",
    "        help=\"How many classifier trainings per synthetic dataset\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--classifier-batch-size\",\n",
    "        type=int,\n",
    "        default=64,\n",
    "        help=\"Batch size for the ResNet-18 training and evaluation\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\",\n",
    "        default=\"auto\",\n",
    "        help=\"Device to use (cuda, cpu or auto)\",\n",
    "    )\n",
    "    parser.add_argument(\"--base-seed\", type=int, default=2024, help=\"Base seed for reproducibility\")\n",
    "    parser.add_argument(\n",
    "        \"--output-dir\",\n",
    "        type=Path,\n",
    "        default=Path(\"balance_class0_runs\"),\n",
    "        help=\"Directory where CSV and metadata files will be stored\",\n",
    "    )\n",
    "\n",
    "    # parse_args([]) evita conflitos de CLI em ambientes interativos\n",
    "    args = parser.parse_args([])\n",
    "\n",
    "    return ExperimentConfig(\n",
    "        data_flag=args.data_flag,\n",
    "        data_batch_size=args.data_batch_size,\n",
    "        latent_dim=args.latent_dim,\n",
    "        gan_epochs=args.gan_epochs,\n",
    "        classifier_epochs=args.classifier_epochs,\n",
    "        num_gan_runs=args.num_gan_runs,\n",
    "        num_generation_runs=args.num_generation_runs,\n",
    "        num_classifier_runs=args.num_classifier_runs,\n",
    "        classifier_batch_size=args.classifier_batch_size,\n",
    "        device=args.device,\n",
    "        base_seed=args.base_seed,\n",
    "        output_dir=args.output_dir,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe515352-d686-41fc-871c-2ea7f4b4cd3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab981f2-66e4-48b2-93f8-c61081ee40f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

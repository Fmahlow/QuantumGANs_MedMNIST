{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelos de Difusão com BreastMNIST\n",
        "\n",
        "Este notebook demonstra como treinar duas redes de difusão não condicionais (**DDPM**) utilizando o dataset **BreastMNIST** do MedMNIST.\n",
        "O procedimento segue a mesma preparação do notebook `gan_classical_medmnist`, porém substituindo as GANs por modelos de difusão.\n",
        "Treinaremos um modelo para a classe 0 e outro para a classe 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Instalação de dependências\n",
        "!pip install -q diffusers accelerate medmnist datasets torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Configuração básica do Accelerate\n",
        "from accelerate.utils import write_basic_config\n",
        "write_basic_config()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Preparação do dataset BreastMNIST\n",
        "import os\n",
        "from pathlib import Path\n",
        "from medmnist import BreastMNIST\n",
        "from PIL import Image\n",
        "\n",
        "data_dir = Path('data/breastmnist')\n",
        "class0_dir = data_dir / 'class0'\n",
        "class1_dir = data_dir / 'class1'\n",
        "class0_dir.mkdir(parents=True, exist_ok=True)\n",
        "class1_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "train_dataset = BreastMNIST(split='train', download=True)\n",
        "imgs, labels = train_dataset.imgs, train_dataset.labels.flatten()\n",
        "for idx, (img, label) in enumerate(zip(imgs, labels)):\n",
        "    if label == 0:\n",
        "        Image.fromarray(img.squeeze()).save(class0_dir / f'{idx}.png')\n",
        "    elif label == 1:\n",
        "        Image.fromarray(img.squeeze()).save(class1_dir / f'{idx}.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Treinamento dos modelos de difusão para cada classe\n",
        "!accelerate launch diffusers/examples/unconditional_image_generation/train_unconditional.py --train_data_dir 'data/breastmnist/class0' --resolution 28 --output_dir 'ddpm_breastmnist_class0' --train_batch_size 64 --num_epochs 100 --mixed_precision fp16\n",
        "!accelerate launch diffusers/examples/unconditional_image_generation/train_unconditional.py --train_data_dir 'data/breastmnist/class1' --resolution 28 --output_dir 'ddpm_breastmnist_class1' --train_batch_size 64 --num_epochs 100 --mixed_precision fp16\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Geração de imagens a partir dos modelos treinados\n",
        "from diffusers import DiffusionPipeline\n",
        "import torch\n",
        "\n",
        "pipe0 = DiffusionPipeline.from_pretrained('ddpm_breastmnist_class0').to('cuda')\n",
        "img0 = pipe0().images[0]\n",
        "\n",
        "pipe1 = DiffusionPipeline.from_pretrained('ddpm_breastmnist_class1').to('cuda')\n",
        "img1 = pipe1().images[0]\n",
        "display(img0)\n",
        "display(img1)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
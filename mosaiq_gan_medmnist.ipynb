{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum GAN com Pennylane e MedMNIST\n",
    "\n",
    "Este notebook apresenta uma implementação simplificada de uma GAN quântica inspirada no método de *patches* descrito por Huang et al. Utilizamos o dataset **MedMNIST** para comparação com os modelos clássicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Quântico\n",
    "Instalação de `pennylane` e demais bibliotecas necessárias para execução do modelo híbrido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pennylane pennylane-lightning torch medmnist matplotlib --quiet\n",
    "import torch\n",
    "import pennylane as qml\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import medmnist\n",
    "from medmnist import INFO\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparação do Dataset\n",
    "Utilizamos o mesmo subset do notebook clássico para permitir comparação direta. Pode ser necessário reduzir a resolução das imagens para se adequar ao número de qubits disponíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 560k/560k [00:00<00:00, 1.21MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Seleciona o dataset\n",
    "DATA_FLAG = 'breastmnist'\n",
    "info = INFO[DATA_FLAG]\n",
    "download = True\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    #transforms.Resize((8, 8)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "\n",
    "# Carrega treino e teste\n",
    "train_dataset = getattr(medmnist, info['python_class'])(split='train', transform=transform, download=download)\n",
    "test_dataset = getattr(medmnist, info['python_class'])(split='test', transform=transform, download=download)\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset BreastMNIST of size 28 (breastmnist)\n",
      "    Number of datapoints: 546\n",
      "    Root location: /root/.medmnist\n",
      "    Split: train\n",
      "    Task: binary-class\n",
      "    Number of channels: 1\n",
      "    Meaning of labels: {'0': 'malignant', '1': 'normal, benign'}\n",
      "    Number of samples: {'train': 546, 'val': 78, 'test': 156}\n",
      "    Description: The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.\n",
      "    License: CC BY 4.0\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "def subset_by_label(dataset, label):\n",
    "    # suporta datasets que usam .labels ou .targets\n",
    "    labels = dataset.labels if hasattr(dataset, \"labels\") else dataset.targets\n",
    "    idx = []\n",
    "    for i, l in enumerate(labels):\n",
    "        # extrai o valor escalar de qualquer tensor ou array\n",
    "        scalar = l.item() if hasattr(l, \"item\") else int(l)\n",
    "        if scalar == label:\n",
    "            idx.append(i)\n",
    "    return Subset(dataset, idx)\n",
    "\n",
    "# agora você pode criar os DataLoaders:\n",
    "train_loader_0 = DataLoader(\n",
    "    subset_by_label(train_dataset, 0),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "train_loader_1 = DataLoader(\n",
    "    subset_by_label(train_dataset, 1),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Treinamento\n",
    "Define a função de perda adversarial e executa um ciclo de treinamento simplificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Iter 1/500: Loss D=1.334, Loss G=0.669 — 54.40s\n",
      "Iter 2/500: Loss D=1.203, Loss G=0.781 — 54.29s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 140\u001b[0m\n\u001b[1;32m    137\u001b[0m fake_lbl \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((b_size, \u001b[38;5;241m1\u001b[39m), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    139\u001b[0m noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(b_size, n_qubits, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m (math\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 140\u001b[0m fake  \u001b[38;5;241m=\u001b[39m \u001b[43mG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# treina Discriminador\u001b[39;00m\n\u001b[1;32m    143\u001b[0m optD\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 106\u001b[0m, in \u001b[0;36mQuantumGenerator.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    102\u001b[0m images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_generators \u001b[38;5;241m*\u001b[39m n_qubits, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gen_idx, params \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_params):\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# para cada amostra, roda o circuito (em CPU) e retorna CPU tensor\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     patches \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\u001b[43m[\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m            \u001b[49m\u001b[43mquantum_circuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# shape (batch_size, n_qubits)\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     start \u001b[38;5;241m=\u001b[39m gen_idx \u001b[38;5;241m*\u001b[39m n_qubits\n\u001b[1;32m    115\u001b[0m     images[:, start:start \u001b[38;5;241m+\u001b[39m n_qubits] \u001b[38;5;241m=\u001b[39m patches\n",
      "Cell \u001b[0;32mIn[10], line 108\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    102\u001b[0m images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_generators \u001b[38;5;241m*\u001b[39m n_qubits, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gen_idx, params \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_params):\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# para cada amostra, roda o circuito (em CPU) e retorna CPU tensor\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     patches \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\n\u001b[1;32m    107\u001b[0m         torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[0;32m--> 108\u001b[0m             \u001b[43mquantum_circuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    109\u001b[0m             device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m    110\u001b[0m         )\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m x\n\u001b[1;32m    112\u001b[0m     ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# shape (batch_size, n_qubits)\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     start \u001b[38;5;241m=\u001b[39m gen_idx \u001b[38;5;241m*\u001b[39m n_qubits\n\u001b[1;32m    115\u001b[0m     images[:, start:start \u001b[38;5;241m+\u001b[39m n_qubits] \u001b[38;5;241m=\u001b[39m patches\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/pennylane/workflow/qnode.py:922\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_capture_qnode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m capture_qnode  \u001b[38;5;66;03m# pylint: disable=import-outside-toplevel\u001b[39;00m\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m capture_qnode(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 922\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/pennylane/workflow/qnode.py:895\u001b[0m, in \u001b[0;36mQNode._impl_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# Calculate the classical jacobians if necessary\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_program\u001b[38;5;241m.\u001b[39mset_classical_component(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[0;32m--> 895\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiff_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_program\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    904\u001b[0m res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/pennylane/workflow/execution.py:233\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, device, diff_method, interface, grad_on_execution, cache, cachesize, max_diff, device_vjp, postselect_mode, mcm_method, gradient_kwargs, transform_program, executor_backend)\u001b[0m\n\u001b[1;32m    229\u001b[0m tapes, outer_post_processing \u001b[38;5;241m=\u001b[39m outer_transform(tapes)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m outer_transform\u001b[38;5;241m.\u001b[39mis_informative, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould only contain device preprocessing\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m user_post_processing(outer_post_processing(results))\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/pennylane/workflow/run.py:338\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(tapes, device, config, inner_transform_program)\u001b[0m\n\u001b[1;32m    335\u001b[0m         params \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mget_parameters(trainable_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    336\u001b[0m         tape\u001b[38;5;241m.\u001b[39mtrainable_params \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mget_trainable_indices(params)\n\u001b[0;32m--> 338\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mml_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecute_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjpc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/pennylane/workflow/interfaces/torch.py:240\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, execute_fn, jpc, device)\u001b[0m\n\u001b[1;32m    232\u001b[0m     parameters\u001b[38;5;241m.\u001b[39mextend(tape\u001b[38;5;241m.\u001b[39mget_parameters())\n\u001b[1;32m    234\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtapes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(tapes),\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecute_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m: execute_fn,\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjpc\u001b[39m\u001b[38;5;124m\"\u001b[39m: jpc,\n\u001b[1;32m    238\u001b[0m }\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExecuteTapes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/pennylane/workflow/interfaces/torch.py:89\u001b[0m, in \u001b[0;36mpytreeify.<locals>.new_apply\u001b[0;34m(*inp)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_apply\u001b[39m(\u001b[38;5;241m*\u001b[39minp):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Inputs already flat\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     out_struct_holder \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 89\u001b[0m     flat_out \u001b[38;5;241m=\u001b[39m \u001b[43morig_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_struct_holder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pytree\u001b[38;5;241m.\u001b[39mtree_unflatten(flat_out, out_struct_holder[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/torch/autograd/function.py:553\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    561\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/pennylane/workflow/interfaces/torch.py:93\u001b[0m, in \u001b[0;36mpytreeify.<locals>.new_forward\u001b[0;34m(ctx, out_struct_holder, *inp)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_forward\u001b[39m(ctx, out_struct_holder, \u001b[38;5;241m*\u001b[39minp):\n\u001b[0;32m---> 93\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43morig_fw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     flat_out, out_struct \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_flatten(out)\n\u001b[1;32m     95\u001b[0m     ctx\u001b[38;5;241m.\u001b[39m_out_struct \u001b[38;5;241m=\u001b[39m out_struct\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/pennylane/workflow/interfaces/torch.py:162\u001b[0m, in \u001b[0;36mExecuteTapes.forward\u001b[0;34m(ctx, kwargs, *parameters)\u001b[0m\n\u001b[1;32m    159\u001b[0m ctx\u001b[38;5;241m.\u001b[39mtapes \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtapes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    160\u001b[0m ctx\u001b[38;5;241m.\u001b[39mjpc \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjpc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 162\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexecute_fn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# if any input tensor uses the GPU, the output should as well\u001b[39;00m\n\u001b[1;32m    165\u001b[0m ctx\u001b[38;5;241m.\u001b[39mtorch_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/pennylane/workflow/run.py:253\u001b[0m, in \u001b[0;36m_make_inner_execute.<locals>.inner_execute\u001b[0;34m(tapes)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_execute\u001b[39m(tapes: QuantumScriptBatch) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResultBatch:\n\u001b[1;32m    245\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execution that occurs within a ML framework boundary.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m    Closure Variables:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m        device (qml.devices.Device): a Pennylane device\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m     transformed_tapes, transform_post_processing \u001b[38;5;241m=\u001b[39m \u001b[43minner_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m transformed_tapes:\n\u001b[1;32m    256\u001b[0m         results \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mexecute(transformed_tapes, execution_config\u001b[38;5;241m=\u001b[39mexecution_config)\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/pennylane/transforms/core/transform_program.py:501\u001b[0m, in \u001b[0;36mTransformProgram.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(args[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJaxpr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_jaxpr(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__call_tapes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/pennylane/transforms/core/transform_program.py:431\u001b[0m, in \u001b[0;36mTransformProgram.__call_tapes\u001b[0;34m(self, tapes)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m argnums \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;66;03m# pylint: disable=unsubscriptable-object\u001b[39;00m\n\u001b[1;32m    430\u001b[0m     tape\u001b[38;5;241m.\u001b[39mtrainable_params \u001b[38;5;241m=\u001b[39m argnums[tape_idx]\n\u001b[0;32m--> 431\u001b[0m new_tapes, fn \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m execution_tapes\u001b[38;5;241m.\u001b[39mextend(new_tapes)\n\u001b[1;32m    434\u001b[0m fns\u001b[38;5;241m.\u001b[39mappend(fn)\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/pennylane/transforms/convert_to_numpy_parameters.py:84\u001b[0m, in \u001b[0;36mconvert_to_numpy_parameters\u001b[0;34m(tape)\u001b[0m\n\u001b[1;32m     82\u001b[0m new_ops \u001b[38;5;241m=\u001b[39m (_convert_op_to_numpy_data(op) \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m tape\u001b[38;5;241m.\u001b[39moperations)\n\u001b[1;32m     83\u001b[0m new_measurements \u001b[38;5;241m=\u001b[39m (_convert_measurement_to_numpy_data(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m tape\u001b[38;5;241m.\u001b[39mmeasurements)\n\u001b[0;32m---> 84\u001b[0m new_circuit \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_measurements\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshots\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_params\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnull_postprocessing\u001b[39m(results):\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A postprocesing function returned by a transform that only converts the batch of results\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    into a result for a single ``QuantumTape``.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/pennylane/tape/qscript.py:194\u001b[0m, in \u001b[0;36mQuantumScript.__init__\u001b[0;34m(self, ops, measurements, shots, trainable_params)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    189\u001b[0m     ops: Optional[Iterable[Operator]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    192\u001b[0m     trainable_params: Optional[Sequence[\u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    193\u001b[0m ):\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ops \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m ops \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(ops)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_measurements \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m measurements \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(measurements)\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shots \u001b[38;5;241m=\u001b[39m Shots(shots)\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/pennylane/transforms/convert_to_numpy_parameters.py:82\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;129m@transform\u001b[39m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_numpy_parameters\u001b[39m(tape: QuantumScript) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[QuantumScriptBatch, PostprocessingFn]:\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Transforms a circuit to one with purely numpy parameters.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m \n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m     new_ops \u001b[38;5;241m=\u001b[39m (\u001b[43m_convert_op_to_numpy_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m tape\u001b[38;5;241m.\u001b[39moperations)\n\u001b[1;32m     83\u001b[0m     new_measurements \u001b[38;5;241m=\u001b[39m (_convert_measurement_to_numpy_data(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m tape\u001b[38;5;241m.\u001b[39mmeasurements)\n\u001b[1;32m     84\u001b[0m     new_circuit \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\n\u001b[1;32m     85\u001b[0m         new_ops, new_measurements, shots\u001b[38;5;241m=\u001b[39mtape\u001b[38;5;241m.\u001b[39mshots, trainable_params\u001b[38;5;241m=\u001b[39mtape\u001b[38;5;241m.\u001b[39mtrainable_params\n\u001b[1;32m     86\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/pennylane/transforms/convert_to_numpy_parameters.py:30\u001b[0m, in \u001b[0;36m_convert_op_to_numpy_data\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Use operator method to change parameters when it become available\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_new_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/functools.py:909\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    907\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 909\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/pennylane/ops/functions/bind_new_parameters.py:50\u001b[0m, in \u001b[0;36mbind_new_parameters\u001b[0;34m(op, params)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a new operator with updated parameters\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03mThis function takes an :class:`~.Operator` and new parameters as input and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m    .Operator: New operator with updated parameters\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\u001b[38;5;241m*\u001b[39mparams, wires\u001b[38;5;241m=\u001b[39m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwires\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopy\u001b[38;5;241m.\u001b[39mdeepcopy(op\u001b[38;5;241m.\u001b[39mhyperparameters))\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# operation is doing something different with its call signature.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     new_op \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(op)\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.11/site-packages/pennylane/operation.py:1376\u001b[0m, in \u001b[0;36mOperator.wires\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_batching()\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_size\n\u001b[0;32m-> 1376\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwires\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Wires:\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wires that the operator acts on.\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \n\u001b[1;32m   1380\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;124;03m        Wires: wires\u001b[39;00m\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wires\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ——— Hiperparâmetros ———\n",
    "image_size    = 5      # tamanho do “patch”\n",
    "batch_size    = 8      # tamanho do batch\n",
    "pca_dims      = 40     # dimensão final (8 geradores × 5 qubits)\n",
    "n_qubits      = 5      # número de qubits (e de features por gerador)\n",
    "q_depth       = 6      # profundidade do circuito\n",
    "n_generators  = 8      # quantos “patches” quânticos → 40 dims\n",
    "num_iter      = 500    # iterações de treino\n",
    "\n",
    "# ——— Dispositivo GPU ———\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ——— Função de escala para PCA ———\n",
    "def scale_data(data, scale=None, dtype=np.float32):\n",
    "    if scale is None:\n",
    "        scale = [-1, 1]\n",
    "    mn, mx = float(np.min(data)), float(np.max(data))\n",
    "    a, b   = float(scale[0]), float(scale[1])\n",
    "    return (((b - a) * (data - mn) / (mx - mn)) + a).astype(dtype)\n",
    "\n",
    "# ——— Pré-processamento (PCA) ———\n",
    "all_imgs   = train_dataset.imgs if hasattr(train_dataset, \"imgs\") else train_dataset.data\n",
    "flat_imgs  = all_imgs.reshape(len(all_imgs), -1)\n",
    "scaled     = scale_data(flat_imgs, [0, 1])\n",
    "pca        = PCA(n_components=pca_dims)\n",
    "pca_data   = pca.fit_transform(scaled)\n",
    "\n",
    "# mantém os dados em CPU (tensores “normais”)\n",
    "cpu_tensor_data = torch.from_numpy(scale_data(pca_data)).float()\n",
    "\n",
    "dataloader_pca = DataLoader(\n",
    "    cpu_tensor_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,   # só pin na CPU; nunca pin tensores CUDA\n",
    ")\n",
    "\n",
    "# ——— Circuito quântico ———\n",
    "dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\", diff_method=\"parameter-shift\")\n",
    "def quantum_circuit(noise, weights):\n",
    "    weights = weights.reshape(q_depth, n_qubits)\n",
    "    # codifica ruído\n",
    "    for q in range(n_qubits):\n",
    "        qml.RY(noise[q], wires=q)\n",
    "        qml.RX(noise[q], wires=q)\n",
    "    # camadas variacionais + emaranhamento\n",
    "    for layer in range(q_depth):\n",
    "        for q in range(n_qubits):\n",
    "            qml.RY(weights[layer][q], wires=q)\n",
    "        for q in range(n_qubits - 1):\n",
    "            qml.CZ(wires=[q, q + 1])\n",
    "    # retorna valor esperado de X em cada qubit\n",
    "    return [qml.expval(qml.PauliX(q)) for q in range(n_qubits)]\n",
    "\n",
    "# ——— Modelos ———\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(pca_dims,        hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim,      hidden_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 4, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class QuantumGenerator(nn.Module):\n",
    "    def __init__(self, n_generators, q_delta=1.0):\n",
    "        super().__init__()\n",
    "        # mantenha os parâmetros quânticos em CPU, pois o simulação roda em CPU\n",
    "        self.q_params = nn.ParameterList([\n",
    "            nn.Parameter(q_delta * torch.rand(q_depth, n_qubits), requires_grad=True)\n",
    "            for _ in range(n_generators)\n",
    "        ])\n",
    "        self.n_generators = n_generators\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # saída final: batch_size × (n_generators * n_qubits) = batch_size × 40\n",
    "        images = torch.zeros(batch_size, self.n_generators * n_qubits, device=device)\n",
    "\n",
    "        for gen_idx, params in enumerate(self.q_params):\n",
    "            # para cada amostra, roda o circuito (em CPU) e retorna CPU tensor\n",
    "            patches = torch.stack([\n",
    "                torch.tensor(\n",
    "                    quantum_circuit(sample.cpu(), params.cpu()),\n",
    "                    device=device\n",
    "                ).float()\n",
    "                for sample in x\n",
    "            ], dim=0)  # shape (batch_size, n_qubits)\n",
    "\n",
    "            start = gen_idx * n_qubits\n",
    "            images[:, start:start + n_qubits] = patches\n",
    "\n",
    "        return images\n",
    "\n",
    "# ——— Instâncias e Otimizadores ———\n",
    "D = Discriminator().to(device)\n",
    "G = QuantumGenerator(n_generators).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optD      = optim.SGD(D.parameters(), lr=1e-2)\n",
    "optG      = optim.SGD(G.parameters(), lr=3e-1)\n",
    "\n",
    "# ——— Loop de Treino (GPU) ———\n",
    "total_start = time.time()\n",
    "for it in range(1, num_iter + 1):\n",
    "    iter_start = time.time()\n",
    "\n",
    "    for real in dataloader_pca:\n",
    "        # real sai do DataLoader em CPU, já como pinned tensor\n",
    "        real   = real.to(device, non_blocking=True)\n",
    "        b_size = real.size(0)\n",
    "        real_lbl = torch.ones((b_size, 1), device=device)\n",
    "        fake_lbl = torch.zeros((b_size, 1), device=device)\n",
    "\n",
    "        noise = torch.rand(b_size, n_qubits, device=device) * (math.pi / 2)\n",
    "        fake  = G(noise)\n",
    "\n",
    "        # treina Discriminador\n",
    "        optD.zero_grad()\n",
    "        loss_D = criterion(D(real), real_lbl) + criterion(D(fake.detach()), fake_lbl)\n",
    "        loss_D.backward()\n",
    "        optD.step()\n",
    "\n",
    "        # treina Gerador\n",
    "        optG.zero_grad()\n",
    "        loss_G = criterion(D(fake), real_lbl)\n",
    "        loss_G.backward()\n",
    "        optG.step()\n",
    "\n",
    "    elapsed = time.time() - iter_start\n",
    "    print(f\"Iter {it}/{num_iter}: Loss D={loss_D.item():.3f}, \"\n",
    "          f\"Loss G={loss_G.item():.3f} — {elapsed:.2f}s\")\n",
    "\n",
    "    if it % 50 == 0:\n",
    "        with torch.no_grad():\n",
    "            eval_noise = torch.rand(8, n_qubits, device=device) * (math.pi / 2)\n",
    "            samples    = G(eval_noise).cpu()\n",
    "        fig, axs = plt.subplots(1, 8, figsize=(16, 2))\n",
    "        for ax, samp in zip(axs, samples):\n",
    "            ax.plot(samp.numpy())\n",
    "            ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "total_time = time.time() - total_start\n",
    "print(f\"Tempo total de treinamento: {total_time:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Treinamento separado por classe\n",
    "Treinamos dois geradores: um para imagens malignas (rótulo 0) e outro para imagens benignas (rótulo 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_quantum_gan(loader, G, D, epochs=50, device=None):\n",
    "    \"\"\"\n",
    "    Treina o Quantum GAN usando dados de PCA vindos de `loader` (CPU, pin_memory=True)\n",
    "    G e D já devem estar instanciados e enviados corretamente ao device.\n",
    "    Retorna listas de histórico de loss do Discriminador e do Gerador.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optD = optim.SGD(D.parameters(), lr=1e-2)\n",
    "    optG = optim.SGD(G.parameters(), lr=3e-1)\n",
    "    hist_D, hist_G = [], []\n",
    "\n",
    "    total_start = time.time()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start = time.time()\n",
    "        running_D, running_G = 0.0, 0.0\n",
    "\n",
    "        for real in loader:\n",
    "            # real sai do DataLoader como tensor CPU pinned\n",
    "            real = real.to(device, non_blocking=True)  # move para GPU\n",
    "            b_size = real.size(0)\n",
    "\n",
    "            # rótulos\n",
    "            real_label = torch.ones((b_size, 1), device=device)\n",
    "            fake_label = torch.zeros((b_size, 1), device=device)\n",
    "\n",
    "            # gera amostras falsas\n",
    "            noise = torch.rand(b_size, n_qubits, device=device) * (math.pi / 2)\n",
    "            fake = G(noise)\n",
    "\n",
    "            # --- Atualiza Discriminador ---\n",
    "            optD.zero_grad()\n",
    "            out_real = D(real)\n",
    "            out_fake = D(fake.detach())\n",
    "            loss_D = criterion(out_real, real_label) + criterion(out_fake, fake_label)\n",
    "            loss_D.backward()\n",
    "            optD.step()\n",
    "\n",
    "            # --- Atualiza Gerador ---\n",
    "            optG.zero_grad()\n",
    "            out_fake = D(fake)\n",
    "            loss_G = criterion(out_fake, real_label)\n",
    "            loss_G.backward()\n",
    "            optG.step()\n",
    "\n",
    "            running_D += loss_D.item()\n",
    "            running_G += loss_G.item()\n",
    "\n",
    "        # calcula médias por batch\n",
    "        hist_D.append(running_D / len(loader))\n",
    "        hist_G.append(running_G / len(loader))\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        print(f\"Epoch {epoch}/{epochs}: D={hist_D[-1]:.4f}, G={hist_G[-1]:.4f} — {epoch_time:.2f}s\")\n",
    "\n",
    "    total_time = time.time() - total_start\n",
    "    print(f\"Training completed in {total_time:.2f}s\")\n",
    "    return hist_D, hist_G\n",
    "\n",
    "# Exemplo de uso:\n",
    "# hist_D, hist_G = train_quantum_gan(dataloader_pca, G, D, epochs=50, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scale_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m labels = train_dataset.labels \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(train_dataset, \u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m train_dataset.targets\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Escala e converte o PCA já treinado (pca_data) para Tensor CPU\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m scaled_pca_np = \u001b[43mscale_data\u001b[49m(pca_data)                            \u001b[38;5;66;03m# shape (N, 40)\u001b[39;00m\n\u001b[32m      9\u001b[39m tensor_pca     = torch.from_numpy(scaled_pca_np).float()        \u001b[38;5;66;03m# Tensor CPU\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Índices para cada classe\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'scale_data' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ——— Cria DataLoaders PCA por rótulo ———\n",
    "# Extrai labels originais (pode ser .labels ou .targets)\n",
    "labels = train_dataset.labels if hasattr(train_dataset, \"labels\") else train_dataset.targets\n",
    "\n",
    "# Escala e converte o PCA já treinado (pca_data) para Tensor CPU\n",
    "scaled_pca_np = scale_data(pca_data)                            # shape (N, 40)\n",
    "tensor_pca     = torch.from_numpy(scaled_pca_np).float()        # Tensor CPU\n",
    "\n",
    "# Índices para cada classe\n",
    "idx0 = [i for i, l in enumerate(labels) if int(l) == 0]\n",
    "idx1 = [i for i, l in enumerate(labels) if int(l) == 1]\n",
    "\n",
    "# Subconjuntos PCA por rótulo\n",
    "pca0 = tensor_pca[idx0]   # amostras “malignas”\n",
    "pca1 = tensor_pca[idx1]   # amostras “benignas”\n",
    "\n",
    "# DataLoaders com pin_memory para transferir rapidamente à GPU\n",
    "loader_mal = DataLoader(pca0, batch_size=batch_size, shuffle=True,  drop_last=True, pin_memory=True)\n",
    "loader_ben = DataLoader(pca1, batch_size=batch_size, shuffle=True,  drop_last=True, pin_memory=True)\n",
    "\n",
    "# ——— Treina dois QGANs, um para cada classe ———\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Maligno (label 0)\n",
    "G_mal = QuantumGenerator(n_generators).to(device)\n",
    "D_mal = Discriminator().to(device)\n",
    "hist_D_mal, hist_G_mal = train_quantum_gan(loader_mal, G_mal, D_mal, epochs=50, device=device)\n",
    "\n",
    "# Benigno (label 1)\n",
    "G_ben = QuantumGenerator(n_generators).to(device)\n",
    "D_ben = Discriminator().to(device)\n",
    "hist_D_ben, hist_G_ben = train_quantum_gan(loader_ben, G_ben, D_ben, epochs=50, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curvas de Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# use “hist” porque é assim que você nomeou as listas retornadas\n",
    "epochs = list(range(1, len(hist_D_mal) + 1))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, hist_D_mal, label='D Loss Malignant',     linewidth=2)\n",
    "plt.plot(epochs, hist_G_mal, label='G Loss Malignant',     linewidth=2)\n",
    "plt.plot(epochs, hist_D_ben, label='D Loss Benign',  linestyle='--', linewidth=2)\n",
    "plt.plot(epochs, hist_G_ben, label='G Loss Benign',  linestyle='--', linewidth=2)\n",
    "\n",
    "plt.title('Quantum GAN Losses por Época')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, linestyle=':')\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Avaliação\n",
    "Utilize as mesmas métricas (FID e IS) para comparar as imagens geradas pela abordagem quântica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAN</th>\n",
       "      <th>Generator_Label</th>\n",
       "      <th>Real_Label</th>\n",
       "      <th>FID</th>\n",
       "      <th>IS_Mean</th>\n",
       "      <th>IS_Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QuantumGAN</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>6.255424</td>\n",
       "      <td>1.259082</td>\n",
       "      <td>0.091074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QuantumGAN</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>7.000401</td>\n",
       "      <td>1.380240</td>\n",
       "      <td>0.140491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GAN Generator_Label Real_Label       FID   IS_Mean    IS_Std\n",
       "0  QuantumGAN       Malignant  Malignant  6.255424  1.259082  0.091074\n",
       "1  QuantumGAN          Benign     Benign  7.000401  1.380240  0.140491"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_gan(\n",
    "    G,\n",
    "    label_target: int,\n",
    "    gan_name: str,\n",
    "    gen_label_name: str,\n",
    "    test_dataset,\n",
    "    n_qubits: int,\n",
    "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    max_batches: float = float('inf')\n",
    "):\n",
    "    \"\"\"\n",
    "    Avalia um gerador GAN usando FID e Inception Score.\n",
    "    \n",
    "    Correções aplicadas:\n",
    "      - usa normalize=True tanto em FID quanto em InceptionScore, para aceitar tensores float em [0,1].\n",
    "      - converte imagens grayscale (1 canal) em RGB (3 canais).\n",
    "      - redimensiona tudo para 299×299 (requisito do InceptionV3).\n",
    "    \"\"\"\n",
    "    loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    # normalize=True: aceita floats em [0,1] e faz o cast interno para uint8\n",
    "    fid = FrechetInceptionDistance(feature=64, normalize=True).to(device)\n",
    "    is_metric = InceptionScore(normalize=True).to(device)\n",
    "    \n",
    "    G = G.to(device)\n",
    "    G.eval()\n",
    "    \n",
    "    count = 0\n",
    "    for real, labels in loader:\n",
    "        mask = (labels.squeeze() == label_target)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        # real: [B,1,H,W], floats em [0,1]\n",
    "        real = real[mask].to(device)\n",
    "        real = real.repeat(1, 3, 1, 1)  # -> [B,3,H,W]\n",
    "        real = F.interpolate(real, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        b_size = real.size(0)\n",
    "        noise = torch.rand(b_size, n_qubits, device=device) * (torch.pi / 2)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            fake = G(noise)  # supõe saída [B,1,H,W], floats em [0,1]\n",
    "        fake = fake.to(device)\n",
    "        fake = fake.repeat(1, 3, 1, 1)  # -> [B,3,H,W]\n",
    "        fake = F.interpolate(fake, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # atualiza métricas com floats em [0,1]\n",
    "        fid.update(real, real=True)\n",
    "        fid.update(fake, real=False)\n",
    "        is_metric.update(fake)\n",
    "        \n",
    "        count += 1\n",
    "        if count >= max_batches:\n",
    "            break\n",
    "    \n",
    "    fid_score = fid.compute().item()\n",
    "    is_mean, is_std = is_metric.compute()\n",
    "    \n",
    "    return {\n",
    "        'GAN': gan_name,\n",
    "        'Generator_Label': gen_label_name,\n",
    "        'Real_Label': 'Malignant' if label_target == 0 else 'Benign',\n",
    "        'FID': fid_score,\n",
    "        'IS_Mean': is_mean.item(),\n",
    "        'IS_Std': is_std.item()\n",
    "    }\n",
    "\n",
    "# Exemplo de uso:\n",
    "results = []\n",
    "results.append(evaluate_gan(G_mal, 0, 'QuantumGAN', 'Malignant', test_dataset, n_qubits))\n",
    "results.append(evaluate_gan(G_ben, 1, 'QuantumGAN', 'Benign',   test_dataset, n_qubits))\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação com ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, ConcatDataset, random_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    xs, ys = zip(*batch)\n",
    "    xs = torch.stack(xs, dim=0)\n",
    "    ys_list = []\n",
    "    for y in ys:\n",
    "        if isinstance(y, torch.Tensor):\n",
    "            val = y.item() if y.numel() == 1 else int(y.argmax().item())\n",
    "        else:\n",
    "            val = int(y)\n",
    "        ys_list.append(val)\n",
    "    ys = torch.tensor(ys_list, dtype=torch.long)\n",
    "    return xs, ys\n",
    "\n",
    "class SyntheticDataset(Dataset):\n",
    "    def __init__(self, generator_dict, num_per_class, latent_dim, device=None):\n",
    "        self.samples = []\n",
    "        device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        for label_name, gen in generator_dict.items():\n",
    "            label = 0 if label_name == 'malignant' else 1\n",
    "            noise = torch.rand(num_per_class, n_qubits, device=device) * torch.pi/2\n",
    "            with torch.no_grad():\n",
    "                imgs = gen(noise).cpu()\n",
    "            for img in imgs:\n",
    "                self.samples.append((img, label))\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "def train_model(model, loader, epochs=5, device=None):\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    for _ in range(epochs):\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def evaluate(model, loader, device=None):\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            out = model(x)\n",
    "            preds = out.argmax(dim=1).cpu()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(y)\n",
    "    y_true = torch.cat(all_labels).numpy()\n",
    "    y_pred = torch.cat(all_preds).numpy()\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return acc, prec, rec, f1, auc, tn, fp, fn, tp\n",
    "\n",
    "def run_experiments(train_dataset, test_dataset, G_dict, batch_size=32, epochs=5, device=None):\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    latent_dim = n_qubits\n",
    "    ratios = [0.0, 0.25, 0.5, 0.75, 1.0, 1.5]\n",
    "    results = []\n",
    "    for r in ratios:\n",
    "        if r == 0.0:\n",
    "            ds = train_dataset\n",
    "        else:\n",
    "            num_syn = int(len(train_dataset) * r)\n",
    "            syn_ds = SyntheticDataset(G_dict, num_syn // 2, latent_dim, device)\n",
    "            ds = ConcatDataset([train_dataset, syn_ds])\n",
    "        loader = DataLoader(ds, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "        model = resnet18(num_classes=2)\n",
    "        model.conv1 = nn.Conv2d(1, 64, 7, 2, 3, bias=False)\n",
    "        train_model(model, loader, epochs=epochs, device=device)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "        acc, prec, rec, f1, auc, tn, fp, fn, tp = evaluate(model, test_loader, device=device)\n",
    "        results.append({'ratio': r,'acc': acc,'prec': prec,'rec': rec,'f1': f1,'auc': auc,'tn': tn,'fp': fp,'fn': fn,'tp': tp})\n",
    "    syn_only_ds = SyntheticDataset(G_dict, len(train_dataset)//2, latent_dim, device)\n",
    "    syn_loader = DataLoader(syn_only_ds, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "    model = resnet18(num_classes=2)\n",
    "    model.conv1 = nn.Conv2d(1, 64, 7, 2, 3, bias=False)\n",
    "    train_model(model, syn_loader, epochs=epochs, device=device)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "    acc, prec, rec, f1, auc, tn, fp, fn, tp = evaluate(model, test_loader, device=device)\n",
    "    results.append({'ratio':'100%_sintético→real','acc':acc,'prec':prec,'rec':rec,'f1':f1,'auc':auc,'tn':tn,'fp':fp,'fn':fn,'tp':tp})\n",
    "    total_syn = len(syn_only_ds)\n",
    "    n_train = int(total_syn * 0.7)\n",
    "    n_test = total_syn - n_train\n",
    "    syn_train_ds, syn_test_ds = random_split(syn_only_ds, [n_train, n_test])\n",
    "    train_loader = DataLoader(syn_train_ds, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "    test_loader = DataLoader(syn_test_ds, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "    model = resnet18(num_classes=2)\n",
    "    model.conv1 = nn.Conv2d(1, 64, 7, 2, 3, bias=False)\n",
    "    train_model(model, train_loader, epochs=epochs, device=device)\n",
    "    acc, prec, rec, f1, auc, tn, fp, fn, tp = evaluate(model, test_loader, device=device)\n",
    "    results.append({'ratio':'100%_sintético_70/30_selftest','acc':acc,'prec':prec,'rec':rec,'f1':f1,'auc':auc,'tn':tn,'fp':fp,'fn':fn,'tp':tp})\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60846/1243825210.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n",
      "/tmp/ipykernel_60846/1243825210.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n",
      "/tmp/ipykernel_60846/1243825210.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n",
      "/tmp/ipykernel_60846/1243825210.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n",
      "/tmp/ipykernel_60846/1243825210.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n",
      "/tmp/ipykernel_60846/1243825210.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n",
      "/tmp/ipykernel_60846/1243825210.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratio</th>\n",
       "      <th>acc</th>\n",
       "      <th>prec</th>\n",
       "      <th>rec</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.791353</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.879310</td>\n",
       "      <td>0.756892</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.823077</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.877049</td>\n",
       "      <td>0.695489</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.839744</td>\n",
       "      <td>0.850394</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.896266</td>\n",
       "      <td>0.747494</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.801282</td>\n",
       "      <td>0.867257</td>\n",
       "      <td>0.859649</td>\n",
       "      <td>0.863436</td>\n",
       "      <td>0.751253</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.776942</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100%_sintético→real</td>\n",
       "      <td>0.698718</td>\n",
       "      <td>0.727891</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.819923</td>\n",
       "      <td>0.493108</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100%_sintético_70/30_selftest</td>\n",
       "      <td>0.993902</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>0.994318</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ratio       acc      prec       rec        f1  \\\n",
       "0                            0.0  0.826923  0.891892  0.868421  0.880000   \n",
       "1                           0.25  0.820513  0.864407  0.894737  0.879310   \n",
       "2                            0.5  0.807692  0.823077  0.938596  0.877049   \n",
       "3                           0.75  0.839744  0.850394  0.947368  0.896266   \n",
       "4                            1.0  0.801282  0.867257  0.859649  0.863436   \n",
       "5                            1.5  0.717949  0.948718  0.649123  0.770833   \n",
       "6            100%_sintético→real  0.698718  0.727891  0.938596  0.819923   \n",
       "7  100%_sintético_70/30_selftest  0.993902  0.987013  1.000000  0.993464   \n",
       "\n",
       "        auc  tn  fp  fn   tp  \n",
       "0  0.791353  30  12  15   99  \n",
       "1  0.756892  26  16  12  102  \n",
       "2  0.695489  19  23   7  107  \n",
       "3  0.747494  23  19   6  108  \n",
       "4  0.751253  27  15  16   98  \n",
       "5  0.776942  38   4  40   74  \n",
       "6  0.493108   2  40   7  107  \n",
       "7  0.994318  87   1   0   76  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_dict = {'malignant': G_mal, 'benign': G_ben}\n",
    "classification_results = run_experiments(train_dataset, test_dataset, G_dict, batch_size=64, epochs=5)\n",
    "classification_results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

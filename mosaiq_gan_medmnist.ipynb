{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum GAN com Pennylane e MedMNIST\n",
    "\n",
    "Este notebook apresenta uma implementação simplificada de uma GAN quântica inspirada no método de *patches* descrito por Huang et al. Utilizamos o dataset **MedMNIST** para comparação com os modelos clássicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Quântico\n",
    "Instalação de `pennylane` e demais bibliotecas necessárias para execução do modelo híbrido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pennylane pennylane-lightning torch medmnist matplotlib --quiet\n",
    "import torch\n",
    "import pennylane as qml\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import medmnist\n",
    "from medmnist import INFO\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparação do Dataset\n",
    "Utilizamos o mesmo subset do notebook clássico para permitir comparação direta. Pode ser necessário reduzir a resolução das imagens para se adequar ao número de qubits disponíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 560k/560k [00:00<00:00, 1.21MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Seleciona o dataset\n",
    "DATA_FLAG = 'breastmnist'\n",
    "info = INFO[DATA_FLAG]\n",
    "download = True\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    #transforms.Resize((8, 8)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "\n",
    "# Carrega treino e teste\n",
    "train_dataset = getattr(medmnist, info['python_class'])(split='train', transform=transform, download=download)\n",
    "test_dataset = getattr(medmnist, info['python_class'])(split='test', transform=transform, download=download)\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset BreastMNIST of size 28 (breastmnist)\n",
      "    Number of datapoints: 546\n",
      "    Root location: /root/.medmnist\n",
      "    Split: train\n",
      "    Task: binary-class\n",
      "    Number of channels: 1\n",
      "    Meaning of labels: {'0': 'malignant', '1': 'normal, benign'}\n",
      "    Number of samples: {'train': 546, 'val': 78, 'test': 156}\n",
      "    Description: The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.\n",
      "    License: CC BY 4.0\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Treinamento\n",
    "Configuração de modelos e funções para treinamento separado por classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ——— Hiperparâmetros ———\n",
    "image_size    = 5      # tamanho do “patch”\n",
    "batch_size    = 8      # tamanho do batch\n",
    "pca_dims      = 40     # dimensão final (8 geradores × 5 qubits)\n",
    "n_qubits      = 5      # número de qubits (e de features por gerador)\n",
    "q_depth       = 6      # profundidade do circuito\n",
    "n_generators  = 8      # quantos “patches” quânticos → 40 dims\n",
    "\n",
    "# ——— Dispositivo GPU ———\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ——— Função de escala para PCA ———\n",
    "def scale_data(data, scale=None, dtype=np.float32):\n",
    "    if scale is None:\n",
    "        scale = [-1, 1]\n",
    "    mn, mx = float(np.min(data)), float(np.max(data))\n",
    "    a, b   = float(scale[0]), float(scale[1])\n",
    "    return (((b - a) * (data - mn) / (mx - mn)) + a).astype(dtype)\n",
    "\n",
    "# ——— Pré-processamento (PCA) ———\n",
    "all_imgs   = train_dataset.imgs if hasattr(train_dataset, \"imgs\") else train_dataset.data\n",
    "flat_imgs  = all_imgs.reshape(len(all_imgs), -1)\n",
    "scaled     = scale_data(flat_imgs, [0, 1])\n",
    "pca        = PCA(n_components=pca_dims)\n",
    "pca_data   = pca.fit_transform(scaled)\n",
    "\n",
    "# ——— Circuito quântico ———\n",
    "dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\", diff_method=\"parameter-shift\")\n",
    "def quantum_circuit(noise, weights):\n",
    "    weights = weights.reshape(q_depth, n_qubits)\n",
    "    # codifica ruído\n",
    "    for q in range(n_qubits):\n",
    "        qml.RY(noise[q], wires=q)\n",
    "        qml.RX(noise[q], wires=q)\n",
    "    # camadas variacionais + emaranhamento\n",
    "    for layer in range(q_depth):\n",
    "        for q in range(n_qubits):\n",
    "            qml.RY(weights[layer][q], wires=q)\n",
    "        for q in range(n_qubits - 1):\n",
    "            qml.CZ(wires=[q, q + 1])\n",
    "    # retorna valor esperado de X em cada qubit\n",
    "    return [qml.expval(qml.PauliX(q)) for q in range(n_qubits)]\n",
    "\n",
    "# ——— Modelos ———\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(pca_dims,        hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim,      hidden_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 4, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class QuantumGenerator(nn.Module):\n",
    "    def __init__(self, n_generators, q_delta=1.0):\n",
    "        super().__init__()\n",
    "        # mantenha os parâmetros quânticos em CPU, pois o simulação roda em CPU\n",
    "        self.q_params = nn.ParameterList([\n",
    "            nn.Parameter(q_delta * torch.rand(q_depth, n_qubits), requires_grad=True)\n",
    "            for _ in range(n_generators)\n",
    "        ])\n",
    "        self.n_generators = n_generators\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # saída final: batch_size × (n_generators * n_qubits) = batch_size × 40\n",
    "        images = torch.zeros(batch_size, self.n_generators * n_qubits, device=device)\n",
    "\n",
    "        for gen_idx, params in enumerate(self.q_params):\n",
    "            # para cada amostra, roda o circuito (em CPU) e retorna CPU tensor\n",
    "            patches = torch.stack([\n",
    "                torch.tensor(\n",
    "                    quantum_circuit(sample.cpu(), params.cpu()),\n",
    "                    device=device\n",
    "                ).float()\n",
    "                for sample in x\n",
    "            ], dim=0)  # shape (batch_size, n_qubits)\n",
    "\n",
    "            start = gen_idx * n_qubits\n",
    "            images[:, start:start + n_qubits] = patches\n",
    "\n",
    "        return images\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Treinamento separado por classe\n",
    "Treinamos dois geradores: um para imagens malignas (rótulo 0) e outro para imagens benignas (rótulo 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_quantum_gan(loader, G, D, epochs=50, device=None):\n",
    "    \"\"\"\n",
    "    Treina o Quantum GAN usando dados de PCA vindos de `loader` (CPU, pin_memory=True)\n",
    "    G e D já devem estar instanciados e enviados corretamente ao device.\n",
    "    Retorna listas de histórico de loss do Discriminador e do Gerador.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optD = optim.SGD(D.parameters(), lr=1e-2)\n",
    "    optG = optim.SGD(G.parameters(), lr=3e-1)\n",
    "    hist_D, hist_G = [], []\n",
    "\n",
    "    total_start = time.time()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start = time.time()\n",
    "        running_D, running_G = 0.0, 0.0\n",
    "\n",
    "        for real in loader:\n",
    "            # real sai do DataLoader como tensor CPU pinned\n",
    "            real = real.to(device, non_blocking=True)  # move para GPU\n",
    "            b_size = real.size(0)\n",
    "\n",
    "            # rótulos\n",
    "            real_label = torch.ones((b_size, 1), device=device)\n",
    "            fake_label = torch.zeros((b_size, 1), device=device)\n",
    "\n",
    "            # gera amostras falsas\n",
    "            noise = torch.rand(b_size, n_qubits, device=device) * (math.pi / 2)\n",
    "            fake = G(noise)\n",
    "\n",
    "            # --- Atualiza Discriminador ---\n",
    "            optD.zero_grad()\n",
    "            out_real = D(real)\n",
    "            out_fake = D(fake.detach())\n",
    "            loss_D = criterion(out_real, real_label) + criterion(out_fake, fake_label)\n",
    "            loss_D.backward()\n",
    "            optD.step()\n",
    "\n",
    "            # --- Atualiza Gerador ---\n",
    "            optG.zero_grad()\n",
    "            out_fake = D(fake)\n",
    "            loss_G = criterion(out_fake, real_label)\n",
    "            loss_G.backward()\n",
    "            optG.step()\n",
    "\n",
    "            running_D += loss_D.item()\n",
    "            running_G += loss_G.item()\n",
    "\n",
    "        # calcula médias por batch\n",
    "        hist_D.append(running_D / len(loader))\n",
    "        hist_G.append(running_G / len(loader))\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        print(f\"Epoch {epoch}/{epochs}: D={hist_D[-1]:.4f}, G={hist_G[-1]:.4f} — {epoch_time:.2f}s\")\n",
    "\n",
    "    total_time = time.time() - total_start\n",
    "    print(f\"Training completed in {total_time:.2f}s\")\n",
    "    return hist_D, hist_G\n",
    "\n",
    "# Exemplo de uso:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ——— Cria DataLoaders PCA por rótulo ———\n",
    "# Extrai labels originais (pode ser .labels ou .targets)\n",
    "labels = train_dataset.labels if hasattr(train_dataset, \"labels\") else train_dataset.targets\n",
    "\n",
    "# Escala e converte o PCA já treinado (pca_data) para Tensor CPU\n",
    "scaled_pca_np = scale_data(pca_data)                            # shape (N, 40)\n",
    "tensor_pca     = torch.from_numpy(scaled_pca_np).float()        # Tensor CPU\n",
    "\n",
    "# Índices para cada classe\n",
    "idx0 = [i for i, l in enumerate(labels) if int(l) == 0]\n",
    "idx1 = [i for i, l in enumerate(labels) if int(l) == 1]\n",
    "\n",
    "# Subconjuntos PCA por rótulo\n",
    "pca0 = tensor_pca[idx0]   # amostras “malignas”\n",
    "pca1 = tensor_pca[idx1]   # amostras “benignas”\n",
    "\n",
    "# DataLoaders com pin_memory para transferir rapidamente à GPU\n",
    "loader_mal = DataLoader(pca0, batch_size=batch_size, shuffle=True,  drop_last=True, pin_memory=True)\n",
    "loader_ben = DataLoader(pca1, batch_size=batch_size, shuffle=True,  drop_last=True, pin_memory=True)\n",
    "\n",
    "# ——— Treina dois QGANs, um para cada classe ———\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Maligno (label 0)\n",
    "G_mal = QuantumGenerator(n_generators).to(device)\n",
    "D_mal = Discriminator().to(device)\n",
    "hist_D_mal, hist_G_mal = train_quantum_gan(loader_mal, G_mal, D_mal, epochs=50, device=device)\n",
    "\n",
    "# Benigno (label 1)\n",
    "G_ben = QuantumGenerator(n_generators).to(device)\n",
    "D_ben = Discriminator().to(device)\n",
    "hist_D_ben, hist_G_ben = train_quantum_gan(loader_ben, G_ben, D_ben, epochs=50, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curvas de Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# use “hist” porque é assim que você nomeou as listas retornadas\n",
    "epochs = list(range(1, len(hist_D_mal) + 1))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, hist_D_mal, label='D Loss Malignant',     linewidth=2)\n",
    "plt.plot(epochs, hist_G_mal, label='G Loss Malignant',     linewidth=2)\n",
    "plt.plot(epochs, hist_D_ben, label='D Loss Benign',  linestyle='--', linewidth=2)\n",
    "plt.plot(epochs, hist_G_ben, label='G Loss Benign',  linestyle='--', linewidth=2)\n",
    "\n",
    "plt.title('Quantum GAN Losses por Época')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, linestyle=':')\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Avaliação\n",
    "Utilize as mesmas métricas (FID e IS) para comparar as imagens geradas pela abordagem quântica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAN</th>\n",
       "      <th>Generator_Label</th>\n",
       "      <th>Real_Label</th>\n",
       "      <th>FID</th>\n",
       "      <th>IS_Mean</th>\n",
       "      <th>IS_Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QuantumGAN</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>6.255424</td>\n",
       "      <td>1.259082</td>\n",
       "      <td>0.091074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QuantumGAN</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>7.000401</td>\n",
       "      <td>1.380240</td>\n",
       "      <td>0.140491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GAN Generator_Label Real_Label       FID   IS_Mean    IS_Std\n",
       "0  QuantumGAN       Malignant  Malignant  6.255424  1.259082  0.091074\n",
       "1  QuantumGAN          Benign     Benign  7.000401  1.380240  0.140491"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_gan(\n",
    "    G,\n",
    "    label_target: int,\n",
    "    gan_name: str,\n",
    "    gen_label_name: str,\n",
    "    test_dataset,\n",
    "    n_qubits: int,\n",
    "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    max_batches: float = float('inf')\n",
    "):\n",
    "    \"\"\"\n",
    "    Avalia um gerador GAN usando FID e Inception Score.\n",
    "    \n",
    "    Correções aplicadas:\n",
    "      - usa normalize=True tanto em FID quanto em InceptionScore, para aceitar tensores float em [0,1].\n",
    "      - converte imagens grayscale (1 canal) em RGB (3 canais).\n",
    "      - redimensiona tudo para 299×299 (requisito do InceptionV3).\n",
    "    \"\"\"\n",
    "    loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    # normalize=True: aceita floats em [0,1] e faz o cast interno para uint8\n",
    "    fid = FrechetInceptionDistance(feature=64, normalize=True).to(device)\n",
    "    is_metric = InceptionScore(normalize=True).to(device)\n",
    "    \n",
    "    G = G.to(device)\n",
    "    G.eval()\n",
    "    \n",
    "    count = 0\n",
    "    for real, labels in loader:\n",
    "        mask = (labels.squeeze() == label_target)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        # real: [B,1,H,W], floats em [0,1]\n",
    "        real = real[mask].to(device)\n",
    "        real = real.repeat(1, 3, 1, 1)  # -> [B,3,H,W]\n",
    "        real = F.interpolate(real, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        b_size = real.size(0)\n",
    "        noise = torch.rand(b_size, n_qubits, device=device) * (torch.pi / 2)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            fake = G(noise)  # supõe saída [B,1,H,W], floats em [0,1]\n",
    "        fake = fake.to(device)\n",
    "        fake = fake.repeat(1, 3, 1, 1)  # -> [B,3,H,W]\n",
    "        fake = F.interpolate(fake, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # atualiza métricas com floats em [0,1]\n",
    "        fid.update(real, real=True)\n",
    "        fid.update(fake, real=False)\n",
    "        is_metric.update(fake)\n",
    "        \n",
    "        count += 1\n",
    "        if count >= max_batches:\n",
    "            break\n",
    "    \n",
    "    fid_score = fid.compute().item()\n",
    "    is_mean, is_std = is_metric.compute()\n",
    "    \n",
    "    return {\n",
    "        'GAN': gan_name,\n",
    "        'Generator_Label': gen_label_name,\n",
    "        'Real_Label': 'Malignant' if label_target == 0 else 'Benign',\n",
    "        'FID': fid_score,\n",
    "        'IS_Mean': is_mean.item(),\n",
    "        'IS_Std': is_std.item()\n",
    "    }\n",
    "\n",
    "# Exemplo de uso:\n",
    "results = []\n",
    "results.append(evaluate_gan(G_mal, 0, 'QuantumGAN', 'Malignant', test_dataset, n_qubits))\n",
    "results.append(evaluate_gan(G_ben, 1, 'QuantumGAN', 'Benign',   test_dataset, n_qubits))\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação com ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, ConcatDataset, random_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    xs, ys = zip(*batch)\n",
    "    xs = torch.stack(xs, dim=0)\n",
    "    ys_list = []\n",
    "    for y in ys:\n",
    "        if isinstance(y, torch.Tensor):\n",
    "            val = y.item() if y.numel() == 1 else int(y.argmax().item())\n",
    "        else:\n",
    "            val = int(y)\n",
    "        ys_list.append(val)\n",
    "    ys = torch.tensor(ys_list, dtype=torch.long)\n",
    "    return xs, ys\n",
    "\n",
    "class SyntheticDataset(Dataset):\n",
    "    def __init__(self, generator_dict, num_per_class, latent_dim, device=None):\n",
    "        self.samples = []\n",
    "        device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        for label_name, gen in generator_dict.items():\n",
    "            label = 0 if label_name == 'malignant' else 1\n",
    "            noise = torch.rand(num_per_class, n_qubits, device=device) * torch.pi/2\n",
    "            with torch.no_grad():\n",
    "                imgs = gen(noise).cpu()\n",
    "            for img in imgs:\n",
    "                self.samples.append((img, label))\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "def train_model(model, loader, epochs=5, device=None):\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    for _ in range(epochs):\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def evaluate(model, loader, device=None):\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            out = model(x)\n",
    "            preds = out.argmax(dim=1).cpu()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(y)\n",
    "    y_true = torch.cat(all_labels).numpy()\n",
    "    y_pred = torch.cat(all_preds).numpy()\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return acc, prec, rec, f1, auc, tn, fp, fn, tp\n",
    "\n",
    "def run_experiments(train_dataset, test_dataset, G_dict, batch_size=32, epochs=5, device=None):\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    latent_dim = n_qubits\n",
    "    ratios = [0.0, 0.25, 0.5, 0.75, 1.0, 1.5]\n",
    "    results = []\n",
    "    for r in ratios:\n",
    "        if r == 0.0:\n",
    "            ds = train_dataset\n",
    "        else:\n",
    "            num_syn = int(len(train_dataset) * r)\n",
    "            syn_ds = SyntheticDataset(G_dict, num_syn // 2, latent_dim, device)\n",
    "            ds = ConcatDataset([train_dataset, syn_ds])\n",
    "        loader = DataLoader(ds, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "        model = resnet18(num_classes=2)\n",
    "        model.conv1 = nn.Conv2d(1, 64, 7, 2, 3, bias=False)\n",
    "        train_model(model, loader, epochs=epochs, device=device)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "        acc, prec, rec, f1, auc, tn, fp, fn, tp = evaluate(model, test_loader, device=device)\n",
    "        results.append({'ratio': r,'acc': acc,'prec': prec,'rec': rec,'f1': f1,'auc': auc,'tn': tn,'fp': fp,'fn': fn,'tp': tp})\n",
    "    syn_only_ds = SyntheticDataset(G_dict, len(train_dataset)//2, latent_dim, device)\n",
    "    syn_loader = DataLoader(syn_only_ds, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "    model = resnet18(num_classes=2)\n",
    "    model.conv1 = nn.Conv2d(1, 64, 7, 2, 3, bias=False)\n",
    "    train_model(model, syn_loader, epochs=epochs, device=device)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "    acc, prec, rec, f1, auc, tn, fp, fn, tp = evaluate(model, test_loader, device=device)\n",
    "    results.append({'ratio':'100%_sintético→real','acc':acc,'prec':prec,'rec':rec,'f1':f1,'auc':auc,'tn':tn,'fp':fp,'fn':fn,'tp':tp})\n",
    "    total_syn = len(syn_only_ds)\n",
    "    n_train = int(total_syn * 0.7)\n",
    "    n_test = total_syn - n_train\n",
    "    syn_train_ds, syn_test_ds = random_split(syn_only_ds, [n_train, n_test])\n",
    "    train_loader = DataLoader(syn_train_ds, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "    test_loader = DataLoader(syn_test_ds, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "    model = resnet18(num_classes=2)\n",
    "    model.conv1 = nn.Conv2d(1, 64, 7, 2, 3, bias=False)\n",
    "    train_model(model, train_loader, epochs=epochs, device=device)\n",
    "    acc, prec, rec, f1, auc, tn, fp, fn, tp = evaluate(model, test_loader, device=device)\n",
    "    results.append({'ratio':'100%_sintético_70/30_selftest','acc':acc,'prec':prec,'rec':rec,'f1':f1,'auc':auc,'tn':tn,'fp':fp,'fn':fn,'tp':tp})\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60846/1243825210.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n",
      "/tmp/ipykernel_60846/1243825210.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n",
      "/tmp/ipykernel_60846/1243825210.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n",
      "/tmp/ipykernel_60846/1243825210.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n",
      "/tmp/ipykernel_60846/1243825210.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n",
      "/tmp/ipykernel_60846/1243825210.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n",
      "/tmp/ipykernel_60846/1243825210.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  val = int(y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratio</th>\n",
       "      <th>acc</th>\n",
       "      <th>prec</th>\n",
       "      <th>rec</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.791353</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.879310</td>\n",
       "      <td>0.756892</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.823077</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.877049</td>\n",
       "      <td>0.695489</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.839744</td>\n",
       "      <td>0.850394</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.896266</td>\n",
       "      <td>0.747494</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.801282</td>\n",
       "      <td>0.867257</td>\n",
       "      <td>0.859649</td>\n",
       "      <td>0.863436</td>\n",
       "      <td>0.751253</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.776942</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100%_sintético→real</td>\n",
       "      <td>0.698718</td>\n",
       "      <td>0.727891</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.819923</td>\n",
       "      <td>0.493108</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100%_sintético_70/30_selftest</td>\n",
       "      <td>0.993902</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>0.994318</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ratio       acc      prec       rec        f1  \\\n",
       "0                            0.0  0.826923  0.891892  0.868421  0.880000   \n",
       "1                           0.25  0.820513  0.864407  0.894737  0.879310   \n",
       "2                            0.5  0.807692  0.823077  0.938596  0.877049   \n",
       "3                           0.75  0.839744  0.850394  0.947368  0.896266   \n",
       "4                            1.0  0.801282  0.867257  0.859649  0.863436   \n",
       "5                            1.5  0.717949  0.948718  0.649123  0.770833   \n",
       "6            100%_sintético→real  0.698718  0.727891  0.938596  0.819923   \n",
       "7  100%_sintético_70/30_selftest  0.993902  0.987013  1.000000  0.993464   \n",
       "\n",
       "        auc  tn  fp  fn   tp  \n",
       "0  0.791353  30  12  15   99  \n",
       "1  0.756892  26  16  12  102  \n",
       "2  0.695489  19  23   7  107  \n",
       "3  0.747494  23  19   6  108  \n",
       "4  0.751253  27  15  16   98  \n",
       "5  0.776942  38   4  40   74  \n",
       "6  0.493108   2  40   7  107  \n",
       "7  0.994318  87   1   0   76  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_dict = {'malignant': G_mal, 'benign': G_ben}\n",
    "classification_results = run_experiments(train_dataset, test_dataset, G_dict, batch_size=64, epochs=5)\n",
    "classification_results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
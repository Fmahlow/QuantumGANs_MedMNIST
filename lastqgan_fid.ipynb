{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6172c40",
   "metadata": {},
   "source": [
    "# FID e Inception Score da LaSt-QGAN\n",
    "\n",
    "Este notebook replica a metodologia de avaliação usada em `gans_classical_fid_is.ipynb`, mas agora aplicada à arquitetura LaSt-QGAN localizada na pasta `LaSt-QGAN-main`. Treinamos e avaliamos a LaSt-QGAN no MNIST, repetindo múltiplas execuções com sementes controladas e calculando FID e Inception Score em cada rodada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6d3ad5c-c963-4312-994a-bf7fd092a8bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightning\n",
      "  Downloading lightning-2.5.6-py3-none-any.whl.metadata (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m435.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML<8.0,>5.4 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from lightning) (6.0.1)\n",
      "Requirement already satisfied: fsspec<2027.0,>=2022.5.0 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (2024.3.1)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from lightning) (0.11.2)\n",
      "Requirement already satisfied: packaging<27.0,>=20.0 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from lightning) (24.0)\n",
      "Requirement already satisfied: torch<4.0,>=2.1.0 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from lightning) (2.2.1)\n",
      "Requirement already satisfied: torchmetrics<3.0,>0.7.0 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from lightning) (1.3.2)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from lightning) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<6.0,>4.5.0 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from lightning) (4.10.0)\n",
      "Requirement already satisfied: pytorch-lightning in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from lightning) (1.9.4)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (3.9.3)\n",
      "Requirement already satisfied: setuptools in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (68.2.2)\n",
      "Requirement already satisfied: filelock in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from torch<4.0,>=2.1.0->lightning) (3.13.1)\n",
      "Requirement already satisfied: sympy in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from torch<4.0,>=2.1.0->lightning) (1.12)\n",
      "Requirement already satisfied: networkx in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from torch<4.0,>=2.1.0->lightning) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from torch<4.0,>=2.1.0->lightning) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from torch<4.0,>=2.1.0->lightning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from torch<4.0,>=2.1.0->lightning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from torch<4.0,>=2.1.0->lightning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from torch<4.0,>=2.1.0->lightning) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from torch<4.0,>=2.1.0->lightning) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from torch<4.0,>=2.1.0->lightning) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from torch<4.0,>=2.1.0->lightning) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from torch<4.0,>=2.1.0->lightning) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from torch<4.0,>=2.1.0->lightning) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from torch<4.0,>=2.1.0->lightning) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from torch<4.0,>=2.1.0->lightning) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from torch<4.0,>=2.1.0->lightning) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<4.0,>=2.1.0->lightning) (12.4.99)\n",
      "Requirement already satisfied: numpy>1.20.0 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from torchmetrics<3.0,>0.7.0->lightning) (1.26.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from sympy->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (3.6)\n",
      "Downloading lightning-2.5.6-py3-none-any.whl (827 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m827.9/827.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lightning\n",
      "Successfully installed lightning-2.5.6\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install lightning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5314b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "\n",
    "# Garantir que possamos importar os módulos da LaSt-QGAN\n",
    "PROJECT_ROOT = os.path.abspath('LaSt-QGAN-main')\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "from utils import (\n",
    "    DigitsDataset,\n",
    "    GANModule,\n",
    "    AutoencoderModule,\n",
    "    build_model_from_config,\n",
    "    parse_config,\n",
    "    seed_everything,\n",
    ")\n",
    "#from train_qgan import QuantumGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea4ba796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "# Hiperparâmetros e caminhos\n",
    "MNIST_CSV = os.path.join(PROJECT_ROOT, 'mnist.csv')\n",
    "GAN_CONFIG_PATH = os.path.join(PROJECT_ROOT, 'gan.yaml')\n",
    "AUTOENCODER_CONFIG_PATH = os.path.join(PROJECT_ROOT, 'autoencoder.yaml')\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "LATENT_DIM = 6  # número de rotações usado pelo gerador quântico\n",
    "NUM_EPOCHS = 50\n",
    "NUM_TRAINING_RUNS = 3\n",
    "NUM_EVAL_REPEATS = 3\n",
    "BASE_SEED = 2024\n",
    "LABELS = list(range(10))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Usando dispositivo:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3438aa4d-c821-40d9-9730-e5783e58eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks import ModelSummary\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from torch.utils.data import DataLoader\n",
    "from argparse import ArgumentParser\n",
    "import torch.optim as optim\n",
    "import pennylane as qml\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import warnings\n",
    "import torch\n",
    "import wandb\n",
    "import yaml\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, config_path):\n",
    "        config = parse_config(config_path)\n",
    "        for key, value in config.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def generate_fields(self):\n",
    "        self.discriminator = build_model_from_config(self.discriminator)\n",
    "        self.l_device = [int(self.device[-1])]\n",
    "\n",
    "\n",
    "class QuantumGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    Versão independente de argparse / config.\n",
    "    O device quântico é criado dentro da própria classe.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_qubits, n_rots, n_circuits, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_rots = n_rots\n",
    "\n",
    "        # Device do PennyLane atrelado a esse gerador\n",
    "        dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "        @qml.qnode(dev, interface=\"torch\", diff_method=\"backprop\")\n",
    "        def quantum_circuit(weights):\n",
    "            n_circuits_local = weights.size(0)\n",
    "            n_qubits_local = weights.size(-1)\n",
    "\n",
    "            for i in range(n_circuits_local):\n",
    "                for q in range(n_qubits_local):\n",
    "                    qml.RY(weights[i][0, q], wires=q)\n",
    "                    qml.RZ(weights[i][1, q], wires=q)\n",
    "                    qml.RY(weights[i][2, q], wires=q)\n",
    "                    qml.RZ(weights[i][3, q], wires=q)\n",
    "\n",
    "                for q in range(n_qubits_local):\n",
    "                    qml.CRY(weights[i][4, q], wires=[q, (q + 1) % n_qubits_local])\n",
    "                    qml.CRZ(weights[i][5, q], wires=[q, (q + 1) % n_qubits_local])\n",
    "\n",
    "            return [qml.expval(qml.PauliX(q)) for q in range(n_qubits_local)] + [\n",
    "                qml.expval(qml.PauliZ(q)) for q in range(n_qubits_local)\n",
    "            ]\n",
    "\n",
    "        self.quantum_circuit = quantum_circuit\n",
    "\n",
    "        self.rot_params = nn.ModuleList(\n",
    "            [\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(\n",
    "                        in_features=n_qubits,\n",
    "                        out_features=n_qubits * n_rots,\n",
    "                        bias=True,\n",
    "                    ),\n",
    "                    nn.Dropout(p=dropout),\n",
    "                )\n",
    "                for _ in range(n_circuits)\n",
    "            ]\n",
    "        )\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.rot_params:\n",
    "            # o Sequential tem Linear dentro; vamos inicializar o Linear\n",
    "            for sub in layer:\n",
    "                if isinstance(sub, nn.Linear):\n",
    "                    nn.init.uniform_(sub.weight, -0.01, 0.01)\n",
    "                    nn.init.uniform_(sub.bias, -0.01, 0.01)\n",
    "\n",
    "    def partial_measure(self, noise):\n",
    "        rotations = torch.stack(\n",
    "            [\n",
    "                linear(noise.unsqueeze(0)).reshape(self.n_rots, self.n_qubits)\n",
    "                for linear in self.rot_params\n",
    "            ]\n",
    "        )\n",
    "        exps = self.quantum_circuit(rotations)\n",
    "        exps = torch.stack(exps)\n",
    "        return exps\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = next(self.parameters()).device\n",
    "        hidden_states = [self.partial_measure(elem) for elem in x]\n",
    "        hidden_states = torch.stack(hidden_states).to(device)\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "def run_training(config_path: str, autoencoder_config_path: str):\n",
    "    \"\"\"\n",
    "    Função que faz TODO o processo de treino.\n",
    "    Pode ser chamada tanto via main() (CLI) quanto de outro script/notebook.\n",
    "    \"\"\"\n",
    "\n",
    "    config = Config(config_path)\n",
    "    config.generate_fields()\n",
    "    autoencoder_config = Config(autoencoder_config_path)\n",
    "    base_autoencoder = build_model_from_config(autoencoder_config.autoencoder)\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "    seed_everything(config.random_state)\n",
    "\n",
    "    dataset = DigitsDataset(path_to_csv=config.path_to_mnist, label=range(10))\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    # fixado como no seu código original\n",
    "    config.n_rots = 6\n",
    "\n",
    "    generator = QuantumGenerator(\n",
    "        n_qubits=config.n_qubits,\n",
    "        n_rots=config.n_rots,\n",
    "        n_circuits=config.n_circuits,\n",
    "        dropout=config.generator_dropout,\n",
    "    ).double()\n",
    "\n",
    "    autoencoder = AutoencoderModule.load_from_checkpoint(\n",
    "        checkpoint_path=config.path_to_autoencoder,\n",
    "        autoencoder=base_autoencoder,\n",
    "        optimizer=autoencoder_config.optimizers,\n",
    "    ).double()\n",
    "\n",
    "    pushed_config = {\n",
    "        k: v for k, v in dict(vars(config)).items() if not k.startswith(\"__\")\n",
    "    }\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"QGAN\", name=config.run_name, config=pushed_config\n",
    "    )\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"./weights\",\n",
    "        filename=\"qgan-{epoch}\",\n",
    "        verbose=False,\n",
    "        every_n_epochs=0,\n",
    "        save_last=True,\n",
    "    )\n",
    "\n",
    "    gan = GANModule(\n",
    "        alpha=config.alpha,\n",
    "        n_qubits=config.n_qubits,\n",
    "        n_rots=config.n_rots,\n",
    "        autoencoder=autoencoder,\n",
    "        generator=generator,\n",
    "        discriminator=config.discriminator,\n",
    "        optimizers_config=config.optimizers,\n",
    "        step_disc_every_n_steps=config.step_disc_every_n_steps,\n",
    "    ).double()\n",
    "\n",
    "    trainer = l.Trainer(  # l vem do utils (lightning as l)\n",
    "        accelerator=\"cuda\",\n",
    "        devices=config.l_device,\n",
    "        max_epochs=config.epochs,\n",
    "        enable_progress_bar=True,\n",
    "        log_every_n_steps=config.log_every_n_steps,\n",
    "        logger=wandb_logger,\n",
    "        num_sanity_val_steps=0,\n",
    "        fast_dev_run=config.debug,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    trainer.fit(model=gan, train_dataloaders=dataloader)\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b1cdd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_global_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def denormalize(imgs: torch.Tensor) -> torch.Tensor:\n",
    "    return imgs * 0.5 + 0.5\n",
    "\n",
    "\n",
    "def preprocess_for_inception(imgs: torch.Tensor) -> torch.Tensor:\n",
    "    imgs = denormalize(imgs)\n",
    "    imgs = imgs.clamp(0, 1)\n",
    "    if imgs.size(1) == 1:\n",
    "        imgs = imgs.repeat(1, 3, 1, 1)\n",
    "    imgs = F.interpolate(imgs, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "    return imgs\n",
    "\n",
    "\n",
    "def prepare_real_batches(dataset, *, label_target: int | None, batch_size: int = 64):\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    for real in loader:\n",
    "        if label_target is not None:\n",
    "            # DigitsDataset retorna apenas as imagens; filtramos pelas linhas do csv que já são separadas por label\n",
    "            # (as colunas são filtradas na criação do dataset).\n",
    "            yield real\n",
    "        else:\n",
    "            yield real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75827a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lastqgan_components():\n",
    "    gan_cfg = parse_config(GAN_CONFIG_PATH)\n",
    "    auto_cfg = parse_config(AUTOENCODER_CONFIG_PATH)\n",
    "\n",
    "    discriminator = build_model_from_config(gan_cfg['discriminator'])\n",
    "    autoencoder_model = build_model_from_config(auto_cfg['autoencoder'])\n",
    "\n",
    "    autoencoder = AutoencoderModule(autoencoder=autoencoder_model, optimizer=auto_cfg['optimizers']).double()\n",
    "    generator = QuantumGenerator(\n",
    "        n_qubits=gan_cfg['n_qubits'],\n",
    "        n_rots=6,\n",
    "        n_circuits=gan_cfg['n_circuits'],\n",
    "        dropout=gan_cfg['generator_dropout'],\n",
    "    ).double()\n",
    "\n",
    "    gan_module = GANModule(\n",
    "        alpha=gan_cfg['alpha'],\n",
    "        n_qubits=gan_cfg['n_qubits'],\n",
    "        n_rots=6,\n",
    "        autoencoder=autoencoder,\n",
    "        generator=generator,\n",
    "        discriminator=discriminator,\n",
    "        optimizers_config=gan_cfg['optimizers'],\n",
    "        step_disc_every_n_steps=gan_cfg['step_disc_every_n_steps'],\n",
    "    ).double()\n",
    "\n",
    "    return gan_module, autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9e37268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lastqgan(seed: int):\n",
    "    # Função simples para ilustrar o treinamento sem depender da CLI\n",
    "    import lightning as l\n",
    "\n",
    "    seed_everything(seed)\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "    gan_module, _ = load_lastqgan_components()\n",
    "\n",
    "    dataset = DigitsDataset(path_to_csv=MNIST_CSV, label=LABELS)\n",
    "    num_workers = max(1, min(8, (os.cpu_count() or 1) - 1))\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=num_workers,\n",
    "        persistent_workers=num_workers > 0,\n",
    "        prefetch_factor=2,\n",
    "    )\n",
    "\n",
    "    trainer = l.Trainer(\n",
    "        accelerator='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        devices=1,\n",
    "        max_epochs=NUM_EPOCHS,\n",
    "        enable_progress_bar=True,\n",
    "        logger=False,\n",
    "        enable_checkpointing=False,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model=gan_module, train_dataloaders=loader)\n",
    "    return gan_module\n",
    "\n",
    "def sample_from_lastqgan(generator, *, batch_size: int, latent_dim: int, device, label_target=None):\n",
    "    # O gerador quântico opera no espaço latente de qubits; usamos ruído normal padrão.\n",
    "    noise = torch.randn(batch_size, latent_dim, device=device, dtype=torch.double)\n",
    "    with torch.no_grad():\n",
    "        hidden_states = generator.generator.eval()(noise)\n",
    "        decoded = generator.autoencoder.decode(hidden_states)\n",
    "    return decoded.float()\n",
    "\n",
    "\n",
    "def evaluate_generator(generator_module, *, label_target: int | None, latent_dim: int, device, dataset):\n",
    "    fid = FrechetInceptionDistance(feature=64, normalize=True).to(device)\n",
    "    is_metric = InceptionScore(normalize=True).to(device)\n",
    "    generator_module = generator_module.to(device)\n",
    "    generator_module.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for real_batch in prepare_real_batches(dataset, label_target=label_target):\n",
    "            real = real_batch.to(device).unsqueeze(1)\n",
    "            real = preprocess_for_inception(real)\n",
    "            batch_size = real.size(0)\n",
    "            fake = sample_from_lastqgan(\n",
    "                generator_module,\n",
    "                batch_size=batch_size,\n",
    "                latent_dim=latent_dim,\n",
    "                device=device,\n",
    "                label_target=label_target,\n",
    "            )\n",
    "            fake = preprocess_for_inception(fake)\n",
    "\n",
    "            fid.update(real, real=True)\n",
    "            fid.update(fake, real=False)\n",
    "            is_metric.update(fake)\n",
    "\n",
    "    fid_score = float(fid.compute())\n",
    "    is_mean, is_std = [float(x) for x in is_metric.compute()]\n",
    "    return fid_score, is_mean, is_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f47bf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Rodada 1/3 - LaSt-QGAN =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type              | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | autoencoder   | AutoencoderModule | 13.2 M | train\n",
      "1 | generator     | QuantumGenerator  | 4.0 K  | train\n",
      "2 | discriminator | Sequential        | 8.6 K  | train\n",
      "3 | criterion     | WassersteinLoss   | 0      | train\n",
      "4 | penalty_loss  | PenaltyLoss       | 0      | train\n",
      "------------------------------------------------------------\n",
      "13.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "13.2 M    Total params\n",
      "52.704    Total estimated model params size (MB)\n",
      "59        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/mahlow/anaconda3/envs/my_env/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5816eea39ca54950bd897d815d72a362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "dataset = DigitsDataset(path_to_csv=MNIST_CSV, label=LABELS)\n",
    "\n",
    "for trial in range(NUM_TRAINING_RUNS):\n",
    "    seed = BASE_SEED + trial\n",
    "    print(f'===== Rodada {trial + 1}/{NUM_TRAINING_RUNS} - LaSt-QGAN =====')\n",
    "    qgan_model = train_lastqgan(seed)\n",
    "\n",
    "    for label in LABELS:\n",
    "        for repeat in range(NUM_EVAL_REPEATS):\n",
    "            set_global_seed(seed * 1000 + repeat)\n",
    "            fid, is_mean, is_std = evaluate_generator(\n",
    "                qgan_model,\n",
    "                label_target=label,\n",
    "                latent_dim=LATENT_DIM,\n",
    "                device=device,\n",
    "                dataset=dataset,\n",
    "            )\n",
    "            results.append(\n",
    "                {\n",
    "                    'Model': 'LaSt-QGAN',\n",
    "                    'Label': label,\n",
    "                    'Trial': trial,\n",
    "                    'Repeat': repeat,\n",
    "                    'FID': fid,\n",
    "                    'IS_Mean': is_mean,\n",
    "                    'IS_Std': is_std,\n",
    "                }\n",
    "            )\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074ed9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e81cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_by_model_label = (\n",
    "    results_df\n",
    "    .groupby(['Model', 'Label'])\n",
    "    .agg(\n",
    "        FID_mean=('FID', 'mean'),\n",
    "        FID_std=('FID', 'std'),\n",
    "        IS_mean_mean=('IS_Mean', 'mean'),\n",
    "        IS_mean_std=('IS_Mean', 'std'),\n",
    "        IS_std_mean=('IS_Std', 'mean'),\n",
    "        IS_std_std=('IS_Std', 'std'),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "summary_by_model = (\n",
    "    results_df\n",
    "    .groupby(['Model'])\n",
    "    .agg(\n",
    "        FID_mean=('FID', 'mean'),\n",
    "        FID_std=('FID', 'std'),\n",
    "        IS_mean_mean=('IS_Mean', 'mean'),\n",
    "        IS_mean_std=('IS_Mean', 'std'),\n",
    "        IS_std_mean=('IS_Std', 'mean'),\n",
    "        IS_std_std=('IS_Std', 'std'),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "display(summary_by_model_label)\n",
    "display(summary_by_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc77d162-7f75-4849-be3d-6d869fd6df65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3096af-5130-4844-a5bd-e1c752e7c39a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
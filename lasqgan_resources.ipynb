{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Recursos computacionais do LaSt-QGAN\n\n",
        "Este notebook replica a metodologia usada em `gans_classical_resources.ipynb`, agora aplicada ao modelo LaStQGAN.\n",
        "O objetivo \u00e9 medir custo de treinamento e de infer\u00eancia, bem como o n\u00famero de par\u00e2metros do gerador, \n",
        "executando um ciclo enxuto por classe do MNIST.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from statistics import mean\n\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import pennylane as qml\n\n",
        "import sys\n",
        "from pathlib import Path\n\n",
        "sys.path.append(str(Path('LaSt-QGAN-main').resolve()))\n",
        "from utils import build_model_from_config, parse_config, seed_everything, DigitsDataset\n",
        "from models import WassersteinLoss, PenaltyLoss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "GAN_CONFIG_PATH = 'LaSt-QGAN-main/gan.yaml'\n",
        "AUTOENCODER_CONFIG_PATH = 'LaSt-QGAN-main/autoencoder.yaml'\n\n",
        "gan_cfg = parse_config(GAN_CONFIG_PATH)\n",
        "ae_cfg = parse_config(AUTOENCODER_CONFIG_PATH)\n\n",
        "BATCH_SIZE = gan_cfg.get('batch_size', 128)\n",
        "NUM_EPOCHS = 5\n",
        "LATENT_DIM = gan_cfg['n_qubits']\n",
        "N_CIRCUITS = gan_cfg['n_circuits']\n",
        "N_ROTS = 6\n",
        "GEN_DROPOUT = gan_cfg.get('generator_dropout', 0.0)\n\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "seed_everything(gan_cfg.get('random_state', 0))\n\n",
        "full_dataset = DigitsDataset(path_to_csv=gan_cfg['path_to_mnist'], label=range(10))\n",
        "label_ids = list(range(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_parameters(model):\n    return sum(param.numel() for param in model.parameters())\n\n\ndef build_autoencoder_modules():\n    autoencoder = build_model_from_config(ae_cfg[\"autoencoder\"]).double().to(device)\n    encoder = autoencoder[0]\n    decoder = autoencoder[1]\n    return encoder, decoder\n\n\ndef make_discriminator():\n    discriminator = build_model_from_config(gan_cfg[\"discriminator\"]).double().to(device)\n    return discriminator\n\n\ndef make_generator():\n    return QuantumGenerator(\n        n_qubits=LATENT_DIM,\n        n_rots=N_ROTS,\n        n_circuits=N_CIRCUITS,\n        dropout=GEN_DROPOUT,\n    ).double().to(device)\n\n\nclass QuantumGenerator(nn.Module):\n    def __init__(self, n_qubits, n_rots, n_circuits, dropout):\n        super().__init__()\n        self.n_qubits = n_qubits\n        self.n_rots = n_rots\n        self.n_circuits = n_circuits\n        self.rot_params = nn.ModuleList(\n            [\n                nn.Sequential(\n                    nn.Linear(in_features=n_qubits, out_features=n_qubits * n_rots, bias=True),\n                    nn.Dropout(p=dropout),\n                )\n                for _ in range(n_circuits)\n            ]\n        )\n        self.q_device = qml.device(\"default.qubit\", wires=n_qubits)\n\n        @qml.qnode(self.q_device, interface=\"torch\", diff_method=\"backprop\")\n        def quantum_circuit(weights):\n            n_circuits_local = weights.size(0)\n            n_qubits_local = weights.size(-1)\n            for i in range(n_circuits_local):\n                for q in range(n_qubits_local):\n                    qml.RY(weights[i][0, q], wires=q)\n                    qml.RZ(weights[i][1, q], wires=q)\n                    qml.RY(weights[i][2, q], wires=q)\n                    qml.RZ(weights[i][3, q], wires=q)\n                for q in range(n_qubits_local):\n                    qml.CRY(weights[i][4, q], wires=[q, (q + 1) % n_qubits_local])\n                    qml.CRZ(weights[i][5, q], wires=[q, (q + 1) % n_qubits_local])\n            return [qml.expval(qml.PauliX(q)) for q in range(n_qubits_local)] + [\n                qml.expval(qml.PauliZ(q)) for q in range(n_qubits_local)\n            ]\n\n        self.quantum_circuit = quantum_circuit\n        self.init_weights()\n\n    def init_weights(self):\n        for layer in self.rot_params:\n            for module in layer:\n                if isinstance(module, nn.Linear):\n                    nn.init.uniform_(module.weight, -0.01, 0.01)\n                    nn.init.uniform_(module.bias, -0.01, 0.01)\n\n    def partial_measure(self, noise):\n        rotations = torch.stack(\n            [linear(noise.unsqueeze(0)).reshape(self.n_rots, self.n_qubits) for linear in self.rot_params]\n        )\n        exps = self.quantum_circuit(rotations)\n        exps = torch.stack(exps)\n        return exps\n\n    def forward(self, x):\n        hidden_states = [self.partial_measure(elem) for elem in x]\n        hidden_states = torch.stack(hidden_states).to(x.device)\n        return hidden_states\n\n\ndef measure_inference_time(generator, decoder, *, latent_dim, num_runs=32):\n    generator.eval()\n    decoder.eval()\n    sync = torch.cuda.synchronize if torch.cuda.is_available() else (lambda: None)\n    with torch.no_grad():\n        sync()\n        start = time.time()\n        for _ in range(num_runs):\n            noise = torch.randn(1, latent_dim, device=device, dtype=torch.double)\n            hidden = generator(noise)\n            decoder(hidden)\n        sync()\n    return (time.time() - start) / num_runs\n\n\ndef average_inference_time(generators, decoders):\n    tempos = []\n    for label, generator in generators.items():\n        decoder = decoders[label]\n        tempos.append(measure_inference_time(generator, decoder, latent_dim=LATENT_DIM))\n    return mean(tempos) if tempos else float(\"nan\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n\ndef train_lastqgan_for_label(label):\n    encoder, decoder = build_autoencoder_modules()\n    generator = make_generator()\n    discriminator = make_discriminator()\n\n    criterion = WassersteinLoss()\n    penalty = PenaltyLoss(alpha=gan_cfg[\"alpha\"])\n\n    gen_opt_cfg = gan_cfg[\"optimizers\"][\"generator\"]\n    disc_opt_cfg = gan_cfg[\"optimizers\"][\"discriminator\"]\n    gen_optimizer = getattr(optim, gen_opt_cfg[\"type\"])(generator.parameters(), **gen_opt_cfg[\"parameters\"])\n    disc_optimizer = getattr(optim, disc_opt_cfg[\"type\"])(discriminator.parameters(), **disc_opt_cfg[\"parameters\"])\n\n    dataset = DigitsDataset(path_to_csv=gan_cfg[\"path_to_mnist\"], label=label)\n    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n\n    start = time.time()\n    for _ in range(NUM_EPOCHS):\n        for batch in dataloader:\n            batch = batch.unsqueeze(1).double().to(device)\n            real_hidden = encoder(batch)\n            noise = torch.randn(batch.size(0), LATENT_DIM, device=device, dtype=torch.double)\n            fake_hidden = generator(noise)\n\n            real_scores = discriminator(real_hidden)\n            fake_scores = discriminator(fake_hidden.detach())\n            loss_disc = criterion(real_scores, fake_scores)\n            loss_disc = loss_disc + penalty(real_hidden, fake_hidden.detach(), discriminator)\n            disc_optimizer.zero_grad()\n            loss_disc.backward()\n            disc_optimizer.step()\n\n            fake_scores_for_gen = discriminator(fake_hidden)\n            loss_gen = criterion(torch.zeros_like(fake_scores_for_gen), -fake_scores_for_gen)\n            gen_optimizer.zero_grad()\n            loss_gen.backward()\n            gen_optimizer.step()\n    total_time = time.time() - start\n    return generator.eval(), decoder.eval(), total_time\n\n\ndef run_lastqgan():\n    start_total = time.time()\n    generators = {}\n    decoders = {}\n    per_label_training = []\n\n    for label in label_ids:\n        generator, decoder, tempo = train_lastqgan_for_label(label)\n        generators[label] = generator\n        decoders[label] = decoder\n        per_label_training.append({\n            \"Classe\": label,\n            \"Tempo_treinamento_classe_seg\": tempo,\n        })\n\n    total_time = time.time() - start_total\n    generator_params = count_parameters(next(iter(generators.values()))) if generators else 0\n    inference_time = average_inference_time(generators, decoders)\n    return {\n        \"GAN\": \"LaStQGAN\",\n        \"Tempo_treinamento_seg\": total_time,\n        \"Parametros_Gerador\": generator_params,\n        \"Tempo_infer\u00eancia_img_seg\": inference_time,\n    }, per_label_training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary, per_label_training = run_lastqgan()\n\n",
        "df_summary = pd.DataFrame([summary])\n",
        "df_summary['Tempo_treinamento_min'] = df_summary['Tempo_treinamento_seg'] / 60\n",
        "df_summary['Tempo_infer\u00eancia_img_ms'] = df_summary['Tempo_infer\u00eancia_img_seg'] * 1_000\n",
        "df_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_treinamento = pd.DataFrame(per_label_training)\n",
        "df_treinamento['Tempo_treinamento_classe_min'] = df_treinamento['Tempo_treinamento_classe_seg'] / 60\n",
        "df_treinamento\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}